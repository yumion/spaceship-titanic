{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe19873-9ec2-489b-9a9e-c85a167f5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a71c2447-e029-44c2-a5dd-f81f3135b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/6qwnpvfn0cs2whczwk_5pvqh0000gs/T/ipykernel_37056/3830194740.py:5: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n",
      "  train_test = pd.concat([train, test], axis=0, ignore_index=True, sort=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>GroupId</th>\n",
       "      <th>PeopleId</th>\n",
       "      <th>IsGroup</th>\n",
       "      <th>TotalBill</th>\n",
       "      <th>BillBins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>0001</td>\n",
       "      <td>01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0002</td>\n",
       "      <td>01</td>\n",
       "      <td>False</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0003</td>\n",
       "      <td>01</td>\n",
       "      <td>True</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0003</td>\n",
       "      <td>02</td>\n",
       "      <td>True</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0004</td>\n",
       "      <td>01</td>\n",
       "      <td>False</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...               Name  Transported  \\\n",
       "0          0.0        0.0           0.0  ...    Maham Ofracculy          0.0   \n",
       "1        109.0        9.0          25.0  ...       Juanna Vines          1.0   \n",
       "2         43.0     3576.0           0.0  ...      Altark Susent          0.0   \n",
       "3          0.0     1283.0         371.0  ...       Solam Susent          0.0   \n",
       "4        303.0       70.0         151.0  ...  Willy Santantines          1.0   \n",
       "\n",
       "  CabinDeck  CabinNum CabinSide  GroupId PeopleId IsGroup TotalBill  BillBins  \n",
       "0         B       0.0         P     0001       01   False       0.0         0  \n",
       "1         F       0.0         S     0002       01   False     736.0         0  \n",
       "2         A       0.0         S     0003       01    True   10383.0         2  \n",
       "3         A       0.0         S     0003       02    True    5176.0         2  \n",
       "4         F       1.0         S     0004       01   False    1091.0         0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../dataset/train.csv')\n",
    "test = pd.read_csv('../../dataset/test.csv')\n",
    "# 前処理を一度にやるためにtrainとtestをconcatする\n",
    "test['Transported'] = np.nan\n",
    "train_test = pd.concat([train, test], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# split on `/` to cols (deck/num/side)\n",
    "def split_cabin(df):\n",
    "    cabin = df['Cabin'].str.split('/', expand=True).rename(columns={0: 'CabinDeck', 1: 'CabinNum', 2: 'CabinSide'})\n",
    "    cabin['CabinNum'] = cabin['CabinNum'].astype(float)\n",
    "    return pd.concat([df, cabin], axis=1)\n",
    "\n",
    "# group passenger or not\n",
    "def make_group(df):\n",
    "    df['GroupId'] = df['PassengerId'].apply(lambda x: x.split('_')[0])\n",
    "    df['PeopleId'] = df['PassengerId'].apply(lambda x: x.split('_')[1])\n",
    "    df['IsGroup'] = df['GroupId'].duplicated(keep=False)\n",
    "    return df\n",
    "\n",
    "# total room service, etc...\n",
    "def total_bill(df):\n",
    "    df['TotalBill'] = df[\n",
    "        ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "# binalize 3 classes\n",
    "def binalize_bill(df, th1=5000, th2=20000): \n",
    "    df = total_bill(df)\n",
    "    df['BillBins'] = df['TotalBill'].apply(\n",
    "        lambda x: 0 if x < th1 else (2 if x > th1 and x < th2 else 3))\n",
    "    return df\n",
    "\n",
    "\n",
    "train_test = split_cabin(train_test)\n",
    "train_test = make_group(train_test)\n",
    "train_test = binalize_bill(train_test)\n",
    "\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b13abd-68c8-479d-b158-b6a5cbbf99bd",
   "metadata": {},
   "source": [
    "### 使う特徴量を選ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd293eac-97b4-4270-acbf-208d3a1ab133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>IsGroup</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>TotalBill</th>\n",
       "      <th>BillBins</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet CryoSleep  Destination   Age    VIP CabinDeck  CabinNum  \\\n",
       "0     Europa     False  TRAPPIST-1e  39.0  False         B       0.0   \n",
       "1      Earth     False  TRAPPIST-1e  24.0  False         F       0.0   \n",
       "2     Europa     False  TRAPPIST-1e  58.0   True         A       0.0   \n",
       "3     Europa     False  TRAPPIST-1e  33.0  False         A       0.0   \n",
       "4      Earth     False  TRAPPIST-1e  16.0  False         F       1.0   \n",
       "\n",
       "  CabinSide  IsGroup  RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  \\\n",
       "0         P    False          0.0        0.0           0.0     0.0     0.0   \n",
       "1         S    False        109.0        9.0          25.0   549.0    44.0   \n",
       "2         S     True         43.0     3576.0           0.0  6715.0    49.0   \n",
       "3         S     True          0.0     1283.0         371.0  3329.0   193.0   \n",
       "4         S    False        303.0       70.0         151.0   565.0     2.0   \n",
       "\n",
       "   TotalBill  BillBins  Transported  \n",
       "0        0.0         0          0.0  \n",
       "1      736.0         0          1.0  \n",
       "2    10383.0         2          0.0  \n",
       "3     5176.0         2          0.0  \n",
       "4     1091.0         0          1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test = train_test[['HomePlanet', 'CryoSleep', 'Destination', 'Age', 'VIP', 'CabinDeck', 'CabinNum', 'CabinSide', 'IsGroup', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalBill', 'BillBins', 'Transported']]\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9483535-afa5-4f1c-8ba7-264aee7a3dcc",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a00295ee-a09b-41cd-a287-9dc73879dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HomePlanet, Destination, CabinSideはlabel encoding\n",
    "for col in ['HomePlanet', 'Destination', 'CabinDeck', 'CabinSide']:\n",
    "    train_test[col] = pd.factorize(train_test[col])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6d12e2-e7f0-4c2e-a9d1-7344ee92dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolをintへ\n",
    "def bool2int(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == bool:\n",
    "            df[col] = df[col].astype(float)\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].map({True: 1, False: 0})\n",
    "    return df\n",
    "\n",
    "train_test = bool2int(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893c3a9a-9053-4d01-9cbb-c3af6657f8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>IsGroup</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>TotalBill</th>\n",
       "      <th>BillBins</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12965</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12966</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12967</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>296.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12968</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12969</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12970 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HomePlanet  CryoSleep  Destination   Age  VIP  CabinDeck  CabinNum  \\\n",
       "0               0        0.0            0  39.0  0.0          0       0.0   \n",
       "1               1        0.0            0  24.0  0.0          1       0.0   \n",
       "2               0        0.0            0  58.0  1.0          2       0.0   \n",
       "3               0        0.0            0  33.0  0.0          2       0.0   \n",
       "4               1        0.0            0  16.0  0.0          1       1.0   \n",
       "...           ...        ...          ...   ...  ...        ...       ...   \n",
       "12965           1        1.0            0  34.0  0.0          3    1496.0   \n",
       "12966           1        0.0            0  42.0  0.0         -1       NaN   \n",
       "12967           2        1.0            2   NaN  0.0          5     296.0   \n",
       "12968           0        0.0           -1   NaN  0.0          5     297.0   \n",
       "12969           1        1.0            1  43.0  0.0          3    1498.0   \n",
       "\n",
       "       CabinSide  IsGroup  RoomService  FoodCourt  ShoppingMall     Spa  \\\n",
       "0              0      0.0          0.0        0.0           0.0     0.0   \n",
       "1              1      0.0        109.0        9.0          25.0   549.0   \n",
       "2              1      1.0         43.0     3576.0           0.0  6715.0   \n",
       "3              1      1.0          0.0     1283.0         371.0  3329.0   \n",
       "4              1      0.0        303.0       70.0         151.0   565.0   \n",
       "...          ...      ...          ...        ...           ...     ...   \n",
       "12965          1      1.0          0.0        0.0           0.0     0.0   \n",
       "12966         -1      0.0          0.0      847.0          17.0    10.0   \n",
       "12967          0      0.0          0.0        0.0           0.0     0.0   \n",
       "12968          0      0.0          0.0     2680.0           0.0     0.0   \n",
       "12969          1      0.0          0.0        0.0           0.0     0.0   \n",
       "\n",
       "       VRDeck  TotalBill  BillBins  Transported  \n",
       "0         0.0        0.0         0          0.0  \n",
       "1        44.0      736.0         0          1.0  \n",
       "2        49.0    10383.0         2          0.0  \n",
       "3       193.0     5176.0         2          0.0  \n",
       "4         2.0     1091.0         0          1.0  \n",
       "...       ...        ...       ...          ...  \n",
       "12965     0.0        0.0         0          NaN  \n",
       "12966   144.0     1018.0         0          NaN  \n",
       "12967     0.0        0.0         0          NaN  \n",
       "12968   523.0     3203.0         0          NaN  \n",
       "12969     0.0        0.0         0          NaN  \n",
       "\n",
       "[12970 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8968f15-7beb-4812-8a0b-34a01ca78706",
   "metadata": {},
   "source": [
    "### モデリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fdd3ad9-ef1f-44e8-85af-e82c1f98b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgbm\n",
    "import optuna.integration.lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b001a28-4bb3-47d4-a33e-0718848045c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.1,\n",
    "    'importance_type': 'gain',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7fb96-da28-4596-b01a-9cf413b4cdc9",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12159b79-3081-420f-bcf6-c362e1888c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c287669-65a1-4e2f-ae1b-a712c2974490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=3407):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "SEED = 3407\n",
    "set_seed(SEED)\n",
    "params.update(dict(seed=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dae376e3-e139-4686-92a5-69ddc921112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameをnp.ndarrayに変換\n",
    "trainval = train_test[~train_test['Transported'].isna()]\n",
    "test = train_test[train_test['Transported'].isna()]\n",
    "# inputとlabelに分離\n",
    "x_trainval = trainval.drop('Transported', axis=1).values\n",
    "y_trainval = trainval.Transported.values\n",
    "x_test = test.drop('Transported', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b78f65b-261d-4d0f-b136-2ec06c7794f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 16), (8693,), (4277, 16))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trainval.shape, y_trainval.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "221e97d9-6672-4c85-8a22-8faae4735542",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-14 22:32:19,689]\u001b[0m A new study created in memory with name: no-name-1daed285-4c46-4331-9763-b871d0ba3aec\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.395494:  14%|#4        | 1/7 [00:00<00:05,  1.10it/s]\u001b[32m[I 2022-09-14 22:32:20,600]\u001b[0m Trial 0 finished with value: 0.39549419673208625 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.39549419673208625.\u001b[0m\n",
      "feature_fraction, val_score: 0.395494:  14%|#4        | 1/7 [00:00<00:05,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.267827\tVal's binary_logloss: 0.395494\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.391110:  29%|##8       | 2/7 [00:01<00:04,  1.24it/s]\u001b[32m[I 2022-09-14 22:32:21,336]\u001b[0m Trial 1 finished with value: 0.3911101776758271 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.3911101776758271.\u001b[0m\n",
      "feature_fraction, val_score: 0.391110:  29%|##8       | 2/7 [00:01<00:04,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255861\tVal's binary_logloss: 0.39111\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.391110:  43%|####2     | 3/7 [00:02<00:03,  1.11it/s]\u001b[32m[I 2022-09-14 22:32:22,345]\u001b[0m Trial 2 finished with value: 0.39702846022088756 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.3911101776758271.\u001b[0m\n",
      "feature_fraction, val_score: 0.391110:  43%|####2     | 3/7 [00:02<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.28282\tVal's binary_logloss: 0.397028\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388836:  57%|#####7    | 4/7 [00:03<00:02,  1.12it/s]\u001b[32m[I 2022-09-14 22:32:23,239]\u001b[0m Trial 3 finished with value: 0.38883553428278633 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 0.38883553428278633.\u001b[0m\n",
      "feature_fraction, val_score: 0.388836:  57%|#####7    | 4/7 [00:03<00:02,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.254\tVal's binary_logloss: 0.388836\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388836:  71%|#######1  | 5/7 [00:04<00:01,  1.06it/s]\u001b[32m[I 2022-09-14 22:32:24,254]\u001b[0m Trial 4 finished with value: 0.3928454269051301 and parameters: {'feature_fraction': 0.6}. Best is trial 3 with value: 0.38883553428278633.\u001b[0m\n",
      "feature_fraction, val_score: 0.388836:  71%|#######1  | 5/7 [00:04<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.261216\tVal's binary_logloss: 0.392845\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388836:  86%|########5 | 6/7 [00:05<00:00,  1.01it/s]\u001b[32m[I 2022-09-14 22:32:25,349]\u001b[0m Trial 5 finished with value: 0.3911248267256537 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.38883553428278633.\u001b[0m\n",
      "feature_fraction, val_score: 0.388836:  86%|########5 | 6/7 [00:05<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.247302\tVal's binary_logloss: 0.391125\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388836: 100%|##########| 7/7 [00:06<00:00,  1.03s/it]\u001b[32m[I 2022-09-14 22:32:26,451]\u001b[0m Trial 6 finished with value: 0.39225929559561645 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 0.38883553428278633.\u001b[0m\n",
      "feature_fraction, val_score: 0.388836: 100%|##########| 7/7 [00:06<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253973\tVal's binary_logloss: 0.392259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:   5%|5         | 1/20 [00:03<01:14,  3.90s/it]\u001b[32m[I 2022-09-14 22:32:30,364]\u001b[0m Trial 7 finished with value: 0.3995657574326536 and parameters: {'num_leaves': 178}. Best is trial 7 with value: 0.3995657574326536.\u001b[0m\n",
      "num_leaves, val_score: 0.388836:   5%|5         | 1/20 [00:03<01:14,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's binary_logloss: 0.199564\tVal's binary_logloss: 0.399566\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:  10%|#         | 2/20 [00:10<01:42,  5.68s/it]\u001b[32m[I 2022-09-14 22:32:37,291]\u001b[0m Trial 8 finished with value: 0.4051492721767544 and parameters: {'num_leaves': 250}. Best is trial 7 with value: 0.3995657574326536.\u001b[0m\n",
      "num_leaves, val_score: 0.388836:  10%|#         | 2/20 [00:10<01:42,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tTrain's binary_logloss: 0.226923\tVal's binary_logloss: 0.405149\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:  15%|#5        | 3/20 [00:14<01:23,  4.90s/it]\u001b[32m[I 2022-09-14 22:32:41,255]\u001b[0m Trial 9 finished with value: 0.4055176156834949 and parameters: {'num_leaves': 195}. Best is trial 7 with value: 0.3995657574326536.\u001b[0m\n",
      "num_leaves, val_score: 0.388836:  15%|#5        | 3/20 [00:14<01:23,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tTrain's binary_logloss: 0.227718\tVal's binary_logloss: 0.405518\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:  20%|##        | 4/20 [00:18<01:07,  4.24s/it]\u001b[32m[I 2022-09-14 22:32:44,482]\u001b[0m Trial 10 finished with value: 0.4021635874148233 and parameters: {'num_leaves': 171}. Best is trial 7 with value: 0.3995657574326536.\u001b[0m\n",
      "num_leaves, val_score: 0.388836:  20%|##        | 4/20 [00:18<01:07,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tTrain's binary_logloss: 0.244474\tVal's binary_logloss: 0.402164\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:  25%|##5       | 5/20 [00:19<00:46,  3.09s/it]\u001b[32m[I 2022-09-14 22:32:45,533]\u001b[0m Trial 11 finished with value: 0.3981199095340449 and parameters: {'num_leaves': 44}. Best is trial 11 with value: 0.3981199095340449.\u001b[0m\n",
      "num_leaves, val_score: 0.388836:  25%|##5       | 5/20 [00:19<00:46,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.217305\tVal's binary_logloss: 0.39812\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:  30%|###       | 6/20 [00:20<00:37,  2.66s/it]\u001b[32m[I 2022-09-14 22:32:47,355]\u001b[0m Trial 12 finished with value: 0.39421956801093005 and parameters: {'num_leaves': 91}. Best is trial 12 with value: 0.39421956801093005.\u001b[0m\n",
      "num_leaves, val_score: 0.388836:  30%|###       | 6/20 [00:20<00:37,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tTrain's binary_logloss: 0.249241\tVal's binary_logloss: 0.39422\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:  35%|###5      | 7/20 [00:21<00:26,  2.04s/it]\u001b[32m[I 2022-09-14 22:32:48,122]\u001b[0m Trial 13 finished with value: 0.394069889660834 and parameters: {'num_leaves': 27}. Best is trial 13 with value: 0.394069889660834.\u001b[0m\n",
      "num_leaves, val_score: 0.388836:  35%|###5      | 7/20 [00:21<00:26,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.264465\tVal's binary_logloss: 0.39407\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:  40%|####      | 8/20 [00:23<00:24,  2.02s/it]\u001b[32m[I 2022-09-14 22:32:50,089]\u001b[0m Trial 14 finished with value: 0.39448094460930816 and parameters: {'num_leaves': 96}. Best is trial 13 with value: 0.394069889660834.\u001b[0m\n",
      "num_leaves, val_score: 0.388836:  40%|####      | 8/20 [00:23<00:24,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's binary_logloss: 0.228872\tVal's binary_logloss: 0.394481\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:  45%|####5     | 9/20 [00:24<00:19,  1.74s/it]\u001b[32m[I 2022-09-14 22:32:51,234]\u001b[0m Trial 15 finished with value: 0.39045607046140846 and parameters: {'num_leaves': 48}. Best is trial 15 with value: 0.39045607046140846.\u001b[0m\n",
      "num_leaves, val_score: 0.388836:  45%|####5     | 9/20 [00:24<00:19,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's binary_logloss: 0.27903\tVal's binary_logloss: 0.390456\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388836:  50%|#####     | 10/20 [00:26<00:16,  1.67s/it]\u001b[32m[I 2022-09-14 22:32:52,729]\u001b[0m Trial 16 finished with value: 0.4066251831162372 and parameters: {'num_leaves': 56}. Best is trial 15 with value: 0.39045607046140846.\u001b[0m\n",
      "num_leaves, val_score: 0.388836:  50%|#####     | 10/20 [00:26<00:16,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.192999\tVal's binary_logloss: 0.406625\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388626:  55%|#####5    | 11/20 [00:27<00:12,  1.41s/it]\u001b[32m[I 2022-09-14 22:32:53,541]\u001b[0m Trial 17 finished with value: 0.3886260976496118 and parameters: {'num_leaves': 14}. Best is trial 17 with value: 0.3886260976496118.\u001b[0m\n",
      "num_leaves, val_score: 0.388626:  55%|#####5    | 11/20 [00:27<00:12,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.319467\tVal's binary_logloss: 0.388626\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388626:  60%|######    | 12/20 [00:27<00:09,  1.16s/it]\u001b[32m[I 2022-09-14 22:32:54,140]\u001b[0m Trial 18 finished with value: 0.3886260976496118 and parameters: {'num_leaves': 14}. Best is trial 17 with value: 0.3886260976496118.\u001b[0m\n",
      "num_leaves, val_score: 0.388626:  60%|######    | 12/20 [00:27<00:09,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.319467\tVal's binary_logloss: 0.388626\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.433663\tVal's binary_logloss: 0.436785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388626:  65%|######5   | 13/20 [00:27<00:06,  1.15it/s]\u001b[32m[I 2022-09-14 22:32:54,337]\u001b[0m Trial 19 finished with value: 0.4367854032024237 and parameters: {'num_leaves': 3}. Best is trial 17 with value: 0.3886260976496118.\u001b[0m\n",
      "num_leaves, val_score: 0.388626:  70%|#######   | 14/20 [00:28<00:04,  1.47it/s]\u001b[32m[I 2022-09-14 22:32:54,588]\u001b[0m Trial 20 finished with value: 0.4367854032024237 and parameters: {'num_leaves': 3}. Best is trial 17 with value: 0.3886260976496118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.433663\tVal's binary_logloss: 0.436785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388626:  70%|#######   | 14/20 [00:28<00:04,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388626:  75%|#######5  | 15/20 [00:30<00:05,  1.17s/it]\u001b[32m[I 2022-09-14 22:32:56,905]\u001b[0m Trial 21 finished with value: 0.3957739927731274 and parameters: {'num_leaves': 89}. Best is trial 17 with value: 0.3886260976496118.\u001b[0m\n",
      "num_leaves, val_score: 0.388626:  75%|#######5  | 15/20 [00:30<00:05,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's binary_logloss: 0.252947\tVal's binary_logloss: 0.395774\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388626:  80%|########  | 16/20 [00:34<00:07,  1.97s/it]\u001b[32m[I 2022-09-14 22:33:00,729]\u001b[0m Trial 22 finished with value: 0.39994358124542495 and parameters: {'num_leaves': 133}. Best is trial 17 with value: 0.3886260976496118.\u001b[0m\n",
      "num_leaves, val_score: 0.388626:  80%|########  | 16/20 [00:34<00:07,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tTrain's binary_logloss: 0.230425\tVal's binary_logloss: 0.399944\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388626:  85%|########5 | 17/20 [00:36<00:06,  2.17s/it]\u001b[32m[I 2022-09-14 22:33:03,359]\u001b[0m Trial 23 finished with value: 0.4024918206748453 and parameters: {'num_leaves': 128}. Best is trial 17 with value: 0.3886260976496118.\u001b[0m\n",
      "num_leaves, val_score: 0.388626:  85%|########5 | 17/20 [00:36<00:06,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tTrain's binary_logloss: 0.232473\tVal's binary_logloss: 0.402492\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388626:  90%|######### | 18/20 [00:39<00:04,  2.19s/it]\u001b[32m[I 2022-09-14 22:33:05,592]\u001b[0m Trial 24 finished with value: 0.4109520266745399 and parameters: {'num_leaves': 68}. Best is trial 17 with value: 0.3886260976496118.\u001b[0m\n",
      "num_leaves, val_score: 0.388626:  90%|######### | 18/20 [00:39<00:04,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.172528\tVal's binary_logloss: 0.410952\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388626:  95%|#########5| 19/20 [00:40<00:01,  1.81s/it]\u001b[32m[I 2022-09-14 22:33:06,510]\u001b[0m Trial 25 finished with value: 0.3909197938042965 and parameters: {'num_leaves': 26}. Best is trial 17 with value: 0.3886260976496118.\u001b[0m\n",
      "num_leaves, val_score: 0.388626:  95%|#########5| 19/20 [00:40<00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.26821\tVal's binary_logloss: 0.39092\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388626: 100%|##########| 20/20 [00:42<00:00,  2.12s/it]\u001b[32m[I 2022-09-14 22:33:09,366]\u001b[0m Trial 26 finished with value: 0.39824514055784005 and parameters: {'num_leaves': 115}. Best is trial 17 with value: 0.3886260976496118.\u001b[0m\n",
      "num_leaves, val_score: 0.388626: 100%|##########| 20/20 [00:42<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tTrain's binary_logloss: 0.229112\tVal's binary_logloss: 0.398245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388626:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388626:  10%|#         | 1/10 [00:00<00:04,  1.94it/s]\u001b[32m[I 2022-09-14 22:33:09,889]\u001b[0m Trial 27 finished with value: 0.3941068088885215 and parameters: {'bagging_fraction': 0.5332334867351889, 'bagging_freq': 7}. Best is trial 27 with value: 0.3941068088885215.\u001b[0m\n",
      "bagging, val_score: 0.388626:  10%|#         | 1/10 [00:00<00:04,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.323889\tVal's binary_logloss: 0.394107\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388626:  20%|##        | 2/10 [00:01<00:04,  1.96it/s]\u001b[32m[I 2022-09-14 22:33:10,398]\u001b[0m Trial 28 finished with value: 0.3914673134323511 and parameters: {'bagging_fraction': 0.7022390034422246, 'bagging_freq': 3}. Best is trial 28 with value: 0.3914673134323511.\u001b[0m\n",
      "bagging, val_score: 0.388626:  20%|##        | 2/10 [00:01<00:04,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.319108\tVal's binary_logloss: 0.391467\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.387205:  30%|###       | 3/10 [00:01<00:03,  2.01it/s]\u001b[32m[I 2022-09-14 22:33:10,878]\u001b[0m Trial 29 finished with value: 0.38720505567346986 and parameters: {'bagging_fraction': 0.8701530810123823, 'bagging_freq': 6}. Best is trial 29 with value: 0.38720505567346986.\u001b[0m\n",
      "bagging, val_score: 0.387205:  30%|###       | 3/10 [00:01<00:03,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.31816\tVal's binary_logloss: 0.387205\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.387205:  40%|####      | 4/10 [00:01<00:02,  2.02it/s]\u001b[32m[I 2022-09-14 22:33:11,369]\u001b[0m Trial 30 finished with value: 0.392056400691449 and parameters: {'bagging_fraction': 0.5666775861663855, 'bagging_freq': 4}. Best is trial 29 with value: 0.38720505567346986.\u001b[0m\n",
      "bagging, val_score: 0.387205:  40%|####      | 4/10 [00:01<00:02,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.321422\tVal's binary_logloss: 0.392056\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.387205:  50%|#####     | 5/10 [00:02<00:02,  2.05it/s]\u001b[32m[I 2022-09-14 22:33:11,844]\u001b[0m Trial 31 finished with value: 0.38824372431975235 and parameters: {'bagging_fraction': 0.7790783211535979, 'bagging_freq': 7}. Best is trial 29 with value: 0.38720505567346986.\u001b[0m\n",
      "bagging, val_score: 0.387205:  50%|#####     | 5/10 [00:02<00:02,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.31857\tVal's binary_logloss: 0.388244\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.387205:  60%|######    | 6/10 [00:02<00:01,  2.04it/s]\u001b[32m[I 2022-09-14 22:33:12,336]\u001b[0m Trial 32 finished with value: 0.39098223212994504 and parameters: {'bagging_fraction': 0.786701755584394, 'bagging_freq': 2}. Best is trial 29 with value: 0.38720505567346986.\u001b[0m\n",
      "bagging, val_score: 0.387205:  60%|######    | 6/10 [00:02<00:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.316717\tVal's binary_logloss: 0.390982\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.387205:  70%|#######   | 7/10 [00:03<00:01,  2.06it/s]\u001b[32m[I 2022-09-14 22:33:12,814]\u001b[0m Trial 33 finished with value: 0.387921089210466 and parameters: {'bagging_fraction': 0.8303549639826371, 'bagging_freq': 6}. Best is trial 29 with value: 0.38720505567346986.\u001b[0m\n",
      "bagging, val_score: 0.387205:  70%|#######   | 7/10 [00:03<00:01,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.316857\tVal's binary_logloss: 0.387921\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.387205:  80%|########  | 8/10 [00:03<00:00,  2.07it/s]\u001b[32m[I 2022-09-14 22:33:13,295]\u001b[0m Trial 34 finished with value: 0.38890747993296687 and parameters: {'bagging_fraction': 0.528768367720154, 'bagging_freq': 5}. Best is trial 29 with value: 0.38720505567346986.\u001b[0m\n",
      "bagging, val_score: 0.387205:  80%|########  | 8/10 [00:03<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.319831\tVal's binary_logloss: 0.388907\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.387205:  90%|######### | 9/10 [00:04<00:00,  2.07it/s]\u001b[32m[I 2022-09-14 22:33:13,773]\u001b[0m Trial 35 finished with value: 0.3888446784390452 and parameters: {'bagging_fraction': 0.48412737944403594, 'bagging_freq': 1}. Best is trial 29 with value: 0.38720505567346986.\u001b[0m\n",
      "bagging, val_score: 0.387205:  90%|######### | 9/10 [00:04<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.320158\tVal's binary_logloss: 0.388845\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.387205: 100%|##########| 10/10 [00:04<00:00,  2.03it/s]\u001b[32m[I 2022-09-14 22:33:14,293]\u001b[0m Trial 36 finished with value: 0.3898729626351076 and parameters: {'bagging_fraction': 0.7026212965616482, 'bagging_freq': 5}. Best is trial 29 with value: 0.38720505567346986.\u001b[0m\n",
      "bagging, val_score: 0.387205: 100%|##########| 10/10 [00:04<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.317686\tVal's binary_logloss: 0.389873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.387205:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.387205:  17%|#6        | 1/6 [00:00<00:04,  1.21it/s]\u001b[32m[I 2022-09-14 22:33:15,130]\u001b[0m Trial 37 finished with value: 0.3920183972292258 and parameters: {'feature_fraction': 0.82}. Best is trial 37 with value: 0.3920183972292258.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.387205:  17%|#6        | 1/6 [00:00<00:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.319323\tVal's binary_logloss: 0.392018\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.387205:  33%|###3      | 2/6 [00:01<00:02,  1.61it/s]\u001b[32m[I 2022-09-14 22:33:15,605]\u001b[0m Trial 38 finished with value: 0.38720505567346986 and parameters: {'feature_fraction': 0.852}. Best is trial 38 with value: 0.38720505567346986.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.387205:  33%|###3      | 2/6 [00:01<00:02,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.31816\tVal's binary_logloss: 0.387205\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.387129:  50%|#####     | 3/6 [00:01<00:01,  1.72it/s]\u001b[32m[I 2022-09-14 22:33:16,141]\u001b[0m Trial 39 finished with value: 0.3871289251475479 and parameters: {'feature_fraction': 0.948}. Best is trial 39 with value: 0.3871289251475479.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.387129:  50%|#####     | 3/6 [00:01<00:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.315399\tVal's binary_logloss: 0.387129\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.387129:  67%|######6   | 4/6 [00:02<00:01,  1.84it/s]\u001b[32m[I 2022-09-14 22:33:16,629]\u001b[0m Trial 40 finished with value: 0.3871289251475479 and parameters: {'feature_fraction': 0.9159999999999999}. Best is trial 39 with value: 0.3871289251475479.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.387129:  67%|######6   | 4/6 [00:02<00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.315399\tVal's binary_logloss: 0.387129\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.387129:  83%|########3 | 5/6 [00:02<00:00,  1.91it/s]\u001b[32m[I 2022-09-14 22:33:17,115]\u001b[0m Trial 41 finished with value: 0.38720505567346986 and parameters: {'feature_fraction': 0.8839999999999999}. Best is trial 39 with value: 0.3871289251475479.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.387129:  83%|########3 | 5/6 [00:02<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.31816\tVal's binary_logloss: 0.387205\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.385443: 100%|##########| 6/6 [00:03<00:00,  1.93it/s]\u001b[32m[I 2022-09-14 22:33:17,621]\u001b[0m Trial 42 finished with value: 0.3854434216491946 and parameters: {'feature_fraction': 0.9799999999999999}. Best is trial 42 with value: 0.3854434216491946.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.385443: 100%|##########| 6/6 [00:03<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.314997\tVal's binary_logloss: 0.385443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.385443:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.384241:   5%|5         | 1/20 [00:00<00:09,  1.95it/s]\u001b[32m[I 2022-09-14 22:33:18,142]\u001b[0m Trial 43 finished with value: 0.38424098224065106 and parameters: {'lambda_l1': 1.1254990041638806e-07, 'lambda_l2': 0.0007256904246571266}. Best is trial 43 with value: 0.38424098224065106.\u001b[0m\n",
      "regularization_factors, val_score: 0.384241:   5%|5         | 1/20 [00:00<00:09,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.312527\tVal's binary_logloss: 0.384241\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.384241:  10%|#         | 2/20 [00:01<00:09,  1.99it/s]\u001b[32m[I 2022-09-14 22:33:18,636]\u001b[0m Trial 44 finished with value: 0.38458503512868397 and parameters: {'lambda_l1': 1.5619385875177365e-06, 'lambda_l2': 0.004713251854655346}. Best is trial 43 with value: 0.38424098224065106.\u001b[0m\n",
      "regularization_factors, val_score: 0.384241:  10%|#         | 2/20 [00:01<00:09,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.314593\tVal's binary_logloss: 0.384585\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.384241:  15%|#5        | 3/20 [00:01<00:08,  1.94it/s]\u001b[32m[I 2022-09-14 22:33:19,168]\u001b[0m Trial 45 finished with value: 0.38520907103117863 and parameters: {'lambda_l1': 1.9376040418582793e-05, 'lambda_l2': 8.906594328997229e-07}. Best is trial 43 with value: 0.38424098224065106.\u001b[0m\n",
      "regularization_factors, val_score: 0.384241:  15%|#5        | 3/20 [00:01<00:08,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.312601\tVal's binary_logloss: 0.385209\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.384241:  20%|##        | 4/20 [00:02<00:08,  1.97it/s]\u001b[32m[I 2022-09-14 22:33:19,661]\u001b[0m Trial 46 finished with value: 0.38535068335530714 and parameters: {'lambda_l1': 0.02286938357065969, 'lambda_l2': 2.076345415748266e-07}. Best is trial 43 with value: 0.38424098224065106.\u001b[0m\n",
      "regularization_factors, val_score: 0.384241:  20%|##        | 4/20 [00:02<00:08,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.314111\tVal's binary_logloss: 0.385351\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.384241:  25%|##5       | 5/20 [00:02<00:07,  1.98it/s]\u001b[32m[I 2022-09-14 22:33:20,163]\u001b[0m Trial 47 finished with value: 0.3848286306319461 and parameters: {'lambda_l1': 0.0003170963780724449, 'lambda_l2': 1.9856495945669699}. Best is trial 43 with value: 0.38424098224065106.\u001b[0m\n",
      "regularization_factors, val_score: 0.384241:  25%|##5       | 5/20 [00:02<00:07,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.321614\tVal's binary_logloss: 0.384829\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.384241:  30%|###       | 6/20 [00:03<00:07,  1.94it/s]\u001b[32m[I 2022-09-14 22:33:20,701]\u001b[0m Trial 48 finished with value: 0.38458482963991614 and parameters: {'lambda_l1': 0.00010894067461109016, 'lambda_l2': 0.003273781811363241}. Best is trial 43 with value: 0.38424098224065106.\u001b[0m\n",
      "regularization_factors, val_score: 0.384241:  30%|###       | 6/20 [00:03<00:07,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.314583\tVal's binary_logloss: 0.384585\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383239:  35%|###5      | 7/20 [00:03<00:06,  1.92it/s]\u001b[32m[I 2022-09-14 22:33:21,234]\u001b[0m Trial 49 finished with value: 0.38323874319442824 and parameters: {'lambda_l1': 0.00025649300416688065, 'lambda_l2': 0.014945355529445174}. Best is trial 49 with value: 0.38323874319442824.\u001b[0m\n",
      "regularization_factors, val_score: 0.383239:  35%|###5      | 7/20 [00:03<00:06,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.31262\tVal's binary_logloss: 0.383239\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383239:  40%|####      | 8/20 [00:04<00:06,  1.95it/s]\u001b[32m[I 2022-09-14 22:33:21,726]\u001b[0m Trial 50 finished with value: 0.3854813526277583 and parameters: {'lambda_l1': 1.2303195636231778e-06, 'lambda_l2': 5.9643779391539654e-05}. Best is trial 49 with value: 0.38323874319442824.\u001b[0m\n",
      "regularization_factors, val_score: 0.383239:  40%|####      | 8/20 [00:04<00:06,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.314996\tVal's binary_logloss: 0.385481\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383239:  45%|####5     | 9/20 [00:04<00:05,  1.95it/s]\u001b[32m[I 2022-09-14 22:33:22,236]\u001b[0m Trial 51 finished with value: 0.3842412451673125 and parameters: {'lambda_l1': 0.00028189948989103454, 'lambda_l2': 8.351137731328929e-08}. Best is trial 49 with value: 0.38323874319442824.\u001b[0m\n",
      "regularization_factors, val_score: 0.383239:  45%|####5     | 9/20 [00:04<00:05,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.312524\tVal's binary_logloss: 0.384241\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383239:  50%|#####     | 10/20 [00:05<00:05,  1.94it/s]\u001b[32m[I 2022-09-14 22:33:22,760]\u001b[0m Trial 52 finished with value: 0.3878035919526754 and parameters: {'lambda_l1': 0.19977175460998858, 'lambda_l2': 0.29747932092926355}. Best is trial 49 with value: 0.38323874319442824.\u001b[0m\n",
      "regularization_factors, val_score: 0.383239:  50%|#####     | 10/20 [00:05<00:05,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.316968\tVal's binary_logloss: 0.387804\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383239:  55%|#####5    | 11/20 [00:05<00:04,  1.97it/s]\u001b[32m[I 2022-09-14 22:33:23,252]\u001b[0m Trial 53 finished with value: 0.38414745344997303 and parameters: {'lambda_l1': 0.007205233055844207, 'lambda_l2': 0.0934081782340072}. Best is trial 49 with value: 0.38323874319442824.\u001b[0m\n",
      "regularization_factors, val_score: 0.383239:  55%|#####5    | 11/20 [00:05<00:04,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.314072\tVal's binary_logloss: 0.384147\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383239:  60%|######    | 12/20 [00:06<00:04,  1.94it/s]\u001b[32m[I 2022-09-14 22:33:23,786]\u001b[0m Trial 54 finished with value: 0.391269783022598 and parameters: {'lambda_l1': 5.899600364618708, 'lambda_l2': 0.1952911112592253}. Best is trial 49 with value: 0.38323874319442824.\u001b[0m\n",
      "regularization_factors, val_score: 0.383239:  60%|######    | 12/20 [00:06<00:04,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.342694\tVal's binary_logloss: 0.39127\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383239:  65%|######5   | 13/20 [00:06<00:03,  1.90it/s]\u001b[32m[I 2022-09-14 22:33:24,334]\u001b[0m Trial 55 finished with value: 0.385888029745894 and parameters: {'lambda_l1': 0.010538086623136243, 'lambda_l2': 0.04012449278806845}. Best is trial 49 with value: 0.38323874319442824.\u001b[0m\n",
      "regularization_factors, val_score: 0.383239:  65%|######5   | 13/20 [00:06<00:03,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.313089\tVal's binary_logloss: 0.385888\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383239:  70%|#######   | 14/20 [00:07<00:03,  1.86it/s]\u001b[32m[I 2022-09-14 22:33:24,897]\u001b[0m Trial 56 finished with value: 0.3856909820773129 and parameters: {'lambda_l1': 0.017190396213369544, 'lambda_l2': 4.4140035800120044e-05}. Best is trial 49 with value: 0.38323874319442824.\u001b[0m\n",
      "regularization_factors, val_score: 0.383239:  70%|#######   | 14/20 [00:07<00:03,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.31439\tVal's binary_logloss: 0.385691\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383093:  75%|#######5  | 15/20 [00:07<00:02,  1.86it/s]\u001b[32m[I 2022-09-14 22:33:25,440]\u001b[0m Trial 57 finished with value: 0.3830932657972586 and parameters: {'lambda_l1': 0.00202731977845877, 'lambda_l2': 1.9236139569852346}. Best is trial 57 with value: 0.3830932657972586.\u001b[0m\n",
      "regularization_factors, val_score: 0.383093:  75%|#######5  | 15/20 [00:07<00:02,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.321249\tVal's binary_logloss: 0.383093\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383093:  80%|########  | 16/20 [00:08<00:02,  1.81it/s]\u001b[32m[I 2022-09-14 22:33:26,022]\u001b[0m Trial 58 finished with value: 0.38577757781652194 and parameters: {'lambda_l1': 1.6099944593119443e-08, 'lambda_l2': 4.3989064630059}. Best is trial 57 with value: 0.3830932657972586.\u001b[0m\n",
      "regularization_factors, val_score: 0.383093:  80%|########  | 16/20 [00:08<00:02,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.326936\tVal's binary_logloss: 0.385778\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383093:  85%|########5 | 17/20 [00:08<00:01,  1.81it/s]\u001b[32m[I 2022-09-14 22:33:26,576]\u001b[0m Trial 59 finished with value: 0.38677692150237775 and parameters: {'lambda_l1': 0.0012209981253341032, 'lambda_l2': 0.015308828994699434}. Best is trial 57 with value: 0.3830932657972586.\u001b[0m\n",
      "regularization_factors, val_score: 0.383093:  85%|########5 | 17/20 [00:08<00:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.313393\tVal's binary_logloss: 0.386777\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383093:  90%|######### | 18/20 [00:09<00:01,  1.78it/s]\u001b[32m[I 2022-09-14 22:33:27,162]\u001b[0m Trial 60 finished with value: 0.38792236106788797 and parameters: {'lambda_l1': 0.3998653120589364, 'lambda_l2': 9.438368580732337}. Best is trial 57 with value: 0.3830932657972586.\u001b[0m\n",
      "regularization_factors, val_score: 0.383093:  90%|######### | 18/20 [00:09<00:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.335307\tVal's binary_logloss: 0.387922\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383093:  95%|#########5| 19/20 [00:10<00:00,  1.77it/s]\u001b[32m[I 2022-09-14 22:33:27,727]\u001b[0m Trial 61 finished with value: 0.3854728623355808 and parameters: {'lambda_l1': 1.3162061274803975e-05, 'lambda_l2': 4.432995888059442e-06}. Best is trial 57 with value: 0.3830932657972586.\u001b[0m\n",
      "regularization_factors, val_score: 0.383093:  95%|#########5| 19/20 [00:10<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.314994\tVal's binary_logloss: 0.385473\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.383093: 100%|##########| 20/20 [00:10<00:00,  1.79it/s]\u001b[32m[I 2022-09-14 22:33:28,274]\u001b[0m Trial 62 finished with value: 0.3855574057597964 and parameters: {'lambda_l1': 0.0014692084373295004, 'lambda_l2': 0.6076356488668043}. Best is trial 57 with value: 0.3830932657972586.\u001b[0m\n",
      "regularization_factors, val_score: 0.383093: 100%|##########| 20/20 [00:10<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.3168\tVal's binary_logloss: 0.385557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.383093:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.383093:  20%|##        | 1/5 [00:00<00:02,  1.84it/s]\u001b[32m[I 2022-09-14 22:33:28,827]\u001b[0m Trial 63 finished with value: 0.39215790463726646 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.39215790463726646.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.383093:  20%|##        | 1/5 [00:00<00:02,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.330364\tVal's binary_logloss: 0.392158\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.383093:  40%|####      | 2/5 [00:01<00:01,  1.81it/s]\u001b[32m[I 2022-09-14 22:33:29,384]\u001b[0m Trial 64 finished with value: 0.3848628041959437 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.3848628041959437.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.383093:  40%|####      | 2/5 [00:01<00:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.322566\tVal's binary_logloss: 0.384863\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.382835:  60%|######    | 3/5 [00:01<00:01,  1.82it/s]\u001b[32m[I 2022-09-14 22:33:29,934]\u001b[0m Trial 65 finished with value: 0.3828353542243805 and parameters: {'min_child_samples': 10}. Best is trial 65 with value: 0.3828353542243805.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.382835:  60%|######    | 3/5 [00:01<00:01,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.320289\tVal's binary_logloss: 0.382835\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.382835:  80%|########  | 4/5 [00:02<00:00,  1.84it/s]\u001b[32m[I 2022-09-14 22:33:30,465]\u001b[0m Trial 66 finished with value: 0.3855001190157409 and parameters: {'min_child_samples': 5}. Best is trial 65 with value: 0.3828353542243805.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.382835:  80%|########  | 4/5 [00:02<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.322172\tVal's binary_logloss: 0.3855\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.382835: 100%|##########| 5/5 [00:02<00:00,  1.57it/s]\u001b[32m[I 2022-09-14 22:33:31,273]\u001b[0m Trial 67 finished with value: 0.386289968821277 and parameters: {'min_child_samples': 25}. Best is trial 65 with value: 0.3828353542243805.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.382835: 100%|##########| 5/5 [00:02<00:00,  1.67it/s]\n",
      "\u001b[32m[I 2022-09-14 22:33:31,291]\u001b[0m A new study created in memory with name: no-name-972dd176-e424-4546-8551-3fbab374fc6b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.321232\tVal's binary_logloss: 0.38629\n",
      "fold 0/acc: 0.8223116733755031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "feature_fraction, val_score: 0.388463:  14%|#4        | 1/7 [00:01<00:10,  1.67s/it]\u001b[32m[I 2022-09-14 22:33:32,971]\u001b[0m Trial 0 finished with value: 0.3884625481285006 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.3884625481285006.\u001b[0m\n",
      "feature_fraction, val_score: 0.388463:  14%|#4        | 1/7 [00:01<00:10,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.271142\tVal's binary_logloss: 0.388463\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382242:  29%|##8       | 2/7 [00:03<00:07,  1.56s/it]\u001b[32m[I 2022-09-14 22:33:34,453]\u001b[0m Trial 1 finished with value: 0.3822418932034389 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.3822418932034389.\u001b[0m\n",
      "feature_fraction, val_score: 0.382242:  29%|##8       | 2/7 [00:03<00:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.260123\tVal's binary_logloss: 0.382242\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382242:  43%|####2     | 3/7 [00:04<00:05,  1.48s/it]\u001b[32m[I 2022-09-14 22:33:35,839]\u001b[0m Trial 2 finished with value: 0.3859789385870046 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.3822418932034389.\u001b[0m\n",
      "feature_fraction, val_score: 0.382242:  43%|####2     | 3/7 [00:04<00:05,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.252094\tVal's binary_logloss: 0.385979\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382242:  57%|#####7    | 4/7 [00:05<00:03,  1.30s/it]\u001b[32m[I 2022-09-14 22:33:36,861]\u001b[0m Trial 3 finished with value: 0.3859240199580536 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.3822418932034389.\u001b[0m\n",
      "feature_fraction, val_score: 0.382242:  57%|#####7    | 4/7 [00:05<00:03,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.264238\tVal's binary_logloss: 0.385924\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382242:  71%|#######1  | 5/7 [00:06<00:02,  1.22s/it]\u001b[32m[I 2022-09-14 22:33:37,951]\u001b[0m Trial 4 finished with value: 0.39642810268211387 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.3822418932034389.\u001b[0m\n",
      "feature_fraction, val_score: 0.382242:  71%|#######1  | 5/7 [00:06<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.285683\tVal's binary_logloss: 0.396428\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382242:  86%|########5 | 6/7 [00:07<00:01,  1.09s/it]\u001b[32m[I 2022-09-14 22:33:38,792]\u001b[0m Trial 5 finished with value: 0.3839824465170222 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.3822418932034389.\u001b[0m\n",
      "feature_fraction, val_score: 0.382242:  86%|########5 | 6/7 [00:07<00:01,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255456\tVal's binary_logloss: 0.383982\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382242: 100%|##########| 7/7 [00:08<00:00,  1.10s/it]\u001b[32m[I 2022-09-14 22:33:39,916]\u001b[0m Trial 6 finished with value: 0.3841922066111092 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.3822418932034389.\u001b[0m\n",
      "feature_fraction, val_score: 0.382242: 100%|##########| 7/7 [00:08<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255983\tVal's binary_logloss: 0.384192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382242:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382242:   5%|5         | 1/20 [00:03<01:07,  3.54s/it]\u001b[32m[I 2022-09-14 22:33:43,461]\u001b[0m Trial 7 finished with value: 0.3907472219590968 and parameters: {'num_leaves': 81}. Best is trial 7 with value: 0.3907472219590968.\u001b[0m\n",
      "num_leaves, val_score: 0.382242:   5%|5         | 1/20 [00:03<01:07,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.168535\tVal's binary_logloss: 0.390747\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382242:  10%|#         | 2/20 [00:07<01:12,  4.04s/it]\u001b[32m[I 2022-09-14 22:33:47,860]\u001b[0m Trial 8 finished with value: 0.39262129265191026 and parameters: {'num_leaves': 167}. Best is trial 7 with value: 0.3907472219590968.\u001b[0m\n",
      "num_leaves, val_score: 0.382242:  10%|#         | 2/20 [00:07<01:12,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's binary_logloss: 0.197715\tVal's binary_logloss: 0.392621\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379693:  15%|#5        | 3/20 [00:08<00:45,  2.66s/it]\u001b[32m[I 2022-09-14 22:33:48,880]\u001b[0m Trial 9 finished with value: 0.3796929408450787 and parameters: {'num_leaves': 36}. Best is trial 9 with value: 0.3796929408450787.\u001b[0m\n",
      "num_leaves, val_score: 0.379693:  15%|#5        | 3/20 [00:08<00:45,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.247412\tVal's binary_logloss: 0.379693\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379693:  20%|##        | 4/20 [00:12<00:45,  2.86s/it]\u001b[32m[I 2022-09-14 22:33:52,052]\u001b[0m Trial 10 finished with value: 0.389721809691817 and parameters: {'num_leaves': 142}. Best is trial 9 with value: 0.3796929408450787.\u001b[0m\n",
      "num_leaves, val_score: 0.379693:  20%|##        | 4/20 [00:12<00:45,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's binary_logloss: 0.20559\tVal's binary_logloss: 0.389722\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379693:  25%|##5       | 5/20 [00:15<00:48,  3.21s/it]\u001b[32m[I 2022-09-14 22:33:55,880]\u001b[0m Trial 11 finished with value: 0.3980324096660948 and parameters: {'num_leaves': 200}. Best is trial 9 with value: 0.3796929408450787.\u001b[0m\n",
      "num_leaves, val_score: 0.379693:  25%|##5       | 5/20 [00:15<00:48,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's binary_logloss: 0.192356\tVal's binary_logloss: 0.398032\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379693:  30%|###       | 6/20 [00:18<00:41,  3.00s/it]\u001b[32m[I 2022-09-14 22:33:58,466]\u001b[0m Trial 12 finished with value: 0.3916217038625009 and parameters: {'num_leaves': 132}. Best is trial 9 with value: 0.3796929408450787.\u001b[0m\n",
      "num_leaves, val_score: 0.379693:  30%|###       | 6/20 [00:18<00:41,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's binary_logloss: 0.214784\tVal's binary_logloss: 0.391622\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379693:  35%|###5      | 7/20 [00:19<00:29,  2.25s/it]\u001b[32m[I 2022-09-14 22:33:59,183]\u001b[0m Trial 13 finished with value: 0.3832537442443472 and parameters: {'num_leaves': 27}. Best is trial 9 with value: 0.3796929408450787.\u001b[0m\n",
      "num_leaves, val_score: 0.379693:  35%|###5      | 7/20 [00:19<00:29,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.275311\tVal's binary_logloss: 0.383254\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379693:  40%|####      | 8/20 [00:22<00:30,  2.51s/it]\u001b[32m[I 2022-09-14 22:34:02,240]\u001b[0m Trial 14 finished with value: 0.39552156023137014 and parameters: {'num_leaves': 168}. Best is trial 9 with value: 0.3796929408450787.\u001b[0m\n",
      "num_leaves, val_score: 0.379693:  40%|####      | 8/20 [00:22<00:30,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tTrain's binary_logloss: 0.207933\tVal's binary_logloss: 0.395522\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637:  45%|####5     | 9/20 [00:23<00:22,  2.03s/it]\u001b[32m[I 2022-09-14 22:34:03,225]\u001b[0m Trial 15 finished with value: 0.37963743347969936 and parameters: {'num_leaves': 38}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  45%|####5     | 9/20 [00:23<00:22,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.242261\tVal's binary_logloss: 0.379637\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637:  50%|#####     | 10/20 [00:27<00:27,  2.78s/it]\u001b[32m[I 2022-09-14 22:34:07,665]\u001b[0m Trial 16 finished with value: 0.394509898060851 and parameters: {'num_leaves': 220}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  50%|#####     | 10/20 [00:27<00:27,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's binary_logloss: 0.189277\tVal's binary_logloss: 0.39451\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637:  55%|#####5    | 11/20 [00:29<00:22,  2.51s/it]\u001b[32m[I 2022-09-14 22:34:09,582]\u001b[0m Trial 17 finished with value: 0.3932971275067275 and parameters: {'num_leaves': 77}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  55%|#####5    | 11/20 [00:29<00:22,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.1716\tVal's binary_logloss: 0.393297\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637:  60%|######    | 12/20 [00:30<00:16,  2.00s/it]\u001b[32m[I 2022-09-14 22:34:10,424]\u001b[0m Trial 18 finished with value: 0.3808860471882018 and parameters: {'num_leaves': 30}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  60%|######    | 12/20 [00:30<00:16,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.264816\tVal's binary_logloss: 0.380886\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637:  65%|######5   | 13/20 [00:32<00:13,  1.96s/it]\u001b[32m[I 2022-09-14 22:34:12,275]\u001b[0m Trial 19 finished with value: 0.39368960859387164 and parameters: {'num_leaves': 74}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  70%|#######   | 14/20 [00:32<00:08,  1.42s/it]\u001b[32m[I 2022-09-14 22:34:12,444]\u001b[0m Trial 20 finished with value: 0.49550749719356957 and parameters: {'num_leaves': 2}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  70%|#######   | 14/20 [00:32<00:08,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.176475\tVal's binary_logloss: 0.39369\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.477895\tVal's binary_logloss: 0.495507\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637:  75%|#######5  | 15/20 [00:34<00:07,  1.57s/it]\u001b[32m[I 2022-09-14 22:34:14,364]\u001b[0m Trial 21 finished with value: 0.3849861049154697 and parameters: {'num_leaves': 53}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  75%|#######5  | 15/20 [00:34<00:07,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.211117\tVal's binary_logloss: 0.384986\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637:  80%|########  | 16/20 [00:36<00:07,  1.85s/it]\u001b[32m[I 2022-09-14 22:34:16,863]\u001b[0m Trial 22 finished with value: 0.40034647198777995 and parameters: {'num_leaves': 107}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  80%|########  | 16/20 [00:36<00:07,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.138851\tVal's binary_logloss: 0.400346\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637:  85%|########5 | 17/20 [00:37<00:04,  1.38s/it]\u001b[32m[I 2022-09-14 22:34:17,144]\u001b[0m Trial 23 finished with value: 0.4110449156009201 and parameters: {'num_leaves': 5}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  85%|########5 | 17/20 [00:37<00:04,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.388509\tVal's binary_logloss: 0.411045\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637:  90%|######### | 18/20 [00:38<00:02,  1.35s/it]\u001b[32m[I 2022-09-14 22:34:18,422]\u001b[0m Trial 24 finished with value: 0.3799664225090614 and parameters: {'num_leaves': 49}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  90%|######### | 18/20 [00:38<00:02,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.218236\tVal's binary_logloss: 0.379966\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637:  95%|#########5| 19/20 [00:40<00:01,  1.66s/it]\u001b[32m[I 2022-09-14 22:34:20,815]\u001b[0m Trial 25 finished with value: 0.38840420739832593 and parameters: {'num_leaves': 108}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637:  95%|#########5| 19/20 [00:40<00:01,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's binary_logloss: 0.228844\tVal's binary_logloss: 0.388404\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379637: 100%|##########| 20/20 [00:45<00:00,  2.61s/it]\u001b[32m[I 2022-09-14 22:34:25,629]\u001b[0m Trial 26 finished with value: 0.39554018451209794 and parameters: {'num_leaves': 254}. Best is trial 15 with value: 0.37963743347969936.\u001b[0m\n",
      "num_leaves, val_score: 0.379637: 100%|##########| 20/20 [00:45<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's binary_logloss: 0.183566\tVal's binary_logloss: 0.39554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637:  10%|#         | 1/10 [00:01<00:09,  1.00s/it]\u001b[32m[I 2022-09-14 22:34:26,637]\u001b[0m Trial 27 finished with value: 0.38816595149756666 and parameters: {'bagging_fraction': 0.6865777802881493, 'bagging_freq': 4}. Best is trial 27 with value: 0.38816595149756666.\u001b[0m\n",
      "bagging, val_score: 0.379637:  10%|#         | 1/10 [00:01<00:09,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.242875\tVal's binary_logloss: 0.388166\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637:  20%|##        | 2/10 [00:02<00:08,  1.03s/it]\u001b[32m[I 2022-09-14 22:34:27,683]\u001b[0m Trial 28 finished with value: 0.3941887145293042 and parameters: {'bagging_fraction': 0.617700305406852, 'bagging_freq': 7}. Best is trial 27 with value: 0.38816595149756666.\u001b[0m\n",
      "bagging, val_score: 0.379637:  20%|##        | 2/10 [00:02<00:08,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.244854\tVal's binary_logloss: 0.394189\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637:  30%|###       | 3/10 [00:03<00:07,  1.06s/it]\u001b[32m[I 2022-09-14 22:34:28,780]\u001b[0m Trial 29 finished with value: 0.3796447819621304 and parameters: {'bagging_fraction': 0.7869154178963602, 'bagging_freq': 1}. Best is trial 29 with value: 0.3796447819621304.\u001b[0m\n",
      "bagging, val_score: 0.379637:  30%|###       | 3/10 [00:03<00:07,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.238864\tVal's binary_logloss: 0.379645\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637:  40%|####      | 4/10 [00:04<00:06,  1.05s/it]\u001b[32m[I 2022-09-14 22:34:29,821]\u001b[0m Trial 30 finished with value: 0.39845302720725556 and parameters: {'bagging_fraction': 0.49891904789893066, 'bagging_freq': 7}. Best is trial 29 with value: 0.3796447819621304.\u001b[0m\n",
      "bagging, val_score: 0.379637:  40%|####      | 4/10 [00:04<00:06,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.251757\tVal's binary_logloss: 0.398453\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637:  50%|#####     | 5/10 [00:05<00:05,  1.04s/it]\u001b[32m[I 2022-09-14 22:34:30,828]\u001b[0m Trial 31 finished with value: 0.38757468985082294 and parameters: {'bagging_fraction': 0.7449421512968859, 'bagging_freq': 4}. Best is trial 29 with value: 0.3796447819621304.\u001b[0m\n",
      "bagging, val_score: 0.379637:  50%|#####     | 5/10 [00:05<00:05,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.243279\tVal's binary_logloss: 0.387575\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637:  60%|######    | 6/10 [00:06<00:04,  1.03s/it]\u001b[32m[I 2022-09-14 22:34:31,842]\u001b[0m Trial 32 finished with value: 0.39633244316778915 and parameters: {'bagging_fraction': 0.4914070588781051, 'bagging_freq': 1}. Best is trial 29 with value: 0.3796447819621304.\u001b[0m\n",
      "bagging, val_score: 0.379637:  60%|######    | 6/10 [00:06<00:04,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.249132\tVal's binary_logloss: 0.396332\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637:  70%|#######   | 7/10 [00:07<00:03,  1.03s/it]\u001b[32m[I 2022-09-14 22:34:32,873]\u001b[0m Trial 33 finished with value: 0.3846634954664718 and parameters: {'bagging_fraction': 0.8907741551940884, 'bagging_freq': 5}. Best is trial 29 with value: 0.3796447819621304.\u001b[0m\n",
      "bagging, val_score: 0.379637:  70%|#######   | 7/10 [00:07<00:03,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.240509\tVal's binary_logloss: 0.384663\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637:  80%|########  | 8/10 [00:08<00:02,  1.02s/it]\u001b[32m[I 2022-09-14 22:34:33,877]\u001b[0m Trial 34 finished with value: 0.3886926742798325 and parameters: {'bagging_fraction': 0.6442778533387303, 'bagging_freq': 3}. Best is trial 29 with value: 0.3796447819621304.\u001b[0m\n",
      "bagging, val_score: 0.379637:  80%|########  | 8/10 [00:08<00:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.244188\tVal's binary_logloss: 0.388693\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637:  90%|######### | 9/10 [00:09<00:01,  1.02s/it]\u001b[32m[I 2022-09-14 22:34:34,900]\u001b[0m Trial 35 finished with value: 0.4002325346494177 and parameters: {'bagging_fraction': 0.4776807483535833, 'bagging_freq': 7}. Best is trial 29 with value: 0.3796447819621304.\u001b[0m\n",
      "bagging, val_score: 0.379637:  90%|######### | 9/10 [00:09<00:01,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.251652\tVal's binary_logloss: 0.400233\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379637: 100%|##########| 10/10 [00:10<00:00,  1.02s/it]\u001b[32m[I 2022-09-14 22:34:35,914]\u001b[0m Trial 36 finished with value: 0.3879007381976601 and parameters: {'bagging_fraction': 0.5633856329745629, 'bagging_freq': 1}. Best is trial 29 with value: 0.3796447819621304.\u001b[0m\n",
      "bagging, val_score: 0.379637: 100%|##########| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.244535\tVal's binary_logloss: 0.387901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.379637:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.379637:  17%|#6        | 1/6 [00:00<00:04,  1.01it/s]\u001b[32m[I 2022-09-14 22:34:36,913]\u001b[0m Trial 37 finished with value: 0.3814820216699349 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 37 with value: 0.3814820216699349.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.379637:  17%|#6        | 1/6 [00:00<00:04,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.237418\tVal's binary_logloss: 0.381482\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.379637:  33%|###3      | 2/6 [00:02<00:04,  1.04s/it]\u001b[32m[I 2022-09-14 22:34:37,996]\u001b[0m Trial 38 finished with value: 0.38116063096056896 and parameters: {'feature_fraction': 0.62}. Best is trial 38 with value: 0.38116063096056896.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.379637:  33%|###3      | 2/6 [00:02<00:04,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.244103\tVal's binary_logloss: 0.381161\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.379637:  50%|#####     | 3/6 [00:03<00:03,  1.02s/it]\u001b[32m[I 2022-09-14 22:34:38,997]\u001b[0m Trial 39 finished with value: 0.3814820216699349 and parameters: {'feature_fraction': 0.748}. Best is trial 38 with value: 0.38116063096056896.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.379637:  50%|#####     | 3/6 [00:03<00:03,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.237418\tVal's binary_logloss: 0.381482\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.379637:  67%|######6   | 4/6 [00:04<00:02,  1.03s/it]\u001b[32m[I 2022-09-14 22:34:40,025]\u001b[0m Trial 40 finished with value: 0.37963743347969936 and parameters: {'feature_fraction': 0.716}. Best is trial 40 with value: 0.37963743347969936.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.379637:  67%|######6   | 4/6 [00:04<00:02,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.242261\tVal's binary_logloss: 0.379637\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.379637:  83%|########3 | 5/6 [00:05<00:01,  1.02s/it]\u001b[32m[I 2022-09-14 22:34:41,048]\u001b[0m Trial 41 finished with value: 0.37963743347969936 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 40 with value: 0.37963743347969936.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.379637:  83%|########3 | 5/6 [00:05<00:01,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.242261\tVal's binary_logloss: 0.379637\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.379637: 100%|##########| 6/6 [00:06<00:00,  1.04s/it]\u001b[32m[I 2022-09-14 22:34:42,119]\u001b[0m Trial 42 finished with value: 0.38116063096056896 and parameters: {'feature_fraction': 0.652}. Best is trial 40 with value: 0.37963743347969936.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.379637: 100%|##########| 6/6 [00:06<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.244103\tVal's binary_logloss: 0.381161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379637:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379637:   5%|5         | 1/20 [00:01<00:20,  1.05s/it]\u001b[32m[I 2022-09-14 22:34:43,181]\u001b[0m Trial 43 finished with value: 0.38054375188478406 and parameters: {'lambda_l1': 0.5430066306792094, 'lambda_l2': 3.8406974798097}. Best is trial 43 with value: 0.38054375188478406.\u001b[0m\n",
      "regularization_factors, val_score: 0.379637:   5%|5         | 1/20 [00:01<00:20,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.270862\tVal's binary_logloss: 0.380544\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376672:  10%|#         | 2/20 [00:02<00:18,  1.03s/it]\u001b[32m[I 2022-09-14 22:34:44,190]\u001b[0m Trial 44 finished with value: 0.3766723597922473 and parameters: {'lambda_l1': 8.52015047314107e-06, 'lambda_l2': 0.0009409146319696028}. Best is trial 44 with value: 0.3766723597922473.\u001b[0m\n",
      "regularization_factors, val_score: 0.376672:  10%|#         | 2/20 [00:02<00:18,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.242649\tVal's binary_logloss: 0.376672\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376672:  15%|#5        | 3/20 [00:03<00:17,  1.03s/it]\u001b[32m[I 2022-09-14 22:34:45,231]\u001b[0m Trial 45 finished with value: 0.3774989314496015 and parameters: {'lambda_l1': 3.1316534725619418e-06, 'lambda_l2': 0.0001835546943335254}. Best is trial 44 with value: 0.3766723597922473.\u001b[0m\n",
      "regularization_factors, val_score: 0.376672:  15%|#5        | 3/20 [00:03<00:17,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.245203\tVal's binary_logloss: 0.377499\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  20%|##        | 4/20 [00:04<00:16,  1.04s/it]\u001b[32m[I 2022-09-14 22:34:46,274]\u001b[0m Trial 46 finished with value: 0.3763340002732849 and parameters: {'lambda_l1': 0.0034767094373132092, 'lambda_l2': 0.00355470825264957}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  20%|##        | 4/20 [00:04<00:16,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.24254\tVal's binary_logloss: 0.376334\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  25%|##5       | 5/20 [00:05<00:15,  1.04s/it]\u001b[32m[I 2022-09-14 22:34:47,324]\u001b[0m Trial 47 finished with value: 0.38096053161544907 and parameters: {'lambda_l1': 0.06839136817863944, 'lambda_l2': 1.8362058896720086}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  25%|##5       | 5/20 [00:05<00:15,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.257727\tVal's binary_logloss: 0.380961\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  30%|###       | 6/20 [00:06<00:14,  1.05s/it]\u001b[32m[I 2022-09-14 22:34:48,394]\u001b[0m Trial 48 finished with value: 0.38502373457742767 and parameters: {'lambda_l1': 1.348795509180035, 'lambda_l2': 0.7306132144084652}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  30%|###       | 6/20 [00:06<00:14,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.26307\tVal's binary_logloss: 0.385024\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  35%|###5      | 7/20 [00:07<00:13,  1.04s/it]\u001b[32m[I 2022-09-14 22:34:49,421]\u001b[0m Trial 49 finished with value: 0.3795292186144736 and parameters: {'lambda_l1': 6.578970091899109e-08, 'lambda_l2': 2.3045821143868482e-08}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  35%|###5      | 7/20 [00:07<00:13,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.242261\tVal's binary_logloss: 0.379529\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  40%|####      | 8/20 [00:08<00:12,  1.03s/it]\u001b[32m[I 2022-09-14 22:34:50,431]\u001b[0m Trial 50 finished with value: 0.3793501369485415 and parameters: {'lambda_l1': 4.4902994580584094e-05, 'lambda_l2': 0.00014188798680996558}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  40%|####      | 8/20 [00:08<00:12,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.24434\tVal's binary_logloss: 0.37935\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  45%|####5     | 9/20 [00:09<00:11,  1.03s/it]\u001b[32m[I 2022-09-14 22:34:51,452]\u001b[0m Trial 51 finished with value: 0.37936834734805214 and parameters: {'lambda_l1': 6.606303075305066e-07, 'lambda_l2': 5.14445707800427e-05}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  45%|####5     | 9/20 [00:09<00:11,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.242262\tVal's binary_logloss: 0.379368\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  50%|#####     | 10/20 [00:10<00:10,  1.07s/it]\u001b[32m[I 2022-09-14 22:34:52,599]\u001b[0m Trial 52 finished with value: 0.3837209477804125 and parameters: {'lambda_l1': 0.6046321864495836, 'lambda_l2': 1.1581580347402172e-06}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  50%|#####     | 10/20 [00:10<00:10,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.250904\tVal's binary_logloss: 0.383721\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  55%|#####5    | 11/20 [00:11<00:09,  1.06s/it]\u001b[32m[I 2022-09-14 22:34:53,648]\u001b[0m Trial 53 finished with value: 0.376448235137557 and parameters: {'lambda_l1': 0.0033943031114590703, 'lambda_l2': 0.02896251229315096}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  55%|#####5    | 11/20 [00:11<00:09,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.241741\tVal's binary_logloss: 0.376448\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  60%|######    | 12/20 [00:12<00:08,  1.05s/it]\u001b[32m[I 2022-09-14 22:34:54,668]\u001b[0m Trial 54 finished with value: 0.38147825027013904 and parameters: {'lambda_l1': 0.003052905232151587, 'lambda_l2': 0.021952390015295753}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  60%|######    | 12/20 [00:12<00:08,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.244363\tVal's binary_logloss: 0.381478\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  65%|######5   | 13/20 [00:13<00:07,  1.07s/it]\u001b[32m[I 2022-09-14 22:34:55,775]\u001b[0m Trial 55 finished with value: 0.3819277108120023 and parameters: {'lambda_l1': 0.0017304080550863549, 'lambda_l2': 0.053989857742438925}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  65%|######5   | 13/20 [00:13<00:07,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.24313\tVal's binary_logloss: 0.381928\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  70%|#######   | 14/20 [00:14<00:06,  1.04s/it]\u001b[32m[I 2022-09-14 22:34:56,767]\u001b[0m Trial 56 finished with value: 0.37704309161367505 and parameters: {'lambda_l1': 0.01607445638126844, 'lambda_l2': 0.00915924860843916}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  70%|#######   | 14/20 [00:14<00:06,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.242882\tVal's binary_logloss: 0.377043\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  75%|#######5  | 15/20 [00:15<00:05,  1.03s/it]\u001b[32m[I 2022-09-14 22:34:57,765]\u001b[0m Trial 57 finished with value: 0.3800395421508924 and parameters: {'lambda_l1': 0.0002807237645764126, 'lambda_l2': 4.92488286125438e-06}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  75%|#######5  | 15/20 [00:15<00:05,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.24212\tVal's binary_logloss: 0.38004\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  80%|########  | 16/20 [00:16<00:03,  1.01it/s]\u001b[32m[I 2022-09-14 22:34:58,664]\u001b[0m Trial 58 finished with value: 0.3959932424174005 and parameters: {'lambda_l1': 9.651898315377062, 'lambda_l2': 0.12227169396951432}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  80%|########  | 16/20 [00:16<00:03,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.340017\tVal's binary_logloss: 0.395993\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  85%|########5 | 17/20 [00:17<00:02,  1.02it/s]\u001b[32m[I 2022-09-14 22:34:59,634]\u001b[0m Trial 59 finished with value: 0.3857982838358715 and parameters: {'lambda_l1': 0.0001669581447489763, 'lambda_l2': 0.0017349996346246782}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  85%|########5 | 17/20 [00:17<00:02,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.244945\tVal's binary_logloss: 0.385798\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  90%|######### | 18/20 [00:18<00:02,  1.11s/it]\u001b[32m[I 2022-09-14 22:35:01,034]\u001b[0m Trial 60 finished with value: 0.38285094264425706 and parameters: {'lambda_l1': 0.020865566632328275, 'lambda_l2': 0.25644027572139216}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  90%|######### | 18/20 [00:18<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.246336\tVal's binary_logloss: 0.382851\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334:  95%|#########5| 19/20 [00:20<00:01,  1.11s/it]\u001b[32m[I 2022-09-14 22:35:02,131]\u001b[0m Trial 61 finished with value: 0.38030931585012095 and parameters: {'lambda_l1': 0.0022954326368728674, 'lambda_l2': 0.004649450310464128}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334:  95%|#########5| 19/20 [00:20<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.242227\tVal's binary_logloss: 0.380309\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376334: 100%|##########| 20/20 [00:21<00:00,  1.08s/it]\u001b[32m[I 2022-09-14 22:35:03,156]\u001b[0m Trial 62 finished with value: 0.3795253711833156 and parameters: {'lambda_l1': 1.3428535162145146e-08, 'lambda_l2': 3.5802418078234013e-06}. Best is trial 46 with value: 0.3763340002732849.\u001b[0m\n",
      "regularization_factors, val_score: 0.376334: 100%|##########| 20/20 [00:21<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.242261\tVal's binary_logloss: 0.379525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.376334:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.376334:  20%|##        | 1/5 [00:00<00:03,  1.00it/s]\u001b[32m[I 2022-09-14 22:35:04,163]\u001b[0m Trial 63 finished with value: 0.38083815584509045 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.38083815584509045.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.376334:  20%|##        | 1/5 [00:01<00:03,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.270061\tVal's binary_logloss: 0.380838\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.376334:  40%|####      | 2/5 [00:02<00:03,  1.03s/it]\u001b[32m[I 2022-09-14 22:35:05,214]\u001b[0m Trial 64 finished with value: 0.3846919456360011 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.38083815584509045.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.376334:  40%|####      | 2/5 [00:02<00:03,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.245024\tVal's binary_logloss: 0.384692\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.376334:  60%|######    | 3/5 [00:03<00:02,  1.03s/it]\u001b[32m[I 2022-09-14 22:35:06,254]\u001b[0m Trial 65 finished with value: 0.3822048613181837 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.38083815584509045.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.376334:  60%|######    | 3/5 [00:03<00:02,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.237602\tVal's binary_logloss: 0.382205\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.376334:  80%|########  | 4/5 [00:04<00:01,  1.04s/it]\u001b[32m[I 2022-09-14 22:35:07,309]\u001b[0m Trial 66 finished with value: 0.3875955429566691 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.38083815584509045.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.376334:  80%|########  | 4/5 [00:04<00:01,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.254946\tVal's binary_logloss: 0.387596\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.376334: 100%|##########| 5/5 [00:05<00:00,  1.09s/it]\u001b[32m[I 2022-09-14 22:35:08,481]\u001b[0m Trial 67 finished with value: 0.37781378935651544 and parameters: {'min_child_samples': 5}. Best is trial 67 with value: 0.37781378935651544.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.376334: 100%|##########| 5/5 [00:05<00:00,  1.06s/it]\n",
      "\u001b[32m[I 2022-09-14 22:35:08,493]\u001b[0m A new study created in memory with name: no-name-a8b6e49b-67c8-4de6-81fa-2e5c0d7bd5c8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.235802\tVal's binary_logloss: 0.377814\n",
      "fold 1/acc: 0.8090856814261069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "feature_fraction, val_score: 0.385531:  14%|#4        | 1/7 [00:00<00:05,  1.13it/s]\u001b[32m[I 2022-09-14 22:35:09,385]\u001b[0m Trial 0 finished with value: 0.3855311235167824 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.3855311235167824.\u001b[0m\n",
      "feature_fraction, val_score: 0.385531:  14%|#4        | 1/7 [00:00<00:05,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.260898\tVal's binary_logloss: 0.385531\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382959:  29%|##8       | 2/7 [00:01<00:04,  1.11it/s]\u001b[32m[I 2022-09-14 22:35:10,297]\u001b[0m Trial 1 finished with value: 0.3829591044492006 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.3829591044492006.\u001b[0m\n",
      "feature_fraction, val_score: 0.382959:  29%|##8       | 2/7 [00:01<00:04,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.263847\tVal's binary_logloss: 0.382959\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382959:  43%|####2     | 3/7 [00:02<00:03,  1.14it/s]\u001b[32m[I 2022-09-14 22:35:11,151]\u001b[0m Trial 2 finished with value: 0.38725686927937153 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.3829591044492006.\u001b[0m\n",
      "feature_fraction, val_score: 0.382959:  43%|####2     | 3/7 [00:02<00:03,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.256643\tVal's binary_logloss: 0.387257\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382959:  57%|#####7    | 4/7 [00:03<00:02,  1.09it/s]\u001b[32m[I 2022-09-14 22:35:12,123]\u001b[0m Trial 3 finished with value: 0.394081813216954 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.3829591044492006.\u001b[0m\n",
      "feature_fraction, val_score: 0.382959:  57%|#####7    | 4/7 [00:03<00:02,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.284841\tVal's binary_logloss: 0.394082\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382959:  71%|#######1  | 5/7 [00:04<00:01,  1.12it/s]\u001b[32m[I 2022-09-14 22:35:12,974]\u001b[0m Trial 4 finished with value: 0.3872752304760092 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.3829591044492006.\u001b[0m\n",
      "feature_fraction, val_score: 0.382959:  71%|#######1  | 5/7 [00:04<00:01,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.257344\tVal's binary_logloss: 0.387275\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382959:  86%|########5 | 6/7 [00:05<00:00,  1.07it/s]\u001b[32m[I 2022-09-14 22:35:13,995]\u001b[0m Trial 5 finished with value: 0.38755445498853197 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.3829591044492006.\u001b[0m\n",
      "feature_fraction, val_score: 0.382959:  86%|########5 | 6/7 [00:05<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.27061\tVal's binary_logloss: 0.387554\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.382959: 100%|##########| 7/7 [00:06<00:00,  1.07it/s]\u001b[32m[I 2022-09-14 22:35:14,917]\u001b[0m Trial 6 finished with value: 0.38729457669459166 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.3829591044492006.\u001b[0m\n",
      "feature_fraction, val_score: 0.382959: 100%|##########| 7/7 [00:06<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.254461\tVal's binary_logloss: 0.387295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382959:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382959:   5%|5         | 1/20 [00:03<01:14,  3.92s/it]\u001b[32m[I 2022-09-14 22:35:18,848]\u001b[0m Trial 7 finished with value: 0.40310220185332424 and parameters: {'num_leaves': 190}. Best is trial 7 with value: 0.40310220185332424.\u001b[0m\n",
      "num_leaves, val_score: 0.382959:   5%|5         | 1/20 [00:03<01:14,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tTrain's binary_logloss: 0.204013\tVal's binary_logloss: 0.403102\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382959:  10%|#         | 2/20 [00:07<01:07,  3.77s/it]\u001b[32m[I 2022-09-14 22:35:22,511]\u001b[0m Trial 8 finished with value: 0.40074695179616043 and parameters: {'num_leaves': 178}. Best is trial 8 with value: 0.40074695179616043.\u001b[0m\n",
      "num_leaves, val_score: 0.382959:  10%|#         | 2/20 [00:07<01:07,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's binary_logloss: 0.180727\tVal's binary_logloss: 0.400747\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382959:  15%|#5        | 3/20 [00:09<00:49,  2.92s/it]\u001b[32m[I 2022-09-14 22:35:24,423]\u001b[0m Trial 9 finished with value: 0.3899931236419723 and parameters: {'num_leaves': 69}. Best is trial 9 with value: 0.3899931236419723.\u001b[0m\n",
      "num_leaves, val_score: 0.382959:  15%|#5        | 3/20 [00:09<00:49,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.185168\tVal's binary_logloss: 0.389993\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382959:  20%|##        | 4/20 [00:13<00:54,  3.39s/it]\u001b[32m[I 2022-09-14 22:35:28,538]\u001b[0m Trial 10 finished with value: 0.3991473409997001 and parameters: {'num_leaves': 228}. Best is trial 9 with value: 0.3899931236419723.\u001b[0m\n",
      "num_leaves, val_score: 0.382959:  20%|##        | 4/20 [00:13<00:54,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tTrain's binary_logloss: 0.211888\tVal's binary_logloss: 0.399147\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382959:  25%|##5       | 5/20 [00:17<00:55,  3.69s/it]\u001b[32m[I 2022-09-14 22:35:32,768]\u001b[0m Trial 11 finished with value: 0.43650020874657186 and parameters: {'num_leaves': 188}. Best is trial 9 with value: 0.3899931236419723.\u001b[0m\n",
      "num_leaves, val_score: 0.382959:  25%|##5       | 5/20 [00:17<00:55,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.091909\tVal's binary_logloss: 0.4365\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382959:  30%|###       | 6/20 [00:19<00:43,  3.10s/it]\u001b[32m[I 2022-09-14 22:35:34,713]\u001b[0m Trial 12 finished with value: 0.392681749131766 and parameters: {'num_leaves': 72}. Best is trial 9 with value: 0.3899931236419723.\u001b[0m\n",
      "num_leaves, val_score: 0.382959:  30%|###       | 6/20 [00:19<00:43,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.179836\tVal's binary_logloss: 0.392682\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382959:  35%|###5      | 7/20 [00:22<00:40,  3.08s/it]\u001b[32m[I 2022-09-14 22:35:37,750]\u001b[0m Trial 13 finished with value: 0.4144147216528558 and parameters: {'num_leaves': 128}. Best is trial 9 with value: 0.3899931236419723.\u001b[0m\n",
      "num_leaves, val_score: 0.382959:  35%|###5      | 7/20 [00:22<00:40,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.121035\tVal's binary_logloss: 0.414415\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.382959:  40%|####      | 8/20 [00:27<00:41,  3.46s/it]\u001b[32m[I 2022-09-14 22:35:42,039]\u001b[0m Trial 14 finished with value: 0.4026290120823359 and parameters: {'num_leaves': 237}. Best is trial 9 with value: 0.3899931236419723.\u001b[0m\n",
      "num_leaves, val_score: 0.382959:  40%|####      | 8/20 [00:27<00:41,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's binary_logloss: 0.207318\tVal's binary_logloss: 0.402629\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  45%|####5     | 9/20 [00:28<00:29,  2.66s/it]\u001b[32m[I 2022-09-14 22:35:42,943]\u001b[0m Trial 15 finished with value: 0.38140889740350664 and parameters: {'num_leaves': 34}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  45%|####5     | 9/20 [00:28<00:29,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381409\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  50%|#####     | 10/20 [00:31<00:27,  2.78s/it]\u001b[32m[I 2022-09-14 22:35:45,992]\u001b[0m Trial 16 finished with value: 0.39628813426957377 and parameters: {'num_leaves': 142}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  50%|#####     | 10/20 [00:31<00:27,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's binary_logloss: 0.209133\tVal's binary_logloss: 0.396288\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  55%|#####5    | 11/20 [00:31<00:19,  2.14s/it]\u001b[32m[I 2022-09-14 22:35:46,660]\u001b[0m Trial 17 finished with value: 0.38522983111366843 and parameters: {'num_leaves': 20}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  55%|#####5    | 11/20 [00:31<00:19,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.303346\tVal's binary_logloss: 0.38523\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  60%|######    | 12/20 [00:32<00:13,  1.68s/it]\u001b[32m[I 2022-09-14 22:35:47,310]\u001b[0m Trial 18 finished with value: 0.38500216268036136 and parameters: {'num_leaves': 21}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  60%|######    | 12/20 [00:32<00:13,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.29767\tVal's binary_logloss: 0.385002\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  65%|######5   | 13/20 [00:32<00:08,  1.28s/it]\u001b[32m[I 2022-09-14 22:35:47,670]\u001b[0m Trial 19 finished with value: 0.3937715986981736 and parameters: {'num_leaves': 9}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  65%|######5   | 13/20 [00:32<00:08,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.355731\tVal's binary_logloss: 0.393772\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  70%|#######   | 14/20 [00:34<00:07,  1.33s/it]\u001b[32m[I 2022-09-14 22:35:49,120]\u001b[0m Trial 20 finished with value: 0.3904095590187542 and parameters: {'num_leaves': 56}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  70%|#######   | 14/20 [00:34<00:07,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.202632\tVal's binary_logloss: 0.39041\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  75%|#######5  | 15/20 [00:35<00:06,  1.35s/it]\u001b[32m[I 2022-09-14 22:35:50,497]\u001b[0m Trial 21 finished with value: 0.3883332035986191 and parameters: {'num_leaves': 47}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  75%|#######5  | 15/20 [00:35<00:06,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.223335\tVal's binary_logloss: 0.388333\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  80%|########  | 16/20 [00:38<00:07,  1.79s/it]\u001b[32m[I 2022-09-14 22:35:53,331]\u001b[0m Trial 22 finished with value: 0.4092436142710858 and parameters: {'num_leaves': 107}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  80%|########  | 16/20 [00:38<00:07,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.14016\tVal's binary_logloss: 0.409244\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  85%|########5 | 17/20 [00:39<00:04,  1.47s/it]\u001b[32m[I 2022-09-14 22:35:54,059]\u001b[0m Trial 23 finished with value: 0.3844130075158558 and parameters: {'num_leaves': 23}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  85%|########5 | 17/20 [00:39<00:04,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.292195\tVal's binary_logloss: 0.384413\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  90%|######### | 18/20 [00:41<00:03,  1.78s/it]\u001b[32m[I 2022-09-14 22:35:56,541]\u001b[0m Trial 24 finished with value: 0.4008932687975731 and parameters: {'num_leaves': 97}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  90%|######### | 18/20 [00:41<00:03,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.148236\tVal's binary_logloss: 0.400893\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409:  95%|#########5| 19/20 [00:42<00:01,  1.54s/it]\u001b[32m[I 2022-09-14 22:35:57,528]\u001b[0m Trial 25 finished with value: 0.38140889740350664 and parameters: {'num_leaves': 34}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409:  95%|#########5| 19/20 [00:42<00:01,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381409\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381409: 100%|##########| 20/20 [00:45<00:00,  1.84s/it]\u001b[32m[I 2022-09-14 22:36:00,076]\u001b[0m Trial 26 finished with value: 0.39867879424102304 and parameters: {'num_leaves': 95}. Best is trial 15 with value: 0.38140889740350664.\u001b[0m\n",
      "num_leaves, val_score: 0.381409: 100%|##########| 20/20 [00:45<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.15137\tVal's binary_logloss: 0.398679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409:  10%|#         | 1/10 [00:01<00:09,  1.04s/it]\u001b[32m[I 2022-09-14 22:36:01,128]\u001b[0m Trial 27 finished with value: 0.38644767769812544 and parameters: {'bagging_fraction': 0.8660485697621751, 'bagging_freq': 2}. Best is trial 27 with value: 0.38644767769812544.\u001b[0m\n",
      "bagging, val_score: 0.381409:  10%|#         | 1/10 [00:01<00:09,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.254237\tVal's binary_logloss: 0.386448\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409:  20%|##        | 2/10 [00:02<00:08,  1.06s/it]\u001b[32m[I 2022-09-14 22:36:02,194]\u001b[0m Trial 28 finished with value: 0.38764053680034594 and parameters: {'bagging_fraction': 0.7497675208806439, 'bagging_freq': 6}. Best is trial 27 with value: 0.38644767769812544.\u001b[0m\n",
      "bagging, val_score: 0.381409:  20%|##        | 2/10 [00:02<00:08,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253665\tVal's binary_logloss: 0.387641\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409:  30%|###       | 3/10 [00:03<00:07,  1.03s/it]\u001b[32m[I 2022-09-14 22:36:03,186]\u001b[0m Trial 29 finished with value: 0.3887289529429636 and parameters: {'bagging_fraction': 0.6666937073965595, 'bagging_freq': 1}. Best is trial 27 with value: 0.38644767769812544.\u001b[0m\n",
      "bagging, val_score: 0.381409:  30%|###       | 3/10 [00:03<00:07,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.252884\tVal's binary_logloss: 0.388729\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409:  40%|####      | 4/10 [00:04<00:06,  1.04s/it]\u001b[32m[I 2022-09-14 22:36:04,246]\u001b[0m Trial 30 finished with value: 0.4033416031898537 and parameters: {'bagging_fraction': 0.4305986988483179, 'bagging_freq': 6}. Best is trial 27 with value: 0.38644767769812544.\u001b[0m\n",
      "bagging, val_score: 0.381409:  40%|####      | 4/10 [00:04<00:06,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.268893\tVal's binary_logloss: 0.403342\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409:  50%|#####     | 5/10 [00:05<00:05,  1.02s/it]\u001b[32m[I 2022-09-14 22:36:05,244]\u001b[0m Trial 31 finished with value: 0.38855102726062396 and parameters: {'bagging_fraction': 0.734815487065015, 'bagging_freq': 3}. Best is trial 27 with value: 0.38644767769812544.\u001b[0m\n",
      "bagging, val_score: 0.381409:  50%|#####     | 5/10 [00:05<00:05,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.256206\tVal's binary_logloss: 0.388551\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409:  60%|######    | 6/10 [00:06<00:04,  1.01s/it]\u001b[32m[I 2022-09-14 22:36:06,221]\u001b[0m Trial 32 finished with value: 0.384055182267394 and parameters: {'bagging_fraction': 0.7279277575664584, 'bagging_freq': 5}. Best is trial 32 with value: 0.384055182267394.\u001b[0m\n",
      "bagging, val_score: 0.381409:  60%|######    | 6/10 [00:06<00:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255398\tVal's binary_logloss: 0.384055\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409:  70%|#######   | 7/10 [00:07<00:03,  1.06s/it]\u001b[32m[I 2022-09-14 22:36:07,378]\u001b[0m Trial 33 finished with value: 0.38801679678886075 and parameters: {'bagging_fraction': 0.7314486692465177, 'bagging_freq': 6}. Best is trial 32 with value: 0.384055182267394.\u001b[0m\n",
      "bagging, val_score: 0.381409:  70%|#######   | 7/10 [00:07<00:03,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255311\tVal's binary_logloss: 0.388017\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409:  80%|########  | 8/10 [00:09<00:02,  1.33s/it]\u001b[32m[I 2022-09-14 22:36:09,297]\u001b[0m Trial 34 finished with value: 0.3900715760906073 and parameters: {'bagging_fraction': 0.7144658026870647, 'bagging_freq': 1}. Best is trial 32 with value: 0.384055182267394.\u001b[0m\n",
      "bagging, val_score: 0.381409:  80%|########  | 8/10 [00:09<00:02,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.254702\tVal's binary_logloss: 0.390072\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409:  90%|######### | 9/10 [00:10<00:01,  1.22s/it]\u001b[32m[I 2022-09-14 22:36:10,283]\u001b[0m Trial 35 finished with value: 0.38582244786609504 and parameters: {'bagging_fraction': 0.4101725132689788, 'bagging_freq': 4}. Best is trial 32 with value: 0.384055182267394.\u001b[0m\n",
      "bagging, val_score: 0.381409:  90%|######### | 9/10 [00:10<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.268861\tVal's binary_logloss: 0.385822\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.381409: 100%|##########| 10/10 [00:11<00:00,  1.14s/it]\u001b[32m[I 2022-09-14 22:36:11,251]\u001b[0m Trial 36 finished with value: 0.39431308750131794 and parameters: {'bagging_fraction': 0.5609667471113822, 'bagging_freq': 4}. Best is trial 32 with value: 0.384055182267394.\u001b[0m\n",
      "bagging, val_score: 0.381409: 100%|##########| 10/10 [00:11<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.261742\tVal's binary_logloss: 0.394313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.381409:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.381409:  17%|#6        | 1/6 [00:01<00:05,  1.00s/it]\u001b[32m[I 2022-09-14 22:36:12,264]\u001b[0m Trial 37 finished with value: 0.3868913165899785 and parameters: {'feature_fraction': 0.52}. Best is trial 37 with value: 0.3868913165899785.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.381409:  17%|#6        | 1/6 [00:01<00:05,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.263902\tVal's binary_logloss: 0.386891\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.381409:  33%|###3      | 2/6 [00:01<00:03,  1.00it/s]\u001b[32m[I 2022-09-14 22:36:13,258]\u001b[0m Trial 38 finished with value: 0.38547436736129176 and parameters: {'feature_fraction': 0.552}. Best is trial 38 with value: 0.38547436736129176.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.381409:  33%|###3      | 2/6 [00:02<00:03,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.258455\tVal's binary_logloss: 0.385474\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.381409:  50%|#####     | 3/6 [00:02<00:02,  1.01it/s]\u001b[32m[I 2022-09-14 22:36:14,228]\u001b[0m Trial 39 finished with value: 0.3857458574932064 and parameters: {'feature_fraction': 0.6799999999999999}. Best is trial 38 with value: 0.38547436736129176.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.381409:  50%|#####     | 3/6 [00:02<00:02,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253783\tVal's binary_logloss: 0.385746\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.381409:  67%|######6   | 4/6 [00:03<00:01,  1.03it/s]\u001b[32m[I 2022-09-14 22:36:15,177]\u001b[0m Trial 40 finished with value: 0.38140889740350664 and parameters: {'feature_fraction': 0.616}. Best is trial 40 with value: 0.38140889740350664.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.381409:  67%|######6   | 4/6 [00:03<00:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381409\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.381409:  83%|########3 | 5/6 [00:04<00:00,  1.03it/s]\u001b[32m[I 2022-09-14 22:36:16,146]\u001b[0m Trial 41 finished with value: 0.38547436736129176 and parameters: {'feature_fraction': 0.584}. Best is trial 40 with value: 0.38140889740350664.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.381409:  83%|########3 | 5/6 [00:04<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.258455\tVal's binary_logloss: 0.385474\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.381409: 100%|##########| 6/6 [00:05<00:00,  1.01it/s]\u001b[32m[I 2022-09-14 22:36:17,172]\u001b[0m Trial 42 finished with value: 0.38140889740350664 and parameters: {'feature_fraction': 0.6479999999999999}. Best is trial 40 with value: 0.38140889740350664.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.381409: 100%|##########| 6/6 [00:05<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381409:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381409:   5%|5         | 1/20 [00:01<00:20,  1.07s/it]\u001b[32m[I 2022-09-14 22:36:18,249]\u001b[0m Trial 43 finished with value: 0.3852329979208653 and parameters: {'lambda_l1': 0.0034028237688921914, 'lambda_l2': 1.9674440996647415e-07}. Best is trial 43 with value: 0.3852329979208653.\u001b[0m\n",
      "regularization_factors, val_score: 0.381409:   5%|5         | 1/20 [00:01<00:20,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255915\tVal's binary_logloss: 0.385233\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381409:  10%|#         | 2/20 [00:02<00:19,  1.06s/it]\u001b[32m[I 2022-09-14 22:36:19,298]\u001b[0m Trial 44 finished with value: 0.3850255457302362 and parameters: {'lambda_l1': 0.2671423266300389, 'lambda_l2': 2.3338250333014514}. Best is trial 44 with value: 0.3850255457302362.\u001b[0m\n",
      "regularization_factors, val_score: 0.381409:  10%|#         | 2/20 [00:02<00:19,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.274192\tVal's binary_logloss: 0.385026\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381409:  15%|#5        | 3/20 [00:03<00:17,  1.02s/it]\u001b[32m[I 2022-09-14 22:36:20,279]\u001b[0m Trial 45 finished with value: 0.3851488228296351 and parameters: {'lambda_l1': 3.6210084408588097e-07, 'lambda_l2': 0.1428169726362242}. Best is trial 44 with value: 0.3850255457302362.\u001b[0m\n",
      "regularization_factors, val_score: 0.381409:  15%|#5        | 3/20 [00:03<00:17,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.257681\tVal's binary_logloss: 0.385149\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381409:  20%|##        | 4/20 [00:04<00:16,  1.06s/it]\u001b[32m[I 2022-09-14 22:36:21,395]\u001b[0m Trial 46 finished with value: 0.3831779789722207 and parameters: {'lambda_l1': 4.7592595805285e-05, 'lambda_l2': 0.3111978115638506}. Best is trial 46 with value: 0.3831779789722207.\u001b[0m\n",
      "regularization_factors, val_score: 0.381409:  20%|##        | 4/20 [00:04<00:16,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.25805\tVal's binary_logloss: 0.383178\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381409:  25%|##5       | 5/20 [00:05<00:16,  1.09s/it]\u001b[32m[I 2022-09-14 22:36:22,527]\u001b[0m Trial 47 finished with value: 0.3824237685746211 and parameters: {'lambda_l1': 4.991900761075126e-06, 'lambda_l2': 0.5912154883050112}. Best is trial 47 with value: 0.3824237685746211.\u001b[0m\n",
      "regularization_factors, val_score: 0.381409:  25%|##5       | 5/20 [00:05<00:16,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.262085\tVal's binary_logloss: 0.382424\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381409:  30%|###       | 6/20 [00:07<00:21,  1.54s/it]\u001b[32m[I 2022-09-14 22:36:24,946]\u001b[0m Trial 48 finished with value: 0.38544948848747634 and parameters: {'lambda_l1': 1.3237115963018942e-05, 'lambda_l2': 9.28594062625338e-06}. Best is trial 47 with value: 0.3824237685746211.\u001b[0m\n",
      "regularization_factors, val_score: 0.381409:  30%|###       | 6/20 [00:07<00:21,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.256464\tVal's binary_logloss: 0.385449\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381409:  35%|###5      | 7/20 [00:08<00:18,  1.42s/it]\u001b[32m[I 2022-09-14 22:36:26,118]\u001b[0m Trial 49 finished with value: 0.3819343201276181 and parameters: {'lambda_l1': 2.679702760939916, 'lambda_l2': 0.01933096470863808}. Best is trial 49 with value: 0.3819343201276181.\u001b[0m\n",
      "regularization_factors, val_score: 0.381409:  35%|###5      | 7/20 [00:08<00:18,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.283873\tVal's binary_logloss: 0.381934\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381409:  40%|####      | 8/20 [00:10<00:15,  1.32s/it]\u001b[32m[I 2022-09-14 22:36:27,225]\u001b[0m Trial 50 finished with value: 0.383573070384951 and parameters: {'lambda_l1': 2.267054391512285e-05, 'lambda_l2': 0.021725765105173555}. Best is trial 49 with value: 0.3819343201276181.\u001b[0m\n",
      "regularization_factors, val_score: 0.381409:  40%|####      | 8/20 [00:10<00:15,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.25551\tVal's binary_logloss: 0.383573\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381398:  45%|####5     | 9/20 [00:11<00:13,  1.23s/it]\u001b[32m[I 2022-09-14 22:36:28,257]\u001b[0m Trial 51 finished with value: 0.3813979799646953 and parameters: {'lambda_l1': 5.416449488123116e-07, 'lambda_l2': 5.2213457059735894e-05}. Best is trial 51 with value: 0.3813979799646953.\u001b[0m\n",
      "regularization_factors, val_score: 0.381398:  45%|####5     | 9/20 [00:11<00:13,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253499\tVal's binary_logloss: 0.381398\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381398:  50%|#####     | 10/20 [00:12<00:11,  1.18s/it]\u001b[32m[I 2022-09-14 22:36:29,325]\u001b[0m Trial 52 finished with value: 0.38901010515557083 and parameters: {'lambda_l1': 0.0008261721676634996, 'lambda_l2': 0.00032293101363472176}. Best is trial 51 with value: 0.3813979799646953.\u001b[0m\n",
      "regularization_factors, val_score: 0.381398:  50%|#####     | 10/20 [00:12<00:11,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.257622\tVal's binary_logloss: 0.38901\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381398:  55%|#####5    | 11/20 [00:13<00:12,  1.38s/it]\u001b[32m[I 2022-09-14 22:36:31,154]\u001b[0m Trial 53 finished with value: 0.38140634690749525 and parameters: {'lambda_l1': 1.0357836695948857e-08, 'lambda_l2': 1.6439581558330816e-08}. Best is trial 51 with value: 0.3813979799646953.\u001b[0m\n",
      "regularization_factors, val_score: 0.381398:  55%|#####5    | 11/20 [00:13<00:12,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381406\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381354:  60%|######    | 12/20 [00:15<00:10,  1.28s/it]\u001b[32m[I 2022-09-14 22:36:32,199]\u001b[0m Trial 54 finished with value: 0.3813543106929898 and parameters: {'lambda_l1': 1.0925723183472442e-08, 'lambda_l2': 1.0478704015563913e-08}. Best is trial 54 with value: 0.3813543106929898.\u001b[0m\n",
      "regularization_factors, val_score: 0.381354:  60%|######    | 12/20 [00:15<00:10,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381354\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381354:  65%|######5   | 13/20 [00:15<00:08,  1.19s/it]\u001b[32m[I 2022-09-14 22:36:33,173]\u001b[0m Trial 55 finished with value: 0.3813557520378784 and parameters: {'lambda_l1': 1.4647598916652647e-08, 'lambda_l2': 7.0455257661432005e-06}. Best is trial 54 with value: 0.3813543106929898.\u001b[0m\n",
      "regularization_factors, val_score: 0.381354:  65%|######5   | 13/20 [00:15<00:08,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381356\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381327:  70%|#######   | 14/20 [00:17<00:06,  1.17s/it]\u001b[32m[I 2022-09-14 22:36:34,296]\u001b[0m Trial 56 finished with value: 0.38132708141970506 and parameters: {'lambda_l1': 1.428385347761715e-08, 'lambda_l2': 7.71376221632569e-07}. Best is trial 56 with value: 0.38132708141970506.\u001b[0m\n",
      "regularization_factors, val_score: 0.381327:  70%|#######   | 14/20 [00:17<00:06,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381327\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381327:  75%|#######5  | 15/20 [00:18<00:05,  1.11s/it]\u001b[32m[I 2022-09-14 22:36:35,276]\u001b[0m Trial 57 finished with value: 0.38132740908079277 and parameters: {'lambda_l1': 1.87868725584585e-07, 'lambda_l2': 1.2426783042336763e-08}. Best is trial 56 with value: 0.38132708141970506.\u001b[0m\n",
      "regularization_factors, val_score: 0.381327:  75%|#######5  | 15/20 [00:18<00:05,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381327\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381321:  80%|########  | 16/20 [00:19<00:04,  1.06s/it]\u001b[32m[I 2022-09-14 22:36:36,222]\u001b[0m Trial 58 finished with value: 0.3813211584236503 and parameters: {'lambda_l1': 2.986561341523021e-07, 'lambda_l2': 2.680266272289167e-07}. Best is trial 58 with value: 0.3813211584236503.\u001b[0m\n",
      "regularization_factors, val_score: 0.381321:  80%|########  | 16/20 [00:19<00:04,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381321\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381321:  85%|########5 | 17/20 [00:19<00:03,  1.02s/it]\u001b[32m[I 2022-09-14 22:36:37,158]\u001b[0m Trial 59 finished with value: 0.3862462003521205 and parameters: {'lambda_l1': 0.013859562298048094, 'lambda_l2': 5.255201214009093e-07}. Best is trial 58 with value: 0.3813211584236503.\u001b[0m\n",
      "regularization_factors, val_score: 0.381321:  85%|########5 | 17/20 [00:19<00:03,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255175\tVal's binary_logloss: 0.386246\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381239:  90%|######### | 18/20 [00:20<00:02,  1.00s/it]\u001b[32m[I 2022-09-14 22:36:38,106]\u001b[0m Trial 60 finished with value: 0.3812390046338941 and parameters: {'lambda_l1': 1.1000273788725776e-06, 'lambda_l2': 3.0946507889536736e-07}. Best is trial 60 with value: 0.3812390046338941.\u001b[0m\n",
      "regularization_factors, val_score: 0.381239:  90%|######### | 18/20 [00:20<00:02,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253498\tVal's binary_logloss: 0.381239\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381239:  95%|#########5| 19/20 [00:21<00:00,  1.00it/s]\u001b[32m[I 2022-09-14 22:36:39,098]\u001b[0m Trial 61 finished with value: 0.38552967195341337 and parameters: {'lambda_l1': 1.815297710031024e-06, 'lambda_l2': 0.0005445589785390801}. Best is trial 60 with value: 0.3812390046338941.\u001b[0m\n",
      "regularization_factors, val_score: 0.381239:  95%|#########5| 19/20 [00:21<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.256473\tVal's binary_logloss: 0.38553\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.381130: 100%|##########| 20/20 [00:22<00:00,  1.02it/s]\u001b[32m[I 2022-09-14 22:36:40,050]\u001b[0m Trial 62 finished with value: 0.38112961983741517 and parameters: {'lambda_l1': 0.00014361513514546417, 'lambda_l2': 1.0988078190480694e-07}. Best is trial 62 with value: 0.38112961983741517.\u001b[0m\n",
      "regularization_factors, val_score: 0.381130: 100%|##########| 20/20 [00:22<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.256136\tVal's binary_logloss: 0.38113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.381130:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.381130:  20%|##        | 1/5 [00:00<00:03,  1.04it/s]\u001b[32m[I 2022-09-14 22:36:41,023]\u001b[0m Trial 63 finished with value: 0.38388830701290577 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.38388830701290577.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.381130:  20%|##        | 1/5 [00:00<00:03,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.25279\tVal's binary_logloss: 0.383888\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.381130:  40%|####      | 2/5 [00:01<00:02,  1.07it/s]\u001b[32m[I 2022-09-14 22:36:41,944]\u001b[0m Trial 64 finished with value: 0.38310724873280955 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.38310724873280955.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.381130:  40%|####      | 2/5 [00:01<00:02,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.257221\tVal's binary_logloss: 0.383107\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.381130:  60%|######    | 3/5 [00:02<00:01,  1.06it/s]\u001b[32m[I 2022-09-14 22:36:42,892]\u001b[0m Trial 65 finished with value: 0.38422497781863735 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.38310724873280955.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.381130:  60%|######    | 3/5 [00:02<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.27864\tVal's binary_logloss: 0.384225\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.381130:  80%|########  | 4/5 [00:03<00:00,  1.04it/s]\u001b[32m[I 2022-09-14 22:36:43,882]\u001b[0m Trial 66 finished with value: 0.38341865392157476 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.38310724873280955.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.381130:  80%|########  | 4/5 [00:03<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.247741\tVal's binary_logloss: 0.383419\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.381130: 100%|##########| 5/5 [00:04<00:00,  1.05it/s]\u001b[32m[I 2022-09-14 22:36:44,829]\u001b[0m Trial 67 finished with value: 0.3816488896506752 and parameters: {'min_child_samples': 50}. Best is trial 67 with value: 0.3816488896506752.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.381130: 100%|##########| 5/5 [00:04<00:00,  1.05it/s]\n",
      "\u001b[32m[I 2022-09-14 22:36:44,840]\u001b[0m A new study created in memory with name: no-name-879a83ff-9774-4be6-b187-aae3b6bba86a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.263622\tVal's binary_logloss: 0.381649\n",
      "fold 2/acc: 0.8154111558366878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "feature_fraction, val_score: 0.370115:  14%|#4        | 1/7 [00:00<00:05,  1.09it/s]\u001b[32m[I 2022-09-14 22:36:45,768]\u001b[0m Trial 0 finished with value: 0.3701149873513481 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.3701149873513481.\u001b[0m\n",
      "feature_fraction, val_score: 0.370115:  14%|#4        | 1/7 [00:00<00:05,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.26694\tVal's binary_logloss: 0.370115\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.370115:  29%|##8       | 2/7 [00:01<00:04,  1.02it/s]\u001b[32m[I 2022-09-14 22:36:46,795]\u001b[0m Trial 1 finished with value: 0.3786051751223031 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.3701149873513481.\u001b[0m\n",
      "feature_fraction, val_score: 0.370115:  29%|##8       | 2/7 [00:01<00:04,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.287332\tVal's binary_logloss: 0.378605\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.367559:  43%|####2     | 3/7 [00:02<00:03,  1.08it/s]\u001b[32m[I 2022-09-14 22:36:47,650]\u001b[0m Trial 2 finished with value: 0.3675589347673258 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.3675589347673258.\u001b[0m\n",
      "feature_fraction, val_score: 0.367559:  43%|####2     | 3/7 [00:02<00:03,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.259334\tVal's binary_logloss: 0.367559\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.367559:  57%|#####7    | 4/7 [00:03<00:02,  1.06it/s]\u001b[32m[I 2022-09-14 22:36:48,619]\u001b[0m Trial 3 finished with value: 0.3737860347071185 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.3675589347673258.\u001b[0m\n",
      "feature_fraction, val_score: 0.367559:  57%|#####7    | 4/7 [00:03<00:02,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.272856\tVal's binary_logloss: 0.373786\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.367558:  71%|#######1  | 5/7 [00:04<00:01,  1.09it/s]\u001b[32m[I 2022-09-14 22:36:49,488]\u001b[0m Trial 4 finished with value: 0.3675582979892686 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.3675582979892686.\u001b[0m\n",
      "feature_fraction, val_score: 0.367558:  71%|#######1  | 5/7 [00:04<00:01,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253365\tVal's binary_logloss: 0.367558\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.367558:  86%|########5 | 6/7 [00:05<00:00,  1.11it/s]\u001b[32m[I 2022-09-14 22:36:50,348]\u001b[0m Trial 5 finished with value: 0.3704730682353385 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.3675582979892686.\u001b[0m\n",
      "feature_fraction, val_score: 0.367558:  86%|########5 | 6/7 [00:05<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.265679\tVal's binary_logloss: 0.370473\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.365490: 100%|##########| 7/7 [00:06<00:00,  1.12it/s]\u001b[32m[I 2022-09-14 22:36:51,228]\u001b[0m Trial 6 finished with value: 0.3654901672864083 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 6 with value: 0.3654901672864083.\u001b[0m\n",
      "feature_fraction, val_score: 0.365490: 100%|##########| 7/7 [00:06<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.25606\tVal's binary_logloss: 0.36549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:   5%|5         | 1/20 [00:00<00:17,  1.08it/s]\u001b[32m[I 2022-09-14 22:36:52,160]\u001b[0m Trial 7 finished with value: 0.366490688855966 and parameters: {'num_leaves': 33}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:   5%|5         | 1/20 [00:00<00:17,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.250611\tVal's binary_logloss: 0.366491\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:  10%|#         | 2/20 [00:03<00:30,  1.69s/it]\u001b[32m[I 2022-09-14 22:36:54,383]\u001b[0m Trial 8 finished with value: 0.37203536238681667 and parameters: {'num_leaves': 99}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:  10%|#         | 2/20 [00:03<00:30,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's binary_logloss: 0.250234\tVal's binary_logloss: 0.372035\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:  15%|#5        | 3/20 [00:05<00:35,  2.11s/it]\u001b[32m[I 2022-09-14 22:36:56,984]\u001b[0m Trial 9 finished with value: 0.3786911429550357 and parameters: {'num_leaves': 129}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:  15%|#5        | 3/20 [00:05<00:35,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tTrain's binary_logloss: 0.224803\tVal's binary_logloss: 0.378691\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:  20%|##        | 4/20 [00:07<00:33,  2.09s/it]\u001b[32m[I 2022-09-14 22:36:59,052]\u001b[0m Trial 10 finished with value: 0.370769672429008 and parameters: {'num_leaves': 85}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:  20%|##        | 4/20 [00:07<00:33,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tTrain's binary_logloss: 0.251\tVal's binary_logloss: 0.37077\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:  25%|##5       | 5/20 [00:10<00:33,  2.22s/it]\u001b[32m[I 2022-09-14 22:37:01,495]\u001b[0m Trial 11 finished with value: 0.3745961791987876 and parameters: {'num_leaves': 114}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:  25%|##5       | 5/20 [00:10<00:33,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's binary_logloss: 0.215641\tVal's binary_logloss: 0.374596\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:  30%|###       | 6/20 [00:13<00:35,  2.55s/it]\u001b[32m[I 2022-09-14 22:37:04,699]\u001b[0m Trial 12 finished with value: 0.38190640317407726 and parameters: {'num_leaves': 145}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:  30%|###       | 6/20 [00:13<00:35,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tTrain's binary_logloss: 0.227586\tVal's binary_logloss: 0.381906\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:  35%|###5      | 7/20 [00:15<00:31,  2.39s/it]\u001b[32m[I 2022-09-14 22:37:06,762]\u001b[0m Trial 13 finished with value: 0.388758736589694 and parameters: {'num_leaves': 83}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:  35%|###5      | 7/20 [00:15<00:31,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.155859\tVal's binary_logloss: 0.388759\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:  40%|####      | 8/20 [00:18<00:29,  2.47s/it]\u001b[32m[I 2022-09-14 22:37:09,399]\u001b[0m Trial 14 finished with value: 0.38404606552601606 and parameters: {'num_leaves': 101}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:  40%|####      | 8/20 [00:18<00:29,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.134783\tVal's binary_logloss: 0.384046\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:  45%|####5     | 9/20 [00:21<00:29,  2.69s/it]\u001b[32m[I 2022-09-14 22:37:12,573]\u001b[0m Trial 15 finished with value: 0.3824477943272455 and parameters: {'num_leaves': 182}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:  45%|####5     | 9/20 [00:21<00:29,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tTrain's binary_logloss: 0.216952\tVal's binary_logloss: 0.382448\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:  50%|#####     | 10/20 [00:23<00:26,  2.64s/it]\u001b[32m[I 2022-09-14 22:37:15,093]\u001b[0m Trial 16 finished with value: 0.37390894925272894 and parameters: {'num_leaves': 94}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:  50%|#####     | 10/20 [00:23<00:26,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's binary_logloss: 0.231085\tVal's binary_logloss: 0.373909\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365490:  55%|#####5    | 11/20 [00:24<00:17,  1.98s/it]\u001b[32m[I 2022-09-14 22:37:15,594]\u001b[0m Trial 17 finished with value: 0.3717728590082001 and parameters: {'num_leaves': 15}. Best is trial 7 with value: 0.366490688855966.\u001b[0m\n",
      "num_leaves, val_score: 0.365490:  55%|#####5    | 11/20 [00:24<00:17,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.319077\tVal's binary_logloss: 0.371773\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365186:  60%|######    | 12/20 [00:25<00:12,  1.60s/it]\u001b[32m[I 2022-09-14 22:37:16,305]\u001b[0m Trial 18 finished with value: 0.3651858224586056 and parameters: {'num_leaves': 25}. Best is trial 18 with value: 0.3651858224586056.\u001b[0m\n",
      "num_leaves, val_score: 0.365186:  60%|######    | 12/20 [00:25<00:12,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.278289\tVal's binary_logloss: 0.365186\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365186:  65%|######5   | 13/20 [00:25<00:08,  1.25s/it]\u001b[32m[I 2022-09-14 22:37:16,768]\u001b[0m Trial 19 finished with value: 0.3695307139766409 and parameters: {'num_leaves': 13}. Best is trial 18 with value: 0.3651858224586056.\u001b[0m\n",
      "num_leaves, val_score: 0.365186:  65%|######5   | 13/20 [00:25<00:08,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.32841\tVal's binary_logloss: 0.369531\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365186:  70%|#######   | 14/20 [00:30<00:13,  2.24s/it]\u001b[32m[I 2022-09-14 22:37:21,275]\u001b[0m Trial 20 finished with value: 0.38296050529354747 and parameters: {'num_leaves': 251}. Best is trial 18 with value: 0.3651858224586056.\u001b[0m\n",
      "num_leaves, val_score: 0.365186:  70%|#######   | 14/20 [00:30<00:13,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's binary_logloss: 0.196227\tVal's binary_logloss: 0.382961\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365186:  75%|#######5  | 15/20 [00:31<00:10,  2.06s/it]\u001b[32m[I 2022-09-14 22:37:22,917]\u001b[0m Trial 21 finished with value: 0.37358414593423694 and parameters: {'num_leaves': 47}. Best is trial 18 with value: 0.3651858224586056.\u001b[0m\n",
      "num_leaves, val_score: 0.365186:  75%|#######5  | 15/20 [00:31<00:10,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.216465\tVal's binary_logloss: 0.373584\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365186:  80%|########  | 16/20 [00:33<00:07,  1.89s/it]\u001b[32m[I 2022-09-14 22:37:24,416]\u001b[0m Trial 22 finished with value: 0.3701179602970523 and parameters: {'num_leaves': 48}. Best is trial 18 with value: 0.3651858224586056.\u001b[0m\n",
      "num_leaves, val_score: 0.365186:  80%|########  | 16/20 [00:33<00:07,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.214725\tVal's binary_logloss: 0.370118\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365186:  85%|########5 | 17/20 [00:34<00:05,  1.75s/it]\u001b[32m[I 2022-09-14 22:37:25,854]\u001b[0m Trial 23 finished with value: 0.37655141702090256 and parameters: {'num_leaves': 49}. Best is trial 18 with value: 0.3651858224586056.\u001b[0m\n",
      "num_leaves, val_score: 0.365186:  85%|########5 | 17/20 [00:34<00:05,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.213704\tVal's binary_logloss: 0.376551\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365186:  90%|######### | 18/20 [00:38<00:04,  2.26s/it]\u001b[32m[I 2022-09-14 22:37:29,307]\u001b[0m Trial 24 finished with value: 0.3785995232040394 and parameters: {'num_leaves': 166}. Best is trial 18 with value: 0.3651858224586056.\u001b[0m\n",
      "num_leaves, val_score: 0.365186:  95%|#########5| 19/20 [00:38<00:01,  1.64s/it]\u001b[32m[I 2022-09-14 22:37:29,488]\u001b[0m Trial 25 finished with value: 0.4746286228397083 and parameters: {'num_leaves': 2}. Best is trial 18 with value: 0.3651858224586056.\u001b[0m\n",
      "num_leaves, val_score: 0.365186:  95%|#########5| 19/20 [00:38<00:01,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's binary_logloss: 0.210598\tVal's binary_logloss: 0.3786\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.484002\tVal's binary_logloss: 0.474629\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365186: 100%|##########| 20/20 [00:40<00:00,  1.69s/it]\u001b[32m[I 2022-09-14 22:37:31,296]\u001b[0m Trial 26 finished with value: 0.37680435125725154 and parameters: {'num_leaves': 62}. Best is trial 18 with value: 0.3651858224586056.\u001b[0m\n",
      "num_leaves, val_score: 0.365186: 100%|##########| 20/20 [00:40<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.187925\tVal's binary_logloss: 0.376804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365186:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365186:  10%|#         | 1/10 [00:00<00:07,  1.21it/s]\u001b[32m[I 2022-09-14 22:37:32,130]\u001b[0m Trial 27 finished with value: 0.3738931121624811 and parameters: {'bagging_fraction': 0.6752708938827301, 'bagging_freq': 6}. Best is trial 27 with value: 0.3738931121624811.\u001b[0m\n",
      "bagging, val_score: 0.365186:  10%|#         | 1/10 [00:00<00:07,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276681\tVal's binary_logloss: 0.373893\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.363717:  20%|##        | 2/10 [00:01<00:06,  1.26it/s]\u001b[32m[I 2022-09-14 22:37:32,901]\u001b[0m Trial 28 finished with value: 0.36371690378332155 and parameters: {'bagging_fraction': 0.9092735001825434, 'bagging_freq': 1}. Best is trial 28 with value: 0.36371690378332155.\u001b[0m\n",
      "bagging, val_score: 0.363717:  20%|##        | 2/10 [00:01<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.272456\tVal's binary_logloss: 0.363717\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.363717:  30%|###       | 3/10 [00:02<00:05,  1.23it/s]\u001b[32m[I 2022-09-14 22:37:33,737]\u001b[0m Trial 29 finished with value: 0.36992838519747984 and parameters: {'bagging_fraction': 0.8729907474404853, 'bagging_freq': 7}. Best is trial 28 with value: 0.36371690378332155.\u001b[0m\n",
      "bagging, val_score: 0.363717:  30%|###       | 3/10 [00:02<00:05,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.274533\tVal's binary_logloss: 0.369928\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.363717:  40%|####      | 4/10 [00:03<00:04,  1.29it/s]\u001b[32m[I 2022-09-14 22:37:34,452]\u001b[0m Trial 30 finished with value: 0.3729812612630326 and parameters: {'bagging_fraction': 0.6219211035468212, 'bagging_freq': 5}. Best is trial 28 with value: 0.36371690378332155.\u001b[0m\n",
      "bagging, val_score: 0.363717:  40%|####      | 4/10 [00:03<00:04,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.278111\tVal's binary_logloss: 0.372981\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.363717:  50%|#####     | 5/10 [00:03<00:03,  1.33it/s]\u001b[32m[I 2022-09-14 22:37:35,171]\u001b[0m Trial 31 finished with value: 0.37086138870386876 and parameters: {'bagging_fraction': 0.47581456932798194, 'bagging_freq': 2}. Best is trial 28 with value: 0.36371690378332155.\u001b[0m\n",
      "bagging, val_score: 0.363717:  50%|#####     | 5/10 [00:03<00:03,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.283832\tVal's binary_logloss: 0.370861\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.363717:  60%|######    | 6/10 [00:04<00:02,  1.34it/s]\u001b[32m[I 2022-09-14 22:37:35,902]\u001b[0m Trial 32 finished with value: 0.3797082485625555 and parameters: {'bagging_fraction': 0.4072340599534061, 'bagging_freq': 1}. Best is trial 28 with value: 0.36371690378332155.\u001b[0m\n",
      "bagging, val_score: 0.363717:  60%|######    | 6/10 [00:04<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.282191\tVal's binary_logloss: 0.379708\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.363717:  70%|#######   | 7/10 [00:05<00:02,  1.35it/s]\u001b[32m[I 2022-09-14 22:37:36,639]\u001b[0m Trial 33 finished with value: 0.36861027669496504 and parameters: {'bagging_fraction': 0.889040614720044, 'bagging_freq': 7}. Best is trial 28 with value: 0.36371690378332155.\u001b[0m\n",
      "bagging, val_score: 0.363717:  70%|#######   | 7/10 [00:05<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.275497\tVal's binary_logloss: 0.36861\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.363717:  80%|########  | 8/10 [00:06<00:01,  1.37it/s]\u001b[32m[I 2022-09-14 22:37:37,343]\u001b[0m Trial 34 finished with value: 0.37485610756314447 and parameters: {'bagging_fraction': 0.6717372887346493, 'bagging_freq': 5}. Best is trial 28 with value: 0.36371690378332155.\u001b[0m\n",
      "bagging, val_score: 0.363717:  80%|########  | 8/10 [00:06<00:01,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.274649\tVal's binary_logloss: 0.374856\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.363370:  90%|######### | 9/10 [00:06<00:00,  1.37it/s]\u001b[32m[I 2022-09-14 22:37:38,066]\u001b[0m Trial 35 finished with value: 0.3633702951057782 and parameters: {'bagging_fraction': 0.9974272281805386, 'bagging_freq': 5}. Best is trial 35 with value: 0.3633702951057782.\u001b[0m\n",
      "bagging, val_score: 0.363370:  90%|######### | 9/10 [00:06<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.277457\tVal's binary_logloss: 0.36337\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.363370: 100%|##########| 10/10 [00:07<00:00,  1.33it/s]\u001b[32m[I 2022-09-14 22:37:38,876]\u001b[0m Trial 36 finished with value: 0.3769067577928611 and parameters: {'bagging_fraction': 0.7173445910610722, 'bagging_freq': 6}. Best is trial 35 with value: 0.3633702951057782.\u001b[0m\n",
      "bagging, val_score: 0.363370: 100%|##########| 10/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276309\tVal's binary_logloss: 0.376907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.363370:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.363370:  17%|#6        | 1/6 [00:00<00:03,  1.40it/s]\u001b[32m[I 2022-09-14 22:37:39,598]\u001b[0m Trial 37 finished with value: 0.36717446765099326 and parameters: {'feature_fraction': 0.9159999999999999}. Best is trial 37 with value: 0.36717446765099326.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.363370:  17%|#6        | 1/6 [00:00<00:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.275961\tVal's binary_logloss: 0.367174\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.363370:  33%|###3      | 2/6 [00:01<00:03,  1.32it/s]\u001b[32m[I 2022-09-14 22:37:40,387]\u001b[0m Trial 38 finished with value: 0.3633702951057782 and parameters: {'feature_fraction': 0.852}. Best is trial 38 with value: 0.3633702951057782.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.363370:  33%|###3      | 2/6 [00:01<00:03,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.277457\tVal's binary_logloss: 0.36337\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.363370:  50%|#####     | 3/6 [00:02<00:02,  1.28it/s]\u001b[32m[I 2022-09-14 22:37:41,199]\u001b[0m Trial 39 finished with value: 0.367928675911562 and parameters: {'feature_fraction': 0.9799999999999999}. Best is trial 38 with value: 0.3633702951057782.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.363370:  50%|#####     | 3/6 [00:02<00:02,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.272789\tVal's binary_logloss: 0.367929\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.363370:  67%|######6   | 4/6 [00:03<00:01,  1.31it/s]\u001b[32m[I 2022-09-14 22:37:41,928]\u001b[0m Trial 40 finished with value: 0.36717446765099326 and parameters: {'feature_fraction': 0.948}. Best is trial 38 with value: 0.3633702951057782.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.363370:  67%|######6   | 4/6 [00:03<00:01,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.275961\tVal's binary_logloss: 0.367174\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.363370:  83%|########3 | 5/6 [00:03<00:00,  1.31it/s]\u001b[32m[I 2022-09-14 22:37:42,692]\u001b[0m Trial 41 finished with value: 0.3671026361894742 and parameters: {'feature_fraction': 0.82}. Best is trial 38 with value: 0.3633702951057782.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.363370:  83%|########3 | 5/6 [00:03<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276331\tVal's binary_logloss: 0.367103\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.363370: 100%|##########| 6/6 [00:04<00:00,  1.32it/s]\u001b[32m[I 2022-09-14 22:37:43,434]\u001b[0m Trial 42 finished with value: 0.3633702951057782 and parameters: {'feature_fraction': 0.8839999999999999}. Best is trial 38 with value: 0.3633702951057782.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.363370: 100%|##########| 6/6 [00:04<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.277457\tVal's binary_logloss: 0.36337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.363370:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.363370:   5%|5         | 1/20 [00:00<00:13,  1.41it/s]\u001b[32m[I 2022-09-14 22:37:44,149]\u001b[0m Trial 43 finished with value: 0.3633978387470286 and parameters: {'lambda_l1': 1.1168830009926762e-06, 'lambda_l2': 5.054781331220973e-08}. Best is trial 43 with value: 0.3633978387470286.\u001b[0m\n",
      "regularization_factors, val_score: 0.363370:   5%|5         | 1/20 [00:00<00:13,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.277457\tVal's binary_logloss: 0.363398\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.363370:  10%|#         | 2/20 [00:01<00:12,  1.41it/s]\u001b[32m[I 2022-09-14 22:37:44,860]\u001b[0m Trial 44 finished with value: 0.3655578722669217 and parameters: {'lambda_l1': 2.931842845637247, 'lambda_l2': 3.452326597446811e-06}. Best is trial 43 with value: 0.3633978387470286.\u001b[0m\n",
      "regularization_factors, val_score: 0.363370:  10%|#         | 2/20 [00:01<00:12,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.299419\tVal's binary_logloss: 0.365558\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.363370:  15%|#5        | 3/20 [00:02<00:12,  1.32it/s]\u001b[32m[I 2022-09-14 22:37:45,673]\u001b[0m Trial 45 finished with value: 0.3650000974087493 and parameters: {'lambda_l1': 0.5071539049899643, 'lambda_l2': 0.0059534648665708805}. Best is trial 43 with value: 0.3633978387470286.\u001b[0m\n",
      "regularization_factors, val_score: 0.363370:  15%|#5        | 3/20 [00:02<00:12,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.280759\tVal's binary_logloss: 0.365\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.363370:  20%|##        | 4/20 [00:03<00:12,  1.29it/s]\u001b[32m[I 2022-09-14 22:37:46,471]\u001b[0m Trial 46 finished with value: 0.36791693603226283 and parameters: {'lambda_l1': 0.0016165237971325884, 'lambda_l2': 0.002296889479277966}. Best is trial 43 with value: 0.3633978387470286.\u001b[0m\n",
      "regularization_factors, val_score: 0.363370:  20%|##        | 4/20 [00:03<00:12,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276572\tVal's binary_logloss: 0.367917\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362844:  25%|##5       | 5/20 [00:03<00:11,  1.34it/s]\u001b[32m[I 2022-09-14 22:37:47,174]\u001b[0m Trial 47 finished with value: 0.3628444375296186 and parameters: {'lambda_l1': 0.00030520818003425287, 'lambda_l2': 1.6637899479496356e-08}. Best is trial 47 with value: 0.3628444375296186.\u001b[0m\n",
      "regularization_factors, val_score: 0.362844:  25%|##5       | 5/20 [00:03<00:11,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276591\tVal's binary_logloss: 0.362844\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362844:  30%|###       | 6/20 [00:05<00:13,  1.02it/s]\u001b[32m[I 2022-09-14 22:37:48,602]\u001b[0m Trial 48 finished with value: 0.36406641352762487 and parameters: {'lambda_l1': 0.007059773030199356, 'lambda_l2': 2.0916264050666595}. Best is trial 47 with value: 0.3628444375296186.\u001b[0m\n",
      "regularization_factors, val_score: 0.362844:  30%|###       | 6/20 [00:05<00:13,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.287579\tVal's binary_logloss: 0.364066\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362844:  35%|###5      | 7/20 [00:07<00:16,  1.27s/it]\u001b[32m[I 2022-09-14 22:37:50,482]\u001b[0m Trial 49 finished with value: 0.3682886483583729 and parameters: {'lambda_l1': 5.604120440030334, 'lambda_l2': 1.3780250146915357e-08}. Best is trial 47 with value: 0.3628444375296186.\u001b[0m\n",
      "regularization_factors, val_score: 0.362844:  35%|###5      | 7/20 [00:07<00:16,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.318943\tVal's binary_logloss: 0.368289\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362844:  40%|####      | 8/20 [00:08<00:17,  1.46s/it]\u001b[32m[I 2022-09-14 22:37:52,335]\u001b[0m Trial 50 finished with value: 0.3670446672152963 and parameters: {'lambda_l1': 0.01416114616993969, 'lambda_l2': 0.00013023757401743152}. Best is trial 47 with value: 0.3628444375296186.\u001b[0m\n",
      "regularization_factors, val_score: 0.362844:  40%|####      | 8/20 [00:08<00:17,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.278419\tVal's binary_logloss: 0.367045\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362844:  45%|####5     | 9/20 [00:10<00:15,  1.44s/it]\u001b[32m[I 2022-09-14 22:37:53,727]\u001b[0m Trial 51 finished with value: 0.3643858302792766 and parameters: {'lambda_l1': 0.07265433321224428, 'lambda_l2': 3.235468774976679e-08}. Best is trial 47 with value: 0.3628444375296186.\u001b[0m\n",
      "regularization_factors, val_score: 0.362844:  45%|####5     | 9/20 [00:10<00:15,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276562\tVal's binary_logloss: 0.364386\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362827:  50%|#####     | 10/20 [00:12<00:16,  1.61s/it]\u001b[32m[I 2022-09-14 22:37:55,728]\u001b[0m Trial 52 finished with value: 0.36282666228781124 and parameters: {'lambda_l1': 6.215475145031076e-05, 'lambda_l2': 3.99453043989294e-07}. Best is trial 52 with value: 0.36282666228781124.\u001b[0m\n",
      "regularization_factors, val_score: 0.362827:  50%|#####     | 10/20 [00:12<00:16,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276588\tVal's binary_logloss: 0.362827\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362827:  55%|#####5    | 11/20 [00:14<00:15,  1.75s/it]\u001b[32m[I 2022-09-14 22:37:57,791]\u001b[0m Trial 53 finished with value: 0.36336394166888974 and parameters: {'lambda_l1': 1.193328711075001e-08, 'lambda_l2': 1.0445785237640668e-05}. Best is trial 52 with value: 0.36282666228781124.\u001b[0m\n",
      "regularization_factors, val_score: 0.362827:  55%|#####5    | 11/20 [00:14<00:15,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.277458\tVal's binary_logloss: 0.363364\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362827:  60%|######    | 12/20 [00:15<00:13,  1.66s/it]\u001b[32m[I 2022-09-14 22:37:59,232]\u001b[0m Trial 54 finished with value: 0.3628703816123158 and parameters: {'lambda_l1': 3.523457674823219e-05, 'lambda_l2': 1.350927232337625e-06}. Best is trial 52 with value: 0.36282666228781124.\u001b[0m\n",
      "regularization_factors, val_score: 0.362827:  60%|######    | 12/20 [00:15<00:13,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276588\tVal's binary_logloss: 0.36287\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362827:  65%|######5   | 13/20 [00:17<00:10,  1.56s/it]\u001b[32m[I 2022-09-14 22:38:00,583]\u001b[0m Trial 55 finished with value: 0.36339735150102875 and parameters: {'lambda_l1': 3.5091282254122876e-06, 'lambda_l2': 4.378355505572631e-07}. Best is trial 52 with value: 0.36282666228781124.\u001b[0m\n",
      "regularization_factors, val_score: 0.362827:  65%|######5   | 13/20 [00:17<00:10,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.277457\tVal's binary_logloss: 0.363397\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362772:  70%|#######   | 14/20 [00:18<00:08,  1.41s/it]\u001b[32m[I 2022-09-14 22:38:01,651]\u001b[0m Trial 56 finished with value: 0.36277221152106154 and parameters: {'lambda_l1': 0.000131451461831606, 'lambda_l2': 2.218507525234674e-05}. Best is trial 56 with value: 0.36277221152106154.\u001b[0m\n",
      "regularization_factors, val_score: 0.362772:  70%|#######   | 14/20 [00:18<00:08,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276589\tVal's binary_logloss: 0.362772\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362772:  75%|#######5  | 15/20 [00:19<00:07,  1.44s/it]\u001b[32m[I 2022-09-14 22:38:03,168]\u001b[0m Trial 57 finished with value: 0.3628358167340437 and parameters: {'lambda_l1': 8.655376680006479e-05, 'lambda_l2': 7.87590158777303e-05}. Best is trial 56 with value: 0.36277221152106154.\u001b[0m\n",
      "regularization_factors, val_score: 0.362772:  75%|#######5  | 15/20 [00:19<00:07,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276589\tVal's binary_logloss: 0.362836\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362772:  80%|########  | 16/20 [00:20<00:05,  1.36s/it]\u001b[32m[I 2022-09-14 22:38:04,329]\u001b[0m Trial 58 finished with value: 0.36641599779547335 and parameters: {'lambda_l1': 3.1021990755741895e-06, 'lambda_l2': 0.049049694824498495}. Best is trial 56 with value: 0.36277221152106154.\u001b[0m\n",
      "regularization_factors, val_score: 0.362772:  80%|########  | 16/20 [00:20<00:05,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.277138\tVal's binary_logloss: 0.366416\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362772:  85%|########5 | 17/20 [00:21<00:03,  1.20s/it]\u001b[32m[I 2022-09-14 22:38:05,157]\u001b[0m Trial 59 finished with value: 0.36337728583467094 and parameters: {'lambda_l1': 7.243500950114962e-08, 'lambda_l2': 1.3012262845575432e-05}. Best is trial 56 with value: 0.36277221152106154.\u001b[0m\n",
      "regularization_factors, val_score: 0.362772:  85%|########5 | 17/20 [00:21<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.277458\tVal's binary_logloss: 0.363377\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362772:  90%|######### | 18/20 [00:22<00:02,  1.18s/it]\u001b[32m[I 2022-09-14 22:38:06,293]\u001b[0m Trial 60 finished with value: 0.36282754728899314 and parameters: {'lambda_l1': 1.30543005032204e-05, 'lambda_l2': 4.7248204367978894e-07}. Best is trial 56 with value: 0.36277221152106154.\u001b[0m\n",
      "regularization_factors, val_score: 0.362772:  90%|######### | 18/20 [00:22<00:02,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276587\tVal's binary_logloss: 0.362828\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362772:  95%|#########5| 19/20 [00:23<00:01,  1.15s/it]\u001b[32m[I 2022-09-14 22:38:07,367]\u001b[0m Trial 61 finished with value: 0.3659169794134514 and parameters: {'lambda_l1': 0.001002562085938729, 'lambda_l2': 0.001637820110087193}. Best is trial 56 with value: 0.36277221152106154.\u001b[0m\n",
      "regularization_factors, val_score: 0.362772:  95%|#########5| 19/20 [00:23<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.276738\tVal's binary_logloss: 0.365917\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.362772: 100%|##########| 20/20 [00:24<00:00,  1.05s/it]\u001b[32m[I 2022-09-14 22:38:08,183]\u001b[0m Trial 62 finished with value: 0.3633786605830847 and parameters: {'lambda_l1': 2.688343910300523e-07, 'lambda_l2': 4.729226042410385e-05}. Best is trial 56 with value: 0.36277221152106154.\u001b[0m\n",
      "regularization_factors, val_score: 0.362772: 100%|##########| 20/20 [00:24<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.277458\tVal's binary_logloss: 0.363379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.362772:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.361993:  20%|##        | 1/5 [00:00<00:03,  1.33it/s]\u001b[32m[I 2022-09-14 22:38:08,945]\u001b[0m Trial 63 finished with value: 0.36199256910432015 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.36199256910432015.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.361993:  20%|##        | 1/5 [00:00<00:03,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.275321\tVal's binary_logloss: 0.361993\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.361993:  40%|####      | 2/5 [00:01<00:02,  1.34it/s]\u001b[32m[I 2022-09-14 22:38:09,685]\u001b[0m Trial 64 finished with value: 0.36741309719602727 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.36199256910432015.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.361993:  40%|####      | 2/5 [00:01<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.272011\tVal's binary_logloss: 0.367413\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.361993:  60%|######    | 3/5 [00:02<00:01,  1.35it/s]\u001b[32m[I 2022-09-14 22:38:10,423]\u001b[0m Trial 65 finished with value: 0.3681346699650876 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.36199256910432015.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.361993:  60%|######    | 3/5 [00:02<00:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.284876\tVal's binary_logloss: 0.368135\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.361993:  80%|########  | 4/5 [00:02<00:00,  1.38it/s]\u001b[32m[I 2022-09-14 22:38:11,119]\u001b[0m Trial 66 finished with value: 0.3683405920528374 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.36199256910432015.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.361993:  80%|########  | 4/5 [00:02<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.293951\tVal's binary_logloss: 0.368341\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.361993: 100%|##########| 5/5 [00:03<00:00,  1.38it/s]\u001b[32m[I 2022-09-14 22:38:11,852]\u001b[0m Trial 67 finished with value: 0.37264436645630455 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.36199256910432015.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.361993: 100%|##########| 5/5 [00:03<00:00,  1.36it/s]\n",
      "\u001b[32m[I 2022-09-14 22:38:11,865]\u001b[0m A new study created in memory with name: no-name-7a06475c-7f46-4a03-85b2-26d10e73480a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.269964\tVal's binary_logloss: 0.372644\n",
      "fold 3/acc: 0.8245109321058688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "feature_fraction, val_score: 0.407473:  14%|#4        | 1/7 [00:00<00:05,  1.08it/s]\u001b[32m[I 2022-09-14 22:38:12,801]\u001b[0m Trial 0 finished with value: 0.40747340532766807 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.40747340532766807.\u001b[0m\n",
      "feature_fraction, val_score: 0.407473:  14%|#4        | 1/7 [00:00<00:05,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.266031\tVal's binary_logloss: 0.407473\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.397820:  29%|##8       | 2/7 [00:01<00:04,  1.13it/s]\u001b[32m[I 2022-09-14 22:38:13,659]\u001b[0m Trial 1 finished with value: 0.3978199015895359 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.3978199015895359.\u001b[0m\n",
      "feature_fraction, val_score: 0.397820:  29%|##8       | 2/7 [00:01<00:04,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.254514\tVal's binary_logloss: 0.39782\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.397820:  43%|####2     | 3/7 [00:02<00:03,  1.09it/s]\u001b[32m[I 2022-09-14 22:38:14,621]\u001b[0m Trial 2 finished with value: 0.40837988090204835 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.3978199015895359.\u001b[0m\n",
      "feature_fraction, val_score: 0.397820:  43%|####2     | 3/7 [00:02<00:03,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.280067\tVal's binary_logloss: 0.40838\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.397820:  57%|#####7    | 4/7 [00:03<00:02,  1.08it/s]\u001b[32m[I 2022-09-14 22:38:15,563]\u001b[0m Trial 3 finished with value: 0.4003688023485457 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.3978199015895359.\u001b[0m\n",
      "feature_fraction, val_score: 0.397820:  57%|#####7    | 4/7 [00:03<00:02,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.26037\tVal's binary_logloss: 0.400369\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.397820:  71%|#######1  | 5/7 [00:04<00:01,  1.12it/s]\u001b[32m[I 2022-09-14 22:38:16,386]\u001b[0m Trial 4 finished with value: 0.40271623879052393 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.3978199015895359.\u001b[0m\n",
      "feature_fraction, val_score: 0.397820:  71%|#######1  | 5/7 [00:04<00:01,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.251081\tVal's binary_logloss: 0.402716\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.397820:  86%|########5 | 6/7 [00:05<00:00,  1.16it/s]\u001b[32m[I 2022-09-14 22:38:17,191]\u001b[0m Trial 5 finished with value: 0.40087255223659407 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.3978199015895359.\u001b[0m\n",
      "feature_fraction, val_score: 0.397820:  86%|########5 | 6/7 [00:05<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.249482\tVal's binary_logloss: 0.400873\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.397820: 100%|##########| 7/7 [00:06<00:00,  1.17it/s]\u001b[32m[I 2022-09-14 22:38:18,023]\u001b[0m Trial 6 finished with value: 0.40329004611236674 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.3978199015895359.\u001b[0m\n",
      "feature_fraction, val_score: 0.397820: 100%|##########| 7/7 [00:06<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.24699\tVal's binary_logloss: 0.40329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:   5%|5         | 1/20 [00:00<00:11,  1.60it/s]\u001b[32m[I 2022-09-14 22:38:18,657]\u001b[0m Trial 7 finished with value: 0.39802596382785654 and parameters: {'num_leaves': 22}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:   5%|5         | 1/20 [00:00<00:11,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.287149\tVal's binary_logloss: 0.398026\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  10%|#         | 2/20 [00:01<00:14,  1.22it/s]\u001b[32m[I 2022-09-14 22:38:19,607]\u001b[0m Trial 8 finished with value: 0.39994563964841545 and parameters: {'num_leaves': 36}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  10%|#         | 2/20 [00:01<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.239577\tVal's binary_logloss: 0.399946\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  15%|#5        | 3/20 [00:05<00:37,  2.23s/it]\u001b[32m[I 2022-09-14 22:38:23,525]\u001b[0m Trial 9 finished with value: 0.41985176886986303 and parameters: {'num_leaves': 207}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  15%|#5        | 3/20 [00:05<00:37,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tTrain's binary_logloss: 0.207798\tVal's binary_logloss: 0.419852\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  20%|##        | 4/20 [00:08<00:38,  2.41s/it]\u001b[32m[I 2022-09-14 22:38:26,208]\u001b[0m Trial 10 finished with value: 0.408091933815947 and parameters: {'num_leaves': 106}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  20%|##        | 4/20 [00:08<00:38,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's binary_logloss: 0.225654\tVal's binary_logloss: 0.408092\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  25%|##5       | 5/20 [00:10<00:33,  2.24s/it]\u001b[32m[I 2022-09-14 22:38:28,158]\u001b[0m Trial 11 finished with value: 0.40086602890708856 and parameters: {'num_leaves': 78}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  25%|##5       | 5/20 [00:10<00:33,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's binary_logloss: 0.241963\tVal's binary_logloss: 0.400866\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  30%|###       | 6/20 [00:14<00:40,  2.88s/it]\u001b[32m[I 2022-09-14 22:38:32,270]\u001b[0m Trial 12 finished with value: 0.4151571575419828 and parameters: {'num_leaves': 197}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  30%|###       | 6/20 [00:14<00:40,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's binary_logloss: 0.215964\tVal's binary_logloss: 0.415157\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  35%|###5      | 7/20 [00:18<00:42,  3.31s/it]\u001b[32m[I 2022-09-14 22:38:36,458]\u001b[0m Trial 13 finished with value: 0.4455222396059814 and parameters: {'num_leaves': 135}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  35%|###5      | 7/20 [00:18<00:42,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.113412\tVal's binary_logloss: 0.445522\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  40%|####      | 8/20 [00:25<00:54,  4.51s/it]\u001b[32m[I 2022-09-14 22:38:43,531]\u001b[0m Trial 14 finished with value: 0.41617899501117755 and parameters: {'num_leaves': 253}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  40%|####      | 8/20 [00:25<00:54,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's binary_logloss: 0.212244\tVal's binary_logloss: 0.416179\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  45%|####5     | 9/20 [00:32<00:57,  5.25s/it]\u001b[32m[I 2022-09-14 22:38:50,418]\u001b[0m Trial 15 finished with value: 0.41301481482461677 and parameters: {'num_leaves': 156}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  45%|####5     | 9/20 [00:32<00:57,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's binary_logloss: 0.19496\tVal's binary_logloss: 0.413015\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  50%|#####     | 10/20 [00:42<01:06,  6.68s/it]\u001b[32m[I 2022-09-14 22:39:00,309]\u001b[0m Trial 16 finished with value: 0.4135294534227609 and parameters: {'num_leaves': 226}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  50%|#####     | 10/20 [00:42<01:06,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tTrain's binary_logloss: 0.192147\tVal's binary_logloss: 0.413529\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  55%|#####5    | 11/20 [00:43<00:43,  4.87s/it]\u001b[32m[I 2022-09-14 22:39:01,070]\u001b[0m Trial 17 finished with value: 0.39802596382785654 and parameters: {'num_leaves': 22}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  55%|#####5    | 11/20 [00:43<00:43,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.287149\tVal's binary_logloss: 0.398026\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  60%|######    | 12/20 [00:43<00:27,  3.45s/it]\u001b[32m[I 2022-09-14 22:39:01,280]\u001b[0m Trial 18 finished with value: 0.4563701247754813 and parameters: {'num_leaves': 3}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  60%|######    | 12/20 [00:43<00:27,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.430727\tVal's binary_logloss: 0.45637\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  65%|######5   | 13/20 [00:44<00:19,  2.82s/it]\u001b[32m[I 2022-09-14 22:39:02,660]\u001b[0m Trial 19 finished with value: 0.4055083935125672 and parameters: {'num_leaves': 47}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  65%|######5   | 13/20 [00:44<00:19,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.216641\tVal's binary_logloss: 0.405508\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  70%|#######   | 14/20 [00:44<00:12,  2.04s/it]\u001b[32m[I 2022-09-14 22:39:02,889]\u001b[0m Trial 20 finished with value: 0.49765349143876103 and parameters: {'num_leaves': 2}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  70%|#######   | 14/20 [00:44<00:12,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.476334\tVal's binary_logloss: 0.497653\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  75%|#######5  | 15/20 [00:47<00:10,  2.14s/it]\u001b[32m[I 2022-09-14 22:39:05,246]\u001b[0m Trial 21 finished with value: 0.41251441375610176 and parameters: {'num_leaves': 61}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  75%|#######5  | 15/20 [00:47<00:10,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.192585\tVal's binary_logloss: 0.412514\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  80%|########  | 16/20 [00:50<00:10,  2.54s/it]\u001b[32m[I 2022-09-14 22:39:08,734]\u001b[0m Trial 22 finished with value: 0.4287186413059364 and parameters: {'num_leaves': 102}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  80%|########  | 16/20 [00:50<00:10,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.136931\tVal's binary_logloss: 0.428719\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  85%|########5 | 17/20 [00:51<00:06,  2.09s/it]\u001b[32m[I 2022-09-14 22:39:09,767]\u001b[0m Trial 23 finished with value: 0.40542757638669774 and parameters: {'num_leaves': 33}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  85%|########5 | 17/20 [00:51<00:06,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.251489\tVal's binary_logloss: 0.405428\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  90%|######### | 18/20 [00:54<00:04,  2.38s/it]\u001b[32m[I 2022-09-14 22:39:12,821]\u001b[0m Trial 24 finished with value: 0.4249793055488699 and parameters: {'num_leaves': 86}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  90%|######### | 18/20 [00:54<00:04,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.15636\tVal's binary_logloss: 0.424979\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820:  95%|#########5| 19/20 [00:59<00:03,  3.03s/it]\u001b[32m[I 2022-09-14 22:39:17,355]\u001b[0m Trial 25 finished with value: 0.4121682976749912 and parameters: {'num_leaves': 149}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820:  95%|#########5| 19/20 [00:59<00:03,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's binary_logloss: 0.229823\tVal's binary_logloss: 0.412168\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.397820: 100%|##########| 20/20 [01:00<00:00,  2.58s/it]\u001b[32m[I 2022-09-14 22:39:18,902]\u001b[0m Trial 26 finished with value: 0.39802596382785654 and parameters: {'num_leaves': 22}. Best is trial 7 with value: 0.39802596382785654.\u001b[0m\n",
      "num_leaves, val_score: 0.397820: 100%|##########| 20/20 [01:00<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.287149\tVal's binary_logloss: 0.398026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.397820:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.397820:  10%|#         | 1/10 [00:01<00:16,  1.85s/it]\u001b[32m[I 2022-09-14 22:39:20,763]\u001b[0m Trial 27 finished with value: 0.4010643168919467 and parameters: {'bagging_fraction': 0.8682435323098195, 'bagging_freq': 2}. Best is trial 27 with value: 0.4010643168919467.\u001b[0m\n",
      "bagging, val_score: 0.397820:  10%|#         | 1/10 [00:01<00:16,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.254467\tVal's binary_logloss: 0.401064\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.397820:  20%|##        | 2/10 [00:03<00:14,  1.86s/it]\u001b[32m[I 2022-09-14 22:39:22,628]\u001b[0m Trial 28 finished with value: 0.4089746291499714 and parameters: {'bagging_fraction': 0.5356027489771564, 'bagging_freq': 1}. Best is trial 27 with value: 0.4010643168919467.\u001b[0m\n",
      "bagging, val_score: 0.397820:  20%|##        | 2/10 [00:03<00:14,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.259613\tVal's binary_logloss: 0.408975\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.397820:  30%|###       | 3/10 [00:05<00:12,  1.79s/it]\u001b[32m[I 2022-09-14 22:39:24,334]\u001b[0m Trial 29 finished with value: 0.41573230912313575 and parameters: {'bagging_fraction': 0.5162738821629058, 'bagging_freq': 6}. Best is trial 27 with value: 0.4010643168919467.\u001b[0m\n",
      "bagging, val_score: 0.397820:  30%|###       | 3/10 [00:05<00:12,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.261228\tVal's binary_logloss: 0.415732\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.396645:  40%|####      | 4/10 [00:06<00:10,  1.68s/it]\u001b[32m[I 2022-09-14 22:39:25,852]\u001b[0m Trial 30 finished with value: 0.3966447823378616 and parameters: {'bagging_fraction': 0.9795223683291381, 'bagging_freq': 2}. Best is trial 30 with value: 0.3966447823378616.\u001b[0m\n",
      "bagging, val_score: 0.396645:  40%|####      | 4/10 [00:06<00:10,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255415\tVal's binary_logloss: 0.396645\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.396645:  50%|#####     | 5/10 [00:08<00:07,  1.57s/it]\u001b[32m[I 2022-09-14 22:39:27,214]\u001b[0m Trial 31 finished with value: 0.4053096618584152 and parameters: {'bagging_fraction': 0.6257939802969035, 'bagging_freq': 7}. Best is trial 30 with value: 0.3966447823378616.\u001b[0m\n",
      "bagging, val_score: 0.396645:  50%|#####     | 5/10 [00:08<00:07,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.257217\tVal's binary_logloss: 0.40531\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.396645:  60%|######    | 6/10 [00:10<00:07,  1.80s/it]\u001b[32m[I 2022-09-14 22:39:29,471]\u001b[0m Trial 32 finished with value: 0.41754263432727545 and parameters: {'bagging_fraction': 0.5543465407352801, 'bagging_freq': 4}. Best is trial 30 with value: 0.3966447823378616.\u001b[0m\n",
      "bagging, val_score: 0.396645:  60%|######    | 6/10 [00:10<00:07,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.260968\tVal's binary_logloss: 0.417543\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.396645:  70%|#######   | 7/10 [00:11<00:04,  1.58s/it]\u001b[32m[I 2022-09-14 22:39:30,589]\u001b[0m Trial 33 finished with value: 0.40510878136484657 and parameters: {'bagging_fraction': 0.7515222482257531, 'bagging_freq': 7}. Best is trial 30 with value: 0.3966447823378616.\u001b[0m\n",
      "bagging, val_score: 0.396645:  70%|#######   | 7/10 [00:11<00:04,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.2553\tVal's binary_logloss: 0.405109\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.396645:  80%|########  | 8/10 [00:14<00:03,  1.88s/it]\u001b[32m[I 2022-09-14 22:39:33,102]\u001b[0m Trial 34 finished with value: 0.4039110277908989 and parameters: {'bagging_fraction': 0.7701585317422344, 'bagging_freq': 1}. Best is trial 30 with value: 0.3966447823378616.\u001b[0m\n",
      "bagging, val_score: 0.396645:  80%|########  | 8/10 [00:14<00:03,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253249\tVal's binary_logloss: 0.403911\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.396645:  90%|######### | 9/10 [00:15<00:01,  1.85s/it]\u001b[32m[I 2022-09-14 22:39:34,913]\u001b[0m Trial 35 finished with value: 0.40759990127431395 and parameters: {'bagging_fraction': 0.6348678791355108, 'bagging_freq': 7}. Best is trial 30 with value: 0.3966447823378616.\u001b[0m\n",
      "bagging, val_score: 0.396645:  90%|######### | 9/10 [00:16<00:01,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.25468\tVal's binary_logloss: 0.4076\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.396645: 100%|##########| 10/10 [00:18<00:00,  2.11s/it]\u001b[32m[I 2022-09-14 22:39:37,609]\u001b[0m Trial 36 finished with value: 0.39778286603767443 and parameters: {'bagging_fraction': 0.7908314821164101, 'bagging_freq': 7}. Best is trial 30 with value: 0.3966447823378616.\u001b[0m\n",
      "bagging, val_score: 0.396645: 100%|##########| 10/10 [00:18<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.254226\tVal's binary_logloss: 0.397783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.396645:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.396645:  17%|#6        | 1/6 [00:01<00:06,  1.32s/it]\u001b[32m[I 2022-09-14 22:39:38,945]\u001b[0m Trial 37 finished with value: 0.39970649013728504 and parameters: {'feature_fraction': 0.748}. Best is trial 37 with value: 0.39970649013728504.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.396645:  17%|#6        | 1/6 [00:01<00:06,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.251455\tVal's binary_logloss: 0.399706\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.396645:  33%|###3      | 2/6 [00:02<00:05,  1.35s/it]\u001b[32m[I 2022-09-14 22:39:40,314]\u001b[0m Trial 38 finished with value: 0.39970649013728504 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 37 with value: 0.39970649013728504.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.396645:  33%|###3      | 2/6 [00:02<00:05,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.251455\tVal's binary_logloss: 0.399706\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.396645:  50%|#####     | 3/6 [00:04<00:04,  1.38s/it]\u001b[32m[I 2022-09-14 22:39:41,729]\u001b[0m Trial 39 finished with value: 0.3966447823378616 and parameters: {'feature_fraction': 0.716}. Best is trial 39 with value: 0.3966447823378616.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.396645:  50%|#####     | 3/6 [00:04<00:04,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255415\tVal's binary_logloss: 0.396645\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.396645:  67%|######6   | 4/6 [00:05<00:02,  1.39s/it]\u001b[32m[I 2022-09-14 22:39:43,141]\u001b[0m Trial 40 finished with value: 0.3966447823378616 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 39 with value: 0.3966447823378616.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.396645:  67%|######6   | 4/6 [00:05<00:02,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255415\tVal's binary_logloss: 0.396645\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.396645:  83%|########3 | 5/6 [00:07<00:01,  1.53s/it]\u001b[32m[I 2022-09-14 22:39:44,921]\u001b[0m Trial 41 finished with value: 0.3998648823162589 and parameters: {'feature_fraction': 0.652}. Best is trial 39 with value: 0.3966447823378616.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.396645:  83%|########3 | 5/6 [00:07<00:01,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.256699\tVal's binary_logloss: 0.399865\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.396645: 100%|##########| 6/6 [00:08<00:00,  1.50s/it]\u001b[32m[I 2022-09-14 22:39:46,362]\u001b[0m Trial 42 finished with value: 0.3998648823162589 and parameters: {'feature_fraction': 0.62}. Best is trial 39 with value: 0.3966447823378616.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.396645: 100%|##########| 6/6 [00:08<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.256699\tVal's binary_logloss: 0.399865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396645:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396645:   5%|5         | 1/20 [00:01<00:30,  1.58s/it]\u001b[32m[I 2022-09-14 22:39:47,952]\u001b[0m Trial 43 finished with value: 0.3966450494703975 and parameters: {'lambda_l1': 3.7508003587799644e-06, 'lambda_l2': 0.00010395337703180814}. Best is trial 43 with value: 0.3966450494703975.\u001b[0m\n",
      "regularization_factors, val_score: 0.396645:   5%|5         | 1/20 [00:01<00:30,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255416\tVal's binary_logloss: 0.396645\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396601:  10%|#         | 2/20 [00:03<00:27,  1.51s/it]\u001b[32m[I 2022-09-14 22:39:49,414]\u001b[0m Trial 44 finished with value: 0.3966013823804623 and parameters: {'lambda_l1': 2.5101211114806636e-06, 'lambda_l2': 2.385588490975511e-07}. Best is trial 44 with value: 0.3966013823804623.\u001b[0m\n",
      "regularization_factors, val_score: 0.396601:  10%|#         | 2/20 [00:03<00:27,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255414\tVal's binary_logloss: 0.396601\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396601:  15%|#5        | 3/20 [00:04<00:23,  1.40s/it]\u001b[32m[I 2022-09-14 22:39:50,689]\u001b[0m Trial 45 finished with value: 0.39800610788136376 and parameters: {'lambda_l1': 2.5842054324347927, 'lambda_l2': 1.1603021070427544e-08}. Best is trial 44 with value: 0.3966013823804623.\u001b[0m\n",
      "regularization_factors, val_score: 0.396601:  15%|#5        | 3/20 [00:04<00:23,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.280278\tVal's binary_logloss: 0.398006\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396601:  20%|##        | 4/20 [00:05<00:23,  1.47s/it]\u001b[32m[I 2022-09-14 22:39:52,249]\u001b[0m Trial 46 finished with value: 0.3966043799040582 and parameters: {'lambda_l1': 2.7006560866946153e-07, 'lambda_l2': 3.8684159707815444e-08}. Best is trial 44 with value: 0.3966013823804623.\u001b[0m\n",
      "regularization_factors, val_score: 0.396601:  20%|##        | 4/20 [00:05<00:23,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255414\tVal's binary_logloss: 0.396604\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396601:  25%|##5       | 5/20 [00:07<00:21,  1.41s/it]\u001b[32m[I 2022-09-14 22:39:53,576]\u001b[0m Trial 47 finished with value: 0.4075635306236927 and parameters: {'lambda_l1': 8.671910818062688, 'lambda_l2': 7.502759064546698}. Best is trial 44 with value: 0.3966013823804623.\u001b[0m\n",
      "regularization_factors, val_score: 0.396601:  25%|##5       | 5/20 [00:07<00:21,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.339463\tVal's binary_logloss: 0.407564\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396601:  30%|###       | 6/20 [00:08<00:18,  1.32s/it]\u001b[32m[I 2022-09-14 22:39:54,720]\u001b[0m Trial 48 finished with value: 0.39800366181584407 and parameters: {'lambda_l1': 0.003033294793700279, 'lambda_l2': 0.010872640279577385}. Best is trial 44 with value: 0.3966013823804623.\u001b[0m\n",
      "regularization_factors, val_score: 0.396601:  30%|###       | 6/20 [00:08<00:18,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253399\tVal's binary_logloss: 0.398004\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396600:  35%|###5      | 7/20 [00:09<00:15,  1.23s/it]\u001b[32m[I 2022-09-14 22:39:55,749]\u001b[0m Trial 49 finished with value: 0.39660018399050123 and parameters: {'lambda_l1': 1.3758102533706968e-05, 'lambda_l2': 2.6242654555684143e-07}. Best is trial 49 with value: 0.39660018399050123.\u001b[0m\n",
      "regularization_factors, val_score: 0.396600:  35%|###5      | 7/20 [00:09<00:15,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255414\tVal's binary_logloss: 0.3966\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396600:  40%|####      | 8/20 [00:10<00:13,  1.16s/it]\u001b[32m[I 2022-09-14 22:39:56,753]\u001b[0m Trial 50 finished with value: 0.3966070248422127 and parameters: {'lambda_l1': 4.373907424717698e-05, 'lambda_l2': 2.9213471075136283e-06}. Best is trial 49 with value: 0.39660018399050123.\u001b[0m\n",
      "regularization_factors, val_score: 0.396600:  40%|####      | 8/20 [00:10<00:13,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255416\tVal's binary_logloss: 0.396607\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396600:  45%|####5     | 9/20 [00:11<00:11,  1.09s/it]\u001b[32m[I 2022-09-14 22:39:57,689]\u001b[0m Trial 51 finished with value: 0.397497013726351 and parameters: {'lambda_l1': 0.00038127727199657697, 'lambda_l2': 0.00016621533721395199}. Best is trial 49 with value: 0.39660018399050123.\u001b[0m\n",
      "regularization_factors, val_score: 0.396600:  45%|####5     | 9/20 [00:11<00:11,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.257665\tVal's binary_logloss: 0.397497\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396600:  50%|#####     | 10/20 [00:12<00:10,  1.04s/it]\u001b[32m[I 2022-09-14 22:39:58,630]\u001b[0m Trial 52 finished with value: 0.396625078479234 and parameters: {'lambda_l1': 3.3094949725389014e-07, 'lambda_l2': 1.099391114954208e-06}. Best is trial 49 with value: 0.39660018399050123.\u001b[0m\n",
      "regularization_factors, val_score: 0.396600:  50%|#####     | 10/20 [00:12<00:10,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255414\tVal's binary_logloss: 0.396625\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396600:  55%|#####5    | 11/20 [00:13<00:09,  1.01s/it]\u001b[32m[I 2022-09-14 22:39:59,578]\u001b[0m Trial 53 finished with value: 0.39713092898123686 and parameters: {'lambda_l1': 0.024951892089004682, 'lambda_l2': 0.012407473377033459}. Best is trial 49 with value: 0.39660018399050123.\u001b[0m\n",
      "regularization_factors, val_score: 0.396600:  55%|#####5    | 11/20 [00:13<00:09,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.256829\tVal's binary_logloss: 0.397131\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396600:  60%|######    | 12/20 [00:14<00:07,  1.01it/s]\u001b[32m[I 2022-09-14 22:40:00,512]\u001b[0m Trial 54 finished with value: 0.39662102178314573 and parameters: {'lambda_l1': 2.1184282236068466e-08, 'lambda_l2': 6.813596409665106e-07}. Best is trial 49 with value: 0.39660018399050123.\u001b[0m\n",
      "regularization_factors, val_score: 0.396600:  60%|######    | 12/20 [00:14<00:07,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255415\tVal's binary_logloss: 0.396621\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396600:  65%|######5   | 13/20 [00:15<00:06,  1.00it/s]\u001b[32m[I 2022-09-14 22:40:01,526]\u001b[0m Trial 55 finished with value: 0.3966081271803817 and parameters: {'lambda_l1': 1.1496982782113443e-05, 'lambda_l2': 8.763376301942837e-06}. Best is trial 49 with value: 0.39660018399050123.\u001b[0m\n",
      "regularization_factors, val_score: 0.396600:  65%|######5   | 13/20 [00:15<00:06,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255416\tVal's binary_logloss: 0.396608\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396600:  70%|#######   | 14/20 [00:16<00:06,  1.02s/it]\u001b[32m[I 2022-09-14 22:40:02,593]\u001b[0m Trial 56 finished with value: 0.3966013934496742 and parameters: {'lambda_l1': 8.322572688144272e-07, 'lambda_l2': 1.561571887840665e-07}. Best is trial 49 with value: 0.39660018399050123.\u001b[0m\n",
      "regularization_factors, val_score: 0.396600:  70%|#######   | 14/20 [00:16<00:06,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255415\tVal's binary_logloss: 0.396601\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396600:  75%|#######5  | 15/20 [00:17<00:04,  1.00it/s]\u001b[32m[I 2022-09-14 22:40:03,547]\u001b[0m Trial 57 finished with value: 0.3966930938084698 and parameters: {'lambda_l1': 1.5806477218443705e-08, 'lambda_l2': 1.253769156071333e-05}. Best is trial 49 with value: 0.39660018399050123.\u001b[0m\n",
      "regularization_factors, val_score: 0.396600:  75%|#######5  | 15/20 [00:17<00:04,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255414\tVal's binary_logloss: 0.396693\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.396600:  80%|########  | 16/20 [00:18<00:04,  1.06s/it]\u001b[32m[I 2022-09-14 22:40:04,762]\u001b[0m Trial 58 finished with value: 0.39940179726965047 and parameters: {'lambda_l1': 0.00010905723522558326, 'lambda_l2': 0.005273194845240828}. Best is trial 49 with value: 0.39660018399050123.\u001b[0m\n",
      "regularization_factors, val_score: 0.396600:  80%|########  | 16/20 [00:18<00:04,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.254717\tVal's binary_logloss: 0.399402\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.395728:  85%|########5 | 17/20 [00:19<00:03,  1.12s/it]\u001b[32m[I 2022-09-14 22:40:06,010]\u001b[0m Trial 59 finished with value: 0.3957282940458889 and parameters: {'lambda_l1': 0.0016224098620517384, 'lambda_l2': 7.073148257964443e-08}. Best is trial 59 with value: 0.3957282940458889.\u001b[0m\n",
      "regularization_factors, val_score: 0.395728:  85%|########5 | 17/20 [00:19<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255526\tVal's binary_logloss: 0.395728\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.395728:  90%|######### | 18/20 [00:21<00:02,  1.34s/it]\u001b[32m[I 2022-09-14 22:40:07,860]\u001b[0m Trial 60 finished with value: 0.39803746552764996 and parameters: {'lambda_l1': 0.08245697730164447, 'lambda_l2': 1.665990260439055}. Best is trial 59 with value: 0.3957282940458889.\u001b[0m\n",
      "regularization_factors, val_score: 0.395728:  90%|######### | 18/20 [00:21<00:02,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.266814\tVal's binary_logloss: 0.398037\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.395728:  95%|#########5| 19/20 [00:22<00:01,  1.27s/it]\u001b[32m[I 2022-09-14 22:40:08,979]\u001b[0m Trial 61 finished with value: 0.3974952386766477 and parameters: {'lambda_l1': 0.001022548850410787, 'lambda_l2': 4.8471462865016376e-08}. Best is trial 59 with value: 0.3957282940458889.\u001b[0m\n",
      "regularization_factors, val_score: 0.395728:  95%|#########5| 19/20 [00:22<00:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.257673\tVal's binary_logloss: 0.397495\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.395728: 100%|##########| 20/20 [00:23<00:00,  1.17s/it]\u001b[32m[I 2022-09-14 22:40:09,901]\u001b[0m Trial 62 finished with value: 0.3967812099818965 and parameters: {'lambda_l1': 0.016639267322085635, 'lambda_l2': 2.8758771772490606e-05}. Best is trial 59 with value: 0.3957282940458889.\u001b[0m\n",
      "regularization_factors, val_score: 0.395728: 100%|##########| 20/20 [00:23<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.256325\tVal's binary_logloss: 0.396781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.395728:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.395728:  20%|##        | 1/5 [00:00<00:03,  1.07it/s]\u001b[32m[I 2022-09-14 22:40:10,847]\u001b[0m Trial 63 finished with value: 0.40196245418197174 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.40196245418197174.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.395728:  20%|##        | 1/5 [00:00<00:03,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.264778\tVal's binary_logloss: 0.401962\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.395728:  40%|####      | 2/5 [00:01<00:02,  1.12it/s]\u001b[32m[I 2022-09-14 22:40:11,707]\u001b[0m Trial 64 finished with value: 0.4065906047069732 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.40196245418197174.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.395728:  40%|####      | 2/5 [00:01<00:02,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.278114\tVal's binary_logloss: 0.406591\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.395728:  60%|######    | 3/5 [00:02<00:01,  1.12it/s]\u001b[32m[I 2022-09-14 22:40:12,597]\u001b[0m Trial 65 finished with value: 0.3968084918094646 and parameters: {'min_child_samples': 10}. Best is trial 65 with value: 0.3968084918094646.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.395728:  60%|######    | 3/5 [00:02<00:01,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.253136\tVal's binary_logloss: 0.396808\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.395728:  80%|########  | 4/5 [00:03<00:00,  1.15it/s]\u001b[32m[I 2022-09-14 22:40:13,440]\u001b[0m Trial 66 finished with value: 0.39584489835361286 and parameters: {'min_child_samples': 5}. Best is trial 66 with value: 0.39584489835361286.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.395728:  80%|########  | 4/5 [00:03<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.248393\tVal's binary_logloss: 0.395845\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 16\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.395728: 100%|##########| 5/5 [00:04<00:00,  1.16it/s]\u001b[32m[I 2022-09-14 22:40:14,288]\u001b[0m Trial 67 finished with value: 0.3974526138516078 and parameters: {'min_child_samples': 25}. Best is trial 66 with value: 0.39584489835361286.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.395728: 100%|##########| 5/5 [00:04<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's binary_logloss: 0.255925\tVal's binary_logloss: 0.397453\n",
      "fold 4/acc: 0.8107019562715765\n",
      "CV score: 0.8164042798031487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "val_scores = []\n",
    "models = []\n",
    "best_params = []\n",
    "for fold, (train_inds, val_inds) in enumerate(kf.split(x_trainval)):\n",
    "    \n",
    "    x_train, x_val = x_trainval[train_inds], x_trainval[val_inds]\n",
    "    y_train, y_val = y_trainval[train_inds], y_trainval[val_inds]\n",
    "\n",
    "    lgb_train = opt_lgb.Dataset(x_train, y_train)\n",
    "    lgb_val = opt_lgb.Dataset(x_val, y_val, reference=lgb_train)\n",
    "    \n",
    "    lgb_results = {}\n",
    "    model = opt_lgb.train(\n",
    "                    params,                    # ハイパーパラメータをセット\n",
    "                    lgb_train,              # 訓練データを訓練用にセット\n",
    "                    valid_sets=[lgb_train, lgb_val], # 訓練データとテストデータをセット\n",
    "                    valid_names=['Train', 'Val'],    # データセットの名前をそれぞれ設定\n",
    "                    num_boost_round=100,              # 計算回数\n",
    "                    early_stopping_rounds=50,         # アーリーストッピング設定\n",
    "                    evals_result=lgb_results,\n",
    "                    verbose_eval=0,\n",
    "                    )  \n",
    "    best_params.append(model.params)\n",
    "\n",
    "    y_val_proba = model.predict(x_val, num_iteration=model.best_iteration)\n",
    "    y_val_pred = np.where(y_val_proba < 0.5, 0, 1)\n",
    "    score = accuracy_score(y_val, y_val_pred)\n",
    "    print(f'fold {fold}/acc: {score}')\n",
    "    val_scores.append(score)\n",
    "    models.append(model)\n",
    "\n",
    "cv_score = np.mean(val_scores)\n",
    "print(f'CV score: {cv_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d2c3c48-ab62-436c-8b9c-78e6b8d7e232",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=0'>1</a>\u001b[0m importance \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(models)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=3'>4</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(models[i]\u001b[39m.\u001b[39;49mfeature_importances_,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=4'>5</a>\u001b[0m                       index\u001b[39m=\u001b[39mtrainval\u001b[39m.\u001b[39mcolumns[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], columns\u001b[39m=\u001b[39m[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=5'>6</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msort_values(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=6'>7</a>\u001b[0m     importance \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([importance, df], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "importance = pd.DataFrame()\n",
    "\n",
    "for i in range(len(models)):\n",
    "    df = pd.DataFrame(models[i].feature_importances_,\n",
    "                      index=trainval.columns[:-1], columns=[f'model{i+1}'])\n",
    "    df = df.sort_values(f'model{i+1}', ascending=False)\n",
    "    importance = pd.concat([importance, df], axis=1)\n",
    "\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151b9b9-a1c7-4d5a-8501-38e9820ac4fc",
   "metadata": {},
   "source": [
    "### submit用のcsv作成\n",
    "\n",
    "cvごとの推論の単純平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4459b75c-690c-409e-b622-30f068561a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    predictor = models[i]\n",
    "    y_pred = predictor.predict(x_test, num_iteration=model.best_iteration)\n",
    "    y_preds.append(y_pred)\n",
    "ensemble = np.where(np.mean(y_preds, axis=0) < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26e62e7f-7e25-4b9b-8a58-bf68df56393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv('../../dataset/test.csv')['PassengerId']\n",
    "\n",
    "df_submit = pd.DataFrame(ensemble, index=test_ids, columns=['Transported'])\n",
    "df_submit.Transported = df_submit.Transported.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3e7c2dd-7152-449a-8f20-600b9047d49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0013_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0018_01</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0019_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0021_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0023_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9266_02</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9269_01</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9271_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9277_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Transported\n",
       "PassengerId             \n",
       "0013_01             True\n",
       "0018_01            False\n",
       "0019_01             True\n",
       "0021_01             True\n",
       "0023_01             True\n",
       "...                  ...\n",
       "9266_02             True\n",
       "9269_01            False\n",
       "9271_01             True\n",
       "9273_01             True\n",
       "9277_01             True\n",
       "\n",
       "[4277 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76ff1c0f-05f2-4e90-9b8c-0242f97b00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('submission/lgbm_trial5_optuna.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4588e-d121-4526-a80b-d003509fae4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
