{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe19873-9ec2-489b-9a9e-c85a167f5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a71c2447-e029-44c2-a5dd-f81f3135b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/6qwnpvfn0cs2whczwk_5pvqh0000gs/T/ipykernel_4163/1372198113.py:5: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n",
      "  train_test = pd.concat([train, test], axis=0, ignore_index=True, sort=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>GroupId</th>\n",
       "      <th>PeopleId</th>\n",
       "      <th>IsGroup</th>\n",
       "      <th>TotalBill</th>\n",
       "      <th>IsAdult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>0001</td>\n",
       "      <td>01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0002</td>\n",
       "      <td>01</td>\n",
       "      <td>False</td>\n",
       "      <td>736.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0003</td>\n",
       "      <td>01</td>\n",
       "      <td>True</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0003</td>\n",
       "      <td>02</td>\n",
       "      <td>True</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0004</td>\n",
       "      <td>01</td>\n",
       "      <td>False</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...               Name  Transported  \\\n",
       "0          0.0        0.0           0.0  ...    Maham Ofracculy          0.0   \n",
       "1        109.0        9.0          25.0  ...       Juanna Vines          1.0   \n",
       "2         43.0     3576.0           0.0  ...      Altark Susent          0.0   \n",
       "3          0.0     1283.0         371.0  ...       Solam Susent          0.0   \n",
       "4        303.0       70.0         151.0  ...  Willy Santantines          1.0   \n",
       "\n",
       "  CabinDeck  CabinNum CabinSide  GroupId PeopleId IsGroup TotalBill  IsAdult  \n",
       "0         B       0.0         P     0001       01   False       0.0     True  \n",
       "1         F       0.0         S     0002       01   False     736.0     True  \n",
       "2         A       0.0         S     0003       01    True   10383.0     True  \n",
       "3         A       0.0         S     0003       02    True    5176.0     True  \n",
       "4         F       1.0         S     0004       01   False    1091.0    False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../dataset/train.csv')\n",
    "test = pd.read_csv('../../dataset/test.csv')\n",
    "# 前処理を一度にやるためにtrainとtestをconcatする\n",
    "test['Transported'] = np.nan\n",
    "train_test = pd.concat([train, test], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# split on `/` to cols (deck/num/side)\n",
    "def split_cabin(df):\n",
    "    cabin = df['Cabin'].str.split('/', expand=True).rename(columns={0: 'CabinDeck', 1: 'CabinNum', 2: 'CabinSide'})\n",
    "    cabin['CabinNum'] = cabin['CabinNum'].astype(float)\n",
    "    return pd.concat([df, cabin], axis=1)\n",
    "\n",
    "# group passenger or not\n",
    "def make_group(df):\n",
    "    df['GroupId'] = df['PassengerId'].apply(lambda x: x.split('_')[0])\n",
    "    df['PeopleId'] = df['PassengerId'].apply(lambda x: x.split('_')[1])\n",
    "    df['IsGroup'] = df['GroupId'].duplicated(keep=False)\n",
    "    return df\n",
    "\n",
    "# total room service, etc...\n",
    "def total_bill(df):\n",
    "    df['TotalBill'] = df[\n",
    "        ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def is_adult(df):\n",
    "    df['IsAdult'] = df['Age'] >= 18\n",
    "    return df\n",
    "\n",
    "train_test = split_cabin(train_test)\n",
    "train_test = make_group(train_test)\n",
    "train_test = total_bill(train_test)\n",
    "train_test = is_adult(train_test)\n",
    "\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b13abd-68c8-479d-b158-b6a5cbbf99bd",
   "metadata": {},
   "source": [
    "### 使う特徴量を選ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd293eac-97b4-4270-acbf-208d3a1ab133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>IsGroup</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>TotalBill</th>\n",
       "      <th>IsAdult</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet CryoSleep  Destination   Age    VIP CabinDeck  CabinNum  \\\n",
       "0     Europa     False  TRAPPIST-1e  39.0  False         B       0.0   \n",
       "1      Earth     False  TRAPPIST-1e  24.0  False         F       0.0   \n",
       "2     Europa     False  TRAPPIST-1e  58.0   True         A       0.0   \n",
       "3     Europa     False  TRAPPIST-1e  33.0  False         A       0.0   \n",
       "4      Earth     False  TRAPPIST-1e  16.0  False         F       1.0   \n",
       "\n",
       "  CabinSide  IsGroup  RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  \\\n",
       "0         P    False          0.0        0.0           0.0     0.0     0.0   \n",
       "1         S    False        109.0        9.0          25.0   549.0    44.0   \n",
       "2         S     True         43.0     3576.0           0.0  6715.0    49.0   \n",
       "3         S     True          0.0     1283.0         371.0  3329.0   193.0   \n",
       "4         S    False        303.0       70.0         151.0   565.0     2.0   \n",
       "\n",
       "   TotalBill  IsAdult  Transported  \n",
       "0        0.0     True          0.0  \n",
       "1      736.0     True          1.0  \n",
       "2    10383.0     True          0.0  \n",
       "3     5176.0     True          0.0  \n",
       "4     1091.0    False          1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test = train_test[['HomePlanet', 'CryoSleep', 'Destination', 'Age', 'VIP', 'CabinDeck', 'CabinNum', 'CabinSide', 'IsGroup', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalBill', 'IsAdult', 'Transported']]\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd679fd7",
   "metadata": {},
   "source": [
    "### 欠損値を埋める\n",
    "\n",
    "- HomePlanet→最頻値\n",
    "- CryoSleep→最頻値\n",
    "- Destination→最頻値\n",
    "- Age→中央値で埋める\n",
    "- VIP→VIPなしで埋める\n",
    "- CabinNum→最頻値で埋める\n",
    "- CabinSide→CabinNum==82となっているCabinSideの最頻値で埋める？→Pで埋める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f1e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_test.columns:\n",
    "    if col == 'Transported':\n",
    "        continue\n",
    "    elif col == 'CabinSide':\n",
    "        train_test[col] = train_test[col].fillna('P')\n",
    "    elif col == 'VIP':\n",
    "        train_test[col] = train_test[col].fillna(False)\n",
    "    elif col == 'Age':\n",
    "        train_test[col] = train_test[col].fillna(train_test[col].median())\n",
    "    else:\n",
    "        train_test[col] = train_test[col].fillna(train_test[col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9483535-afa5-4f1c-8ba7-264aee7a3dcc",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00295ee-a09b-41cd-a287-9dc73879dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HomePlanet, Destination, CabinSideはonehot encoding\n",
    "for col in ['HomePlanet', 'Destination', 'CabinDeck', 'CabinSide']:\n",
    "    train_test = pd.concat([train_test,  pd.get_dummies(train_test[col], prefix=col)], axis=1)\n",
    "    train_test = train_test.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df6d12e2-e7f0-4c2e-a9d1-7344ee92dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolをintへ\n",
    "def bool2int(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == bool:\n",
    "            df[col] = df[col].astype(float)\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].map({True: 1, False: 0})\n",
    "    return df\n",
    "\n",
    "train_test = bool2int(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "893c3a9a-9053-4d01-9cbb-c3af6657f8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>IsGroup</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>...</th>\n",
       "      <th>CabinDeck_A</th>\n",
       "      <th>CabinDeck_B</th>\n",
       "      <th>CabinDeck_C</th>\n",
       "      <th>CabinDeck_D</th>\n",
       "      <th>CabinDeck_E</th>\n",
       "      <th>CabinDeck_F</th>\n",
       "      <th>CabinDeck_G</th>\n",
       "      <th>CabinDeck_T</th>\n",
       "      <th>CabinSide_P</th>\n",
       "      <th>CabinSide_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12965</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12966</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12967</th>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12968</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12969</th>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12970 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CryoSleep   Age  VIP  CabinNum  IsGroup  RoomService  FoodCourt  \\\n",
       "0            0.0  39.0  0.0       0.0      0.0          0.0        0.0   \n",
       "1            0.0  24.0  0.0       0.0      0.0        109.0        9.0   \n",
       "2            0.0  58.0  1.0       0.0      1.0         43.0     3576.0   \n",
       "3            0.0  33.0  0.0       0.0      1.0          0.0     1283.0   \n",
       "4            0.0  16.0  0.0       1.0      0.0        303.0       70.0   \n",
       "...          ...   ...  ...       ...      ...          ...        ...   \n",
       "12965        1.0  34.0  0.0    1496.0      1.0          0.0        0.0   \n",
       "12966        0.0  42.0  0.0      82.0      0.0          0.0      847.0   \n",
       "12967        1.0  27.0  0.0     296.0      0.0          0.0        0.0   \n",
       "12968        0.0  27.0  0.0     297.0      0.0          0.0     2680.0   \n",
       "12969        1.0  43.0  0.0    1498.0      0.0          0.0        0.0   \n",
       "\n",
       "       ShoppingMall     Spa  VRDeck  ...  CabinDeck_A  CabinDeck_B  \\\n",
       "0               0.0     0.0     0.0  ...            0            1   \n",
       "1              25.0   549.0    44.0  ...            0            0   \n",
       "2               0.0  6715.0    49.0  ...            1            0   \n",
       "3             371.0  3329.0   193.0  ...            1            0   \n",
       "4             151.0   565.0     2.0  ...            0            0   \n",
       "...             ...     ...     ...  ...          ...          ...   \n",
       "12965           0.0     0.0     0.0  ...            0            0   \n",
       "12966          17.0    10.0   144.0  ...            0            0   \n",
       "12967           0.0     0.0     0.0  ...            0            0   \n",
       "12968           0.0     0.0   523.0  ...            0            0   \n",
       "12969           0.0     0.0     0.0  ...            0            0   \n",
       "\n",
       "       CabinDeck_C  CabinDeck_D  CabinDeck_E  CabinDeck_F  CabinDeck_G  \\\n",
       "0                0            0            0            0            0   \n",
       "1                0            0            0            1            0   \n",
       "2                0            0            0            0            0   \n",
       "3                0            0            0            0            0   \n",
       "4                0            0            0            1            0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "12965            0            0            0            0            1   \n",
       "12966            0            0            0            1            0   \n",
       "12967            0            1            0            0            0   \n",
       "12968            0            1            0            0            0   \n",
       "12969            0            0            0            0            1   \n",
       "\n",
       "       CabinDeck_T  CabinSide_P  CabinSide_S  \n",
       "0                0            1            0  \n",
       "1                0            0            1  \n",
       "2                0            0            1  \n",
       "3                0            0            1  \n",
       "4                0            0            1  \n",
       "...            ...          ...          ...  \n",
       "12965            0            0            1  \n",
       "12966            0            1            0  \n",
       "12967            0            1            0  \n",
       "12968            0            1            0  \n",
       "12969            0            0            1  \n",
       "\n",
       "[12970 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8968f15-7beb-4812-8a0b-34a01ca78706",
   "metadata": {},
   "source": [
    "### モデリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fdd3ad9-ef1f-44e8-85af-e82c1f98b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgbm\n",
    "import optuna.integration.lightgbm as opt_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b001a28-4bb3-47d4-a33e-0718848045c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.1,\n",
    "    'importance_type': 'gain',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7fb96-da28-4596-b01a-9cf413b4cdc9",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12159b79-3081-420f-bcf6-c362e1888c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c287669-65a1-4e2f-ae1b-a712c2974490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=3407):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "SEED = 3407\n",
    "set_seed(SEED)\n",
    "params.update(dict(seed=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dae376e3-e139-4686-92a5-69ddc921112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameをnp.ndarrayに変換\n",
    "trainval = train_test[~train_test['Transported'].isna()]\n",
    "test = train_test[train_test['Transported'].isna()]\n",
    "# inputとlabelに分離\n",
    "x_trainval = trainval.drop('Transported', axis=1).values\n",
    "y_trainval = trainval.Transported.values\n",
    "x_test = test.drop('Transported', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b78f65b-261d-4d0f-b136-2ec06c7794f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 28), (8693,), (4277, 28))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trainval.shape, y_trainval.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "221e97d9-6672-4c85-8a22-8faae4735542",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-01 17:10:19,976]\u001b[0m A new study created in memory with name: no-name-92397092-623c-4d34-82f3-4b20067ad49b\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.395422:  14%|#4        | 1/7 [00:01<00:06,  1.08s/it]\u001b[32m[I 2022-10-01 17:10:21,089]\u001b[0m Trial 0 finished with value: 0.3954219458878241 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.3954219458878241.\u001b[0m\n",
      "feature_fraction, val_score: 0.395422:  14%|#4        | 1/7 [00:01<00:06,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.391330:  29%|##8       | 2/7 [00:01<00:03,  1.31it/s]\u001b[32m[I 2022-10-01 17:10:21,630]\u001b[0m Trial 1 finished with value: 0.3913297806985938 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.3913297806985938.\u001b[0m\n",
      "feature_fraction, val_score: 0.391330:  29%|##8       | 2/7 [00:01<00:03,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.389325:  43%|####2     | 3/7 [00:02<00:03,  1.20it/s]\u001b[32m[I 2022-10-01 17:10:22,550]\u001b[0m Trial 2 finished with value: 0.3893254734477095 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.3893254734477095.\u001b[0m\n",
      "feature_fraction, val_score: 0.389325:  43%|####2     | 3/7 [00:02<00:03,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.389325:  57%|#####7    | 4/7 [00:03<00:02,  1.37it/s]\u001b[32m[I 2022-10-01 17:10:23,125]\u001b[0m Trial 3 finished with value: 0.3897679315068959 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.3893254734477095.\u001b[0m\n",
      "feature_fraction, val_score: 0.389325:  57%|#####7    | 4/7 [00:03<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.389325:  71%|#######1  | 5/7 [00:03<00:01,  1.54it/s]\u001b[32m[I 2022-10-01 17:10:23,627]\u001b[0m Trial 4 finished with value: 0.39391977166881864 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.3893254734477095.\u001b[0m\n",
      "feature_fraction, val_score: 0.389325:  71%|#######1  | 5/7 [00:03<00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.389325:  86%|########5 | 6/7 [00:04<00:00,  1.73it/s]\u001b[32m[I 2022-10-01 17:10:24,068]\u001b[0m Trial 5 finished with value: 0.390943147554657 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.3893254734477095.\u001b[0m\n",
      "feature_fraction, val_score: 0.389325:  86%|########5 | 6/7 [00:04<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.389325: 100%|##########| 7/7 [00:04<00:00,  1.81it/s]\u001b[32m[I 2022-10-01 17:10:24,565]\u001b[0m Trial 6 finished with value: 0.3894350456308911 and parameters: {'feature_fraction': 0.4}. Best is trial 2 with value: 0.3893254734477095.\u001b[0m\n",
      "feature_fraction, val_score: 0.389325: 100%|##########| 7/7 [00:04<00:00,  1.53it/s]\n",
      "num_leaves, val_score: 0.389325:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:   5%|5         | 1/20 [00:02<00:39,  2.08s/it]\u001b[32m[I 2022-10-01 17:10:26,653]\u001b[0m Trial 7 finished with value: 0.39376134417443087 and parameters: {'num_leaves': 112}. Best is trial 7 with value: 0.39376134417443087.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:   5%|5         | 1/20 [00:02<00:39,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  10%|#         | 2/20 [00:06<01:04,  3.56s/it]\u001b[32m[I 2022-10-01 17:10:31,241]\u001b[0m Trial 8 finished with value: 0.395092705815429 and parameters: {'num_leaves': 244}. Best is trial 7 with value: 0.39376134417443087.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  10%|#         | 2/20 [00:06<01:04,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  15%|#5        | 3/20 [00:07<00:38,  2.29s/it]\u001b[32m[I 2022-10-01 17:10:32,016]\u001b[0m Trial 9 finished with value: 0.3990665439271831 and parameters: {'num_leaves': 194}. Best is trial 7 with value: 0.39376134417443087.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  15%|#5        | 3/20 [00:07<00:38,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  20%|##        | 4/20 [00:07<00:25,  1.59s/it]\u001b[32m[I 2022-10-01 17:10:32,547]\u001b[0m Trial 10 finished with value: 0.394593989621536 and parameters: {'num_leaves': 144}. Best is trial 7 with value: 0.39376134417443087.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  20%|##        | 4/20 [00:07<00:25,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  25%|##5       | 5/20 [00:08<00:18,  1.20s/it]\u001b[32m[I 2022-10-01 17:10:33,062]\u001b[0m Trial 11 finished with value: 0.39380906293195456 and parameters: {'num_leaves': 132}. Best is trial 7 with value: 0.39376134417443087.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  30%|###       | 6/20 [00:08<00:11,  1.18it/s]\u001b[32m[I 2022-10-01 17:10:33,216]\u001b[0m Trial 12 finished with value: 0.3911103222592409 and parameters: {'num_leaves': 12}. Best is trial 12 with value: 0.3911103222592409.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  30%|###       | 6/20 [00:08<00:11,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  35%|###5      | 7/20 [00:08<00:08,  1.48it/s]\u001b[32m[I 2022-10-01 17:10:33,540]\u001b[0m Trial 13 finished with value: 0.3923090309326274 and parameters: {'num_leaves': 80}. Best is trial 12 with value: 0.3911103222592409.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  35%|###5      | 7/20 [00:08<00:08,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  40%|####      | 8/20 [00:09<00:07,  1.63it/s]\u001b[32m[I 2022-10-01 17:10:34,018]\u001b[0m Trial 14 finished with value: 0.3980078113163323 and parameters: {'num_leaves': 176}. Best is trial 12 with value: 0.3911103222592409.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  40%|####      | 8/20 [00:09<00:07,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  45%|####5     | 9/20 [00:10<00:06,  1.61it/s]\u001b[32m[I 2022-10-01 17:10:34,657]\u001b[0m Trial 15 finished with value: 0.39620343132943336 and parameters: {'num_leaves': 246}. Best is trial 12 with value: 0.3911103222592409.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  45%|####5     | 9/20 [00:10<00:06,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  50%|#####     | 10/20 [00:10<00:05,  1.79it/s]\u001b[32m[I 2022-10-01 17:10:35,076]\u001b[0m Trial 16 finished with value: 0.391807138589005 and parameters: {'num_leaves': 119}. Best is trial 12 with value: 0.3911103222592409.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  55%|#####5    | 11/20 [00:10<00:03,  2.29it/s]\u001b[32m[I 2022-10-01 17:10:35,235]\u001b[0m Trial 17 finished with value: 0.38935742591734485 and parameters: {'num_leaves': 17}. Best is trial 17 with value: 0.38935742591734485.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  55%|#####5    | 11/20 [00:10<00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  60%|######    | 12/20 [00:10<00:02,  2.70it/s]\u001b[32m[I 2022-10-01 17:10:35,454]\u001b[0m Trial 18 finished with value: 0.39223845438899374 and parameters: {'num_leaves': 21}. Best is trial 17 with value: 0.38935742591734485.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  60%|######    | 12/20 [00:10<00:02,  2.70it/s]\u001b[32m[I 2022-10-01 17:10:35,548]\u001b[0m Trial 19 finished with value: 0.47242463131510454 and parameters: {'num_leaves': 2}. Best is trial 17 with value: 0.38935742591734485.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  65%|######5   | 13/20 [00:10<00:02,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  70%|#######   | 14/20 [00:11<00:01,  3.50it/s]\u001b[32m[I 2022-10-01 17:10:35,830]\u001b[0m Trial 20 finished with value: 0.39582110291175193 and parameters: {'num_leaves': 41}. Best is trial 17 with value: 0.38935742591734485.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  70%|#######   | 14/20 [00:11<00:01,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  75%|#######5  | 15/20 [00:11<00:01,  3.38it/s]\u001b[32m[I 2022-10-01 17:10:36,159]\u001b[0m Trial 21 finished with value: 0.40020457816502364 and parameters: {'num_leaves': 59}. Best is trial 17 with value: 0.38935742591734485.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  75%|#######5  | 15/20 [00:11<00:01,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.389325:  80%|########  | 16/20 [00:11<00:01,  3.25it/s]\u001b[32m[I 2022-10-01 17:10:36,499]\u001b[0m Trial 22 finished with value: 0.3923314883260602 and parameters: {'num_leaves': 66}. Best is trial 17 with value: 0.38935742591734485.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  85%|########5 | 17/20 [00:12<00:00,  3.98it/s]\u001b[32m[I 2022-10-01 17:10:36,600]\u001b[0m Trial 23 finished with value: 0.43344691832016446 and parameters: {'num_leaves': 3}. Best is trial 17 with value: 0.38935742591734485.\u001b[0m\n",
      "num_leaves, val_score: 0.389325:  85%|########5 | 17/20 [00:12<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388999:  90%|######### | 18/20 [00:12<00:00,  3.46it/s]\u001b[32m[I 2022-10-01 17:10:36,985]\u001b[0m Trial 24 finished with value: 0.38899862657441414 and parameters: {'num_leaves': 93}. Best is trial 24 with value: 0.38899862657441414.\u001b[0m\n",
      "num_leaves, val_score: 0.388999:  90%|######### | 18/20 [00:12<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388999:  95%|#########5| 19/20 [00:12<00:00,  3.11it/s]\u001b[32m[I 2022-10-01 17:10:37,388]\u001b[0m Trial 25 finished with value: 0.40476537946760965 and parameters: {'num_leaves': 91}. Best is trial 24 with value: 0.38899862657441414.\u001b[0m\n",
      "num_leaves, val_score: 0.388999:  95%|#########5| 19/20 [00:12<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388999: 100%|##########| 20/20 [00:13<00:00,  2.79it/s]\u001b[32m[I 2022-10-01 17:10:37,835]\u001b[0m Trial 26 finished with value: 0.3949097974990982 and parameters: {'num_leaves': 44}. Best is trial 24 with value: 0.38899862657441414.\u001b[0m\n",
      "num_leaves, val_score: 0.388999: 100%|##########| 20/20 [00:13<00:00,  1.51it/s]\n",
      "bagging, val_score: 0.388999:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388999:  10%|#         | 1/10 [00:00<00:04,  2.14it/s]\u001b[32m[I 2022-10-01 17:10:38,310]\u001b[0m Trial 27 finished with value: 0.40880504586004807 and parameters: {'bagging_fraction': 0.7975380649453148, 'bagging_freq': 4}. Best is trial 27 with value: 0.40880504586004807.\u001b[0m\n",
      "bagging, val_score: 0.388999:  10%|#         | 1/10 [00:00<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388999:  20%|##        | 2/10 [00:00<00:02,  2.91it/s]\u001b[32m[I 2022-10-01 17:10:38,567]\u001b[0m Trial 28 finished with value: 0.41746754419159265 and parameters: {'bagging_fraction': 0.5881502944124429, 'bagging_freq': 1}. Best is trial 27 with value: 0.40880504586004807.\u001b[0m\n",
      "bagging, val_score: 0.388999:  20%|##        | 2/10 [00:00<00:02,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388999:  30%|###       | 3/10 [00:01<00:02,  3.02it/s]\u001b[32m[I 2022-10-01 17:10:38,883]\u001b[0m Trial 29 finished with value: 0.4098780637885245 and parameters: {'bagging_fraction': 0.7494919398872271, 'bagging_freq': 6}. Best is trial 27 with value: 0.40880504586004807.\u001b[0m\n",
      "bagging, val_score: 0.388999:  30%|###       | 3/10 [00:01<00:02,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388999:  40%|####      | 4/10 [00:01<00:01,  3.19it/s]\u001b[32m[I 2022-10-01 17:10:39,171]\u001b[0m Trial 30 finished with value: 0.4050786047991028 and parameters: {'bagging_fraction': 0.8324662328550294, 'bagging_freq': 2}. Best is trial 30 with value: 0.4050786047991028.\u001b[0m\n",
      "bagging, val_score: 0.388999:  40%|####      | 4/10 [00:01<00:01,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388999:  50%|#####     | 5/10 [00:01<00:01,  3.40it/s]\u001b[32m[I 2022-10-01 17:10:39,429]\u001b[0m Trial 31 finished with value: 0.41130009254024297 and parameters: {'bagging_fraction': 0.6969082269467914, 'bagging_freq': 1}. Best is trial 30 with value: 0.4050786047991028.\u001b[0m\n",
      "bagging, val_score: 0.388999:  50%|#####     | 5/10 [00:01<00:01,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388999:  60%|######    | 6/10 [00:01<00:01,  3.60it/s]\u001b[32m[I 2022-10-01 17:10:39,676]\u001b[0m Trial 32 finished with value: 0.39863033673455744 and parameters: {'bagging_fraction': 0.46811659775530345, 'bagging_freq': 7}. Best is trial 32 with value: 0.39863033673455744.\u001b[0m\n",
      "bagging, val_score: 0.388999:  60%|######    | 6/10 [00:01<00:01,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388999:  70%|#######   | 7/10 [00:02<00:00,  3.77it/s]\u001b[32m[I 2022-10-01 17:10:39,915]\u001b[0m Trial 33 finished with value: 0.39916658578382447 and parameters: {'bagging_fraction': 0.5407949389413843, 'bagging_freq': 4}. Best is trial 32 with value: 0.39863033673455744.\u001b[0m\n",
      "bagging, val_score: 0.388999:  70%|#######   | 7/10 [00:02<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388999:  80%|########  | 8/10 [00:02<00:00,  3.59it/s]\u001b[32m[I 2022-10-01 17:10:40,224]\u001b[0m Trial 34 finished with value: 0.40545639161063723 and parameters: {'bagging_fraction': 0.7621039592042667, 'bagging_freq': 7}. Best is trial 32 with value: 0.39863033673455744.\u001b[0m\n",
      "bagging, val_score: 0.388999:  80%|########  | 8/10 [00:02<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388999:  90%|######### | 9/10 [00:02<00:00,  3.51it/s]\u001b[32m[I 2022-10-01 17:10:40,521]\u001b[0m Trial 35 finished with value: 0.3923954718426025 and parameters: {'bagging_fraction': 0.6394417483185173, 'bagging_freq': 4}. Best is trial 35 with value: 0.3923954718426025.\u001b[0m\n",
      "bagging, val_score: 0.388999:  90%|######### | 9/10 [00:02<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388999: 100%|##########| 10/10 [00:03<00:00,  3.34it/s]\u001b[32m[I 2022-10-01 17:10:40,853]\u001b[0m Trial 36 finished with value: 0.39160109079921457 and parameters: {'bagging_fraction': 0.8837050948091751, 'bagging_freq': 7}. Best is trial 36 with value: 0.39160109079921457.\u001b[0m\n",
      "bagging, val_score: 0.388999: 100%|##########| 10/10 [00:03<00:00,  3.32it/s]\n",
      "feature_fraction_stage2, val_score: 0.388999:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388999:  17%|#6        | 1/6 [00:00<00:02,  2.15it/s]\u001b[32m[I 2022-10-01 17:10:41,326]\u001b[0m Trial 37 finished with value: 0.38899862657441414 and parameters: {'feature_fraction': 0.516}. Best is trial 37 with value: 0.38899862657441414.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388999:  17%|#6        | 1/6 [00:00<00:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388999:  33%|###3      | 2/6 [00:01<00:02,  1.88it/s]\u001b[32m[I 2022-10-01 17:10:41,905]\u001b[0m Trial 38 finished with value: 0.4056550953689986 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 37 with value: 0.38899862657441414.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388999:  33%|###3      | 2/6 [00:01<00:02,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388999:  50%|#####     | 3/6 [00:01<00:01,  1.96it/s]\u001b[32m[I 2022-10-01 17:10:42,392]\u001b[0m Trial 39 finished with value: 0.38899862657441414 and parameters: {'feature_fraction': 0.484}. Best is trial 37 with value: 0.38899862657441414.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388999:  50%|#####     | 3/6 [00:01<00:01,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388999:  67%|######6   | 4/6 [00:01<00:00,  2.04it/s]\u001b[32m[I 2022-10-01 17:10:42,851]\u001b[0m Trial 40 finished with value: 0.40056141443073606 and parameters: {'feature_fraction': 0.42}. Best is trial 37 with value: 0.38899862657441414.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388999:  67%|######6   | 4/6 [00:01<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388167:  83%|########3 | 5/6 [00:02<00:00,  1.84it/s]\u001b[32m[I 2022-10-01 17:10:43,485]\u001b[0m Trial 41 finished with value: 0.38816684056248046 and parameters: {'feature_fraction': 0.58}. Best is trial 41 with value: 0.38816684056248046.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388167:  83%|########3 | 5/6 [00:02<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388167: 100%|##########| 6/6 [00:02<00:00,  2.14it/s]\u001b[32m[I 2022-10-01 17:10:43,805]\u001b[0m Trial 42 finished with value: 0.4128524724758217 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 41 with value: 0.38816684056248046.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388167: 100%|##########| 6/6 [00:02<00:00,  2.04it/s]\n",
      "regularization_factors, val_score: 0.388167:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.388167:   5%|5         | 1/20 [00:00<00:09,  2.01it/s]\u001b[32m[I 2022-10-01 17:10:44,309]\u001b[0m Trial 43 finished with value: 0.3943864569650918 and parameters: {'lambda_l1': 0.009555983854292387, 'lambda_l2': 1.799497020333357}. Best is trial 43 with value: 0.3943864569650918.\u001b[0m\n",
      "regularization_factors, val_score: 0.388167:   5%|5         | 1/20 [00:00<00:09,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.388167:  10%|#         | 2/20 [00:00<00:06,  2.69it/s]\u001b[32m[I 2022-10-01 17:10:44,594]\u001b[0m Trial 44 finished with value: 0.3926545417787312 and parameters: {'lambda_l1': 0.12270261796708022, 'lambda_l2': 0.002494085490978213}. Best is trial 44 with value: 0.3926545417787312.\u001b[0m\n",
      "regularization_factors, val_score: 0.388167:  10%|#         | 2/20 [00:00<00:06,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.388167:  15%|#5        | 3/20 [00:01<00:07,  2.38it/s]\u001b[32m[I 2022-10-01 17:10:45,071]\u001b[0m Trial 45 finished with value: 0.3960311921896022 and parameters: {'lambda_l1': 2.317949377450319, 'lambda_l2': 2.8306972201549416}. Best is trial 44 with value: 0.3926545417787312.\u001b[0m\n",
      "regularization_factors, val_score: 0.388167:  15%|#5        | 3/20 [00:01<00:07,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.388167:  20%|##        | 4/20 [00:01<00:05,  2.71it/s]\u001b[32m[I 2022-10-01 17:10:45,363]\u001b[0m Trial 46 finished with value: 0.41618952641150264 and parameters: {'lambda_l1': 0.04551004355595026, 'lambda_l2': 6.80748083134664e-05}. Best is trial 44 with value: 0.3926545417787312.\u001b[0m\n",
      "regularization_factors, val_score: 0.388167:  20%|##        | 4/20 [00:01<00:05,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.388167:  25%|##5       | 5/20 [00:01<00:05,  2.96it/s]\u001b[32m[I 2022-10-01 17:10:45,644]\u001b[0m Trial 47 finished with value: 0.4158583936696644 and parameters: {'lambda_l1': 2.3385456398320953e-06, 'lambda_l2': 0.002654059476174328}. Best is trial 44 with value: 0.3926545417787312.\u001b[0m\n",
      "regularization_factors, val_score: 0.388167:  25%|##5       | 5/20 [00:01<00:05,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.388167:  30%|###       | 6/20 [00:02<00:04,  3.19it/s]\u001b[32m[I 2022-10-01 17:10:45,911]\u001b[0m Trial 48 finished with value: 0.38816684043218747 and parameters: {'lambda_l1': 4.585111428274539e-08, 'lambda_l2': 1.2904382923390494e-08}. Best is trial 48 with value: 0.38816684043218747.\u001b[0m\n",
      "regularization_factors, val_score: 0.388167:  30%|###       | 6/20 [00:02<00:04,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.388167:  35%|###5      | 7/20 [00:02<00:03,  3.35it/s]\u001b[32m[I 2022-10-01 17:10:46,178]\u001b[0m Trial 49 finished with value: 0.393926145211229 and parameters: {'lambda_l1': 0.014316722570793387, 'lambda_l2': 0.0002676759779981225}. Best is trial 48 with value: 0.38816684043218747.\u001b[0m\n",
      "regularization_factors, val_score: 0.388167:  35%|###5      | 7/20 [00:02<00:03,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  40%|####      | 8/20 [00:02<00:03,  3.56it/s]\u001b[32m[I 2022-10-01 17:10:46,421]\u001b[0m Trial 50 finished with value: 0.38756236673038313 and parameters: {'lambda_l1': 0.0006953772787537528, 'lambda_l2': 3.9210117037426705e-05}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  40%|####      | 8/20 [00:02<00:03,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  45%|####5     | 9/20 [00:02<00:03,  3.62it/s]\u001b[32m[I 2022-10-01 17:10:46,688]\u001b[0m Trial 51 finished with value: 0.3910895246051188 and parameters: {'lambda_l1': 3.957945292062874e-05, 'lambda_l2': 0.00018459862700289428}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  45%|####5     | 9/20 [00:02<00:03,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  50%|#####     | 10/20 [00:03<00:02,  3.35it/s]\u001b[32m[I 2022-10-01 17:10:47,036]\u001b[0m Trial 52 finished with value: 0.40547505345195795 and parameters: {'lambda_l1': 0.0010194085859444005, 'lambda_l2': 0.8319494402471007}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  50%|#####     | 10/20 [00:03<00:02,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  55%|#####5    | 11/20 [00:03<00:03,  2.69it/s]\u001b[32m[I 2022-10-01 17:10:47,572]\u001b[0m Trial 53 finished with value: 0.38982687524430754 and parameters: {'lambda_l1': 2.7249483659428364e-05, 'lambda_l2': 4.6737812741845754e-07}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  55%|#####5    | 11/20 [00:03<00:03,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  60%|######    | 12/20 [00:04<00:03,  2.47it/s]\u001b[32m[I 2022-10-01 17:10:48,054]\u001b[0m Trial 54 finished with value: 0.38816684052152994 and parameters: {'lambda_l1': 1.3306704170267768e-08, 'lambda_l2': 1.1278365960998215e-08}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  60%|######    | 12/20 [00:04<00:03,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  65%|######5   | 13/20 [00:04<00:03,  2.05it/s]\u001b[32m[I 2022-10-01 17:10:48,732]\u001b[0m Trial 55 finished with value: 0.3881668373683802 and parameters: {'lambda_l1': 5.2836061455462745e-08, 'lambda_l2': 1.8238833969171954e-06}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  65%|######5   | 13/20 [00:04<00:03,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  70%|#######   | 14/20 [00:05<00:03,  1.91it/s]\u001b[32m[I 2022-10-01 17:10:49,341]\u001b[0m Trial 56 finished with value: 0.38844312139403825 and parameters: {'lambda_l1': 9.578887027333826e-07, 'lambda_l2': 1.3517875471928357e-06}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  70%|#######   | 14/20 [00:05<00:03,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  75%|#######5  | 15/20 [00:06<00:02,  1.70it/s]\u001b[32m[I 2022-10-01 17:10:50,072]\u001b[0m Trial 57 finished with value: 0.4121729858660418 and parameters: {'lambda_l1': 0.00047816944466955137, 'lambda_l2': 4.783169433873234e-06}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  75%|#######5  | 15/20 [00:06<00:02,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  80%|########  | 16/20 [00:06<00:02,  1.70it/s]\u001b[32m[I 2022-10-01 17:10:50,664]\u001b[0m Trial 58 finished with value: 0.388443118589943 and parameters: {'lambda_l1': 4.404332030728326e-07, 'lambda_l2': 6.262029884558138e-06}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  80%|########  | 16/20 [00:06<00:02,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  85%|########5 | 17/20 [00:07<00:01,  1.68it/s]\u001b[32m[I 2022-10-01 17:10:51,280]\u001b[0m Trial 59 finished with value: 0.3933794657494132 and parameters: {'lambda_l1': 2.2518373632837577e-05, 'lambda_l2': 0.03546824948004414}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  85%|########5 | 17/20 [00:07<00:01,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  90%|######### | 18/20 [00:07<00:01,  1.87it/s]\u001b[32m[I 2022-10-01 17:10:51,670]\u001b[0m Trial 60 finished with value: 0.3938850130819372 and parameters: {'lambda_l1': 4.0365734896720715, 'lambda_l2': 1.0590112397336094e-07}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  90%|######### | 18/20 [00:07<00:01,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562:  95%|#########5| 19/20 [00:08<00:00,  1.98it/s]\u001b[32m[I 2022-10-01 17:10:52,110]\u001b[0m Trial 61 finished with value: 0.3928427358828271 and parameters: {'lambda_l1': 0.0011369960104331894, 'lambda_l2': 2.2861213103314495e-05}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562:  95%|#########5| 19/20 [00:08<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387562: 100%|##########| 20/20 [00:08<00:00,  2.16it/s]\u001b[32m[I 2022-10-01 17:10:52,474]\u001b[0m Trial 62 finished with value: 0.39006730095029435 and parameters: {'lambda_l1': 9.556705789536633e-05, 'lambda_l2': 0.004154393230831881}. Best is trial 50 with value: 0.38756236673038313.\u001b[0m\n",
      "regularization_factors, val_score: 0.387562: 100%|##########| 20/20 [00:08<00:00,  2.31it/s]\n",
      "min_data_in_leaf, val_score: 0.387562:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.387562:  20%|##        | 1/5 [00:00<00:02,  1.78it/s]\u001b[32m[I 2022-10-01 17:10:53,042]\u001b[0m Trial 63 finished with value: 0.3936739393897821 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.3936739393897821.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.387562:  20%|##        | 1/5 [00:00<00:02,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.387562:  40%|####      | 2/5 [00:01<00:01,  1.53it/s]\u001b[32m[I 2022-10-01 17:10:53,761]\u001b[0m Trial 64 finished with value: 0.4172938668081008 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.3936739393897821.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.387562:  40%|####      | 2/5 [00:01<00:01,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.387562:  60%|######    | 3/5 [00:01<00:01,  1.70it/s]\u001b[32m[I 2022-10-01 17:10:54,271]\u001b[0m Trial 65 finished with value: 0.3949596696348355 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.3936739393897821.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.387562:  60%|######    | 3/5 [00:01<00:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.387562:  80%|########  | 4/5 [00:02<00:00,  1.70it/s]\u001b[32m[I 2022-10-01 17:10:54,863]\u001b[0m Trial 66 finished with value: 0.3981270388730631 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.3936739393897821.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.387562:  80%|########  | 4/5 [00:02<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3498, number of negative: 3456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503020 -> initscore=0.012080\n",
      "[LightGBM] [Info] Start training from score 0.012080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.387562: 100%|##########| 5/5 [00:02<00:00,  1.98it/s]\u001b[32m[I 2022-10-01 17:10:55,215]\u001b[0m Trial 67 finished with value: 0.39434857073008683 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.3936739393897821.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.387562: 100%|##########| 5/5 [00:02<00:00,  1.83it/s]\n",
      "\u001b[32m[I 2022-10-01 17:10:55,225]\u001b[0m A new study created in memory with name: no-name-11804da6-b70d-4008-afbf-e5a4e145ab5e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0/acc: 0.8067855089131685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.377083:  14%|#4        | 1/7 [00:00<00:01,  3.12it/s]\u001b[32m[I 2022-10-01 17:10:55,551]\u001b[0m Trial 0 finished with value: 0.3770831780134534 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.3770831780134534.\u001b[0m\n",
      "feature_fraction, val_score: 0.377083:  14%|#4        | 1/7 [00:00<00:01,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.377083:  29%|##8       | 2/7 [00:00<00:01,  3.85it/s]\u001b[32m[I 2022-10-01 17:10:55,770]\u001b[0m Trial 1 finished with value: 0.38357153193173926 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.3770831780134534.\u001b[0m\n",
      "feature_fraction, val_score: 0.377083:  29%|##8       | 2/7 [00:00<00:01,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.377083:  43%|####2     | 3/7 [00:00<00:01,  3.57it/s]\u001b[32m[I 2022-10-01 17:10:56,074]\u001b[0m Trial 2 finished with value: 0.379110560044698 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.3770831780134534.\u001b[0m\n",
      "feature_fraction, val_score: 0.377083:  57%|#####7    | 4/7 [00:01<00:00,  4.02it/s]\u001b[32m[I 2022-10-01 17:10:56,275]\u001b[0m Trial 3 finished with value: 0.38385239622217043 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.3770831780134534.\u001b[0m\n",
      "feature_fraction, val_score: 0.377083:  57%|#####7    | 4/7 [00:01<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.377083:  71%|#######1  | 5/7 [00:01<00:00,  4.39it/s]\u001b[32m[I 2022-10-01 17:10:56,465]\u001b[0m Trial 4 finished with value: 0.38244968531531326 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.3770831780134534.\u001b[0m\n",
      "feature_fraction, val_score: 0.377083:  71%|#######1  | 5/7 [00:01<00:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.377083:  86%|########5 | 6/7 [00:01<00:00,  3.95it/s]\u001b[32m[I 2022-10-01 17:10:56,768]\u001b[0m Trial 5 finished with value: 0.3799727082029991 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.3770831780134534.\u001b[0m\n",
      "feature_fraction, val_score: 0.377083: 100%|##########| 7/7 [00:01<00:00,  4.36it/s]\u001b[32m[I 2022-10-01 17:10:56,949]\u001b[0m Trial 6 finished with value: 0.3822213742094761 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.3770831780134534.\u001b[0m\n",
      "feature_fraction, val_score: 0.377083: 100%|##########| 7/7 [00:01<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:   5%|5         | 1/20 [00:00<00:08,  2.19it/s]\u001b[32m[I 2022-10-01 17:10:57,415]\u001b[0m Trial 7 finished with value: 0.3893363254197852 and parameters: {'num_leaves': 159}. Best is trial 7 with value: 0.3893363254197852.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:   5%|5         | 1/20 [00:00<00:08,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  10%|#         | 2/20 [00:00<00:09,  1.98it/s]\u001b[32m[I 2022-10-01 17:10:57,954]\u001b[0m Trial 8 finished with value: 0.39420190422713736 and parameters: {'num_leaves': 209}. Best is trial 7 with value: 0.3893363254197852.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  10%|#         | 2/20 [00:00<00:09,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  15%|#5        | 3/20 [00:01<00:06,  2.45it/s]\u001b[32m[I 2022-10-01 17:10:58,247]\u001b[0m Trial 9 finished with value: 0.3818999032671147 and parameters: {'num_leaves': 61}. Best is trial 9 with value: 0.3818999032671147.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  15%|#5        | 3/20 [00:01<00:06,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  20%|##        | 4/20 [00:02<00:09,  1.76it/s]\u001b[32m[I 2022-10-01 17:10:59,064]\u001b[0m Trial 10 finished with value: 0.39186411126291154 and parameters: {'num_leaves': 198}. Best is trial 9 with value: 0.3818999032671147.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  20%|##        | 4/20 [00:02<00:09,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  25%|##5       | 5/20 [00:02<00:06,  2.27it/s]\u001b[32m[I 2022-10-01 17:10:59,277]\u001b[0m Trial 11 finished with value: 0.38180237077062373 and parameters: {'num_leaves': 26}. Best is trial 11 with value: 0.38180237077062373.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  25%|##5       | 5/20 [00:02<00:06,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  30%|###       | 6/20 [00:02<00:06,  2.32it/s]\u001b[32m[I 2022-10-01 17:10:59,687]\u001b[0m Trial 12 finished with value: 0.3974163795762412 and parameters: {'num_leaves': 110}. Best is trial 11 with value: 0.38180237077062373.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  30%|###       | 6/20 [00:02<00:06,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  35%|###5      | 7/20 [00:03<00:05,  2.28it/s]\u001b[32m[I 2022-10-01 17:11:00,142]\u001b[0m Trial 13 finished with value: 0.39105918521494737 and parameters: {'num_leaves': 164}. Best is trial 11 with value: 0.38180237077062373.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  40%|####      | 8/20 [00:03<00:04,  2.86it/s]\u001b[32m[I 2022-10-01 17:11:00,303]\u001b[0m Trial 14 finished with value: 0.38154516810682226 and parameters: {'num_leaves': 24}. Best is trial 14 with value: 0.38154516810682226.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  40%|####      | 8/20 [00:03<00:04,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  45%|####5     | 9/20 [00:03<00:04,  2.71it/s]\u001b[32m[I 2022-10-01 17:11:00,712]\u001b[0m Trial 15 finished with value: 0.38930555142866874 and parameters: {'num_leaves': 85}. Best is trial 14 with value: 0.38154516810682226.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  45%|####5     | 9/20 [00:03<00:04,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  50%|#####     | 10/20 [00:04<00:04,  2.19it/s]\u001b[32m[I 2022-10-01 17:11:01,368]\u001b[0m Trial 16 finished with value: 0.39010076849830233 and parameters: {'num_leaves': 167}. Best is trial 14 with value: 0.38154516810682226.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  55%|#####5    | 11/20 [00:04<00:03,  2.73it/s]\u001b[32m[I 2022-10-01 17:11:01,528]\u001b[0m Trial 17 finished with value: 0.3827312368631662 and parameters: {'num_leaves': 16}. Best is trial 14 with value: 0.38154516810682226.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  55%|#####5    | 11/20 [00:04<00:03,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  60%|######    | 12/20 [00:04<00:02,  3.43it/s]\u001b[32m[I 2022-10-01 17:11:01,648]\u001b[0m Trial 18 finished with value: 0.4283416317644161 and parameters: {'num_leaves': 4}. Best is trial 14 with value: 0.38154516810682226.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  60%|######    | 12/20 [00:04<00:02,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  65%|######5   | 13/20 [00:04<00:01,  3.51it/s]\u001b[32m[I 2022-10-01 17:11:01,917]\u001b[0m Trial 19 finished with value: 0.3802803426034156 and parameters: {'num_leaves': 38}. Best is trial 19 with value: 0.3802803426034156.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  65%|######5   | 13/20 [00:04<00:01,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  70%|#######   | 14/20 [00:05<00:01,  3.18it/s]\u001b[32m[I 2022-10-01 17:11:02,301]\u001b[0m Trial 20 finished with value: 0.3906898402729493 and parameters: {'num_leaves': 75}. Best is trial 19 with value: 0.3802803426034156.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  70%|#######   | 14/20 [00:05<00:01,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  75%|#######5  | 15/20 [00:06<00:02,  2.27it/s]\u001b[32m[I 2022-10-01 17:11:03,036]\u001b[0m Trial 21 finished with value: 0.39261264611881175 and parameters: {'num_leaves': 251}. Best is trial 19 with value: 0.3802803426034156.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  75%|#######5  | 15/20 [00:06<00:02,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  80%|########  | 16/20 [00:06<00:01,  2.64it/s]\u001b[32m[I 2022-10-01 17:11:03,269]\u001b[0m Trial 22 finished with value: 0.38149152966340055 and parameters: {'num_leaves': 47}. Best is trial 19 with value: 0.3802803426034156.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  80%|########  | 16/20 [00:06<00:01,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  85%|########5 | 17/20 [00:06<00:00,  3.04it/s]\u001b[32m[I 2022-10-01 17:11:03,481]\u001b[0m Trial 23 finished with value: 0.38149152966340055 and parameters: {'num_leaves': 47}. Best is trial 19 with value: 0.3802803426034156.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  85%|########5 | 17/20 [00:06<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083:  90%|######### | 18/20 [00:06<00:00,  2.86it/s]\u001b[32m[I 2022-10-01 17:11:03,881]\u001b[0m Trial 24 finished with value: 0.3995142623131249 and parameters: {'num_leaves': 113}. Best is trial 19 with value: 0.3802803426034156.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  95%|#########5| 19/20 [00:07<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-01 17:11:04,092]\u001b[0m Trial 25 finished with value: 0.38149152966340055 and parameters: {'num_leaves': 47}. Best is trial 19 with value: 0.3802803426034156.\u001b[0m\n",
      "num_leaves, val_score: 0.377083:  95%|#########5| 19/20 [00:07<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.377083: 100%|##########| 20/20 [00:07<00:00,  3.12it/s]\u001b[32m[I 2022-10-01 17:11:04,443]\u001b[0m Trial 26 finished with value: 0.38830439843086084 and parameters: {'num_leaves': 89}. Best is trial 19 with value: 0.3802803426034156.\u001b[0m\n",
      "num_leaves, val_score: 0.377083: 100%|##########| 20/20 [00:07<00:00,  2.67it/s]\n",
      "bagging, val_score: 0.377083:  10%|#         | 1/10 [00:00<00:01,  5.03it/s]\u001b[32m[I 2022-10-01 17:11:04,648]\u001b[0m Trial 27 finished with value: 0.3804034587416787 and parameters: {'bagging_fraction': 0.7968346368136466, 'bagging_freq': 6}. Best is trial 27 with value: 0.3804034587416787.\u001b[0m\n",
      "bagging, val_score: 0.377083:  10%|#         | 1/10 [00:00<00:01,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.377083:  20%|##        | 2/10 [00:00<00:01,  5.01it/s]\u001b[32m[I 2022-10-01 17:11:04,849]\u001b[0m Trial 28 finished with value: 0.38547264891132876 and parameters: {'bagging_fraction': 0.7484102170186986, 'bagging_freq': 3}. Best is trial 27 with value: 0.3804034587416787.\u001b[0m\n",
      "bagging, val_score: 0.377083:  20%|##        | 2/10 [00:00<00:01,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.377083:  30%|###       | 3/10 [00:00<00:01,  4.94it/s]\u001b[32m[I 2022-10-01 17:11:05,055]\u001b[0m Trial 29 finished with value: 0.3940734910448312 and parameters: {'bagging_fraction': 0.4913522612640803, 'bagging_freq': 5}. Best is trial 27 with value: 0.3804034587416787.\u001b[0m\n",
      "bagging, val_score: 0.377083:  30%|###       | 3/10 [00:00<00:01,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.377083:  40%|####      | 4/10 [00:00<00:01,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-01 17:11:05,264]\u001b[0m Trial 30 finished with value: 0.38982988863848145 and parameters: {'bagging_fraction': 0.49630814130240786, 'bagging_freq': 4}. Best is trial 27 with value: 0.3804034587416787.\u001b[0m\n",
      "bagging, val_score: 0.377083:  40%|####      | 4/10 [00:00<00:01,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.377083:  50%|#####     | 5/10 [00:01<00:01,  4.85it/s]\u001b[32m[I 2022-10-01 17:11:05,472]\u001b[0m Trial 31 finished with value: 0.3784015799501664 and parameters: {'bagging_fraction': 0.912903528814909, 'bagging_freq': 3}. Best is trial 31 with value: 0.3784015799501664.\u001b[0m\n",
      "bagging, val_score: 0.377083:  60%|######    | 6/10 [00:01<00:00,  4.94it/s]\u001b[32m[I 2022-10-01 17:11:05,667]\u001b[0m Trial 32 finished with value: 0.3805672132682743 and parameters: {'bagging_fraction': 0.8088811020771731, 'bagging_freq': 3}. Best is trial 31 with value: 0.3784015799501664.\u001b[0m\n",
      "bagging, val_score: 0.377083:  60%|######    | 6/10 [00:01<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.377083:  70%|#######   | 7/10 [00:01<00:00,  4.88it/s]\u001b[32m[I 2022-10-01 17:11:05,877]\u001b[0m Trial 33 finished with value: 0.3813081461804933 and parameters: {'bagging_fraction': 0.8307890930598788, 'bagging_freq': 6}. Best is trial 31 with value: 0.3784015799501664.\u001b[0m\n",
      "bagging, val_score: 0.377083:  70%|#######   | 7/10 [00:01<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.377083:  80%|########  | 8/10 [00:01<00:00,  4.95it/s]\u001b[32m[I 2022-10-01 17:11:06,072]\u001b[0m Trial 34 finished with value: 0.3830313033459351 and parameters: {'bagging_fraction': 0.7792087771224026, 'bagging_freq': 5}. Best is trial 31 with value: 0.3784015799501664.\u001b[0m\n",
      "bagging, val_score: 0.377083:  80%|########  | 8/10 [00:01<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.377083:  90%|######### | 9/10 [00:01<00:00,  4.92it/s]\u001b[32m[I 2022-10-01 17:11:06,278]\u001b[0m Trial 35 finished with value: 0.38516695906679943 and parameters: {'bagging_fraction': 0.5513991082009698, 'bagging_freq': 1}. Best is trial 31 with value: 0.3784015799501664.\u001b[0m\n",
      "bagging, val_score: 0.377083:  90%|######### | 9/10 [00:01<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.377083: 100%|##########| 10/10 [00:02<00:00,  4.76it/s]\u001b[32m[I 2022-10-01 17:11:06,503]\u001b[0m Trial 36 finished with value: 0.3783628249390668 and parameters: {'bagging_fraction': 0.9259310157143944, 'bagging_freq': 6}. Best is trial 36 with value: 0.3783628249390668.\u001b[0m\n",
      "bagging, val_score: 0.377083: 100%|##########| 10/10 [00:02<00:00,  4.86it/s]\n",
      "feature_fraction_stage2, val_score: 0.377083:  17%|#6        | 1/6 [00:00<00:00,  5.49it/s]\u001b[32m[I 2022-10-01 17:11:06,692]\u001b[0m Trial 37 finished with value: 0.3806956342592691 and parameters: {'feature_fraction': 0.6799999999999999}. Best is trial 37 with value: 0.3806956342592691.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.377083:  17%|#6        | 1/6 [00:00<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.377083:  33%|###3      | 2/6 [00:00<00:00,  5.07it/s]\u001b[32m[I 2022-10-01 17:11:06,899]\u001b[0m Trial 38 finished with value: 0.3783498285256607 and parameters: {'feature_fraction': 0.52}. Best is trial 38 with value: 0.3783498285256607.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.377083:  33%|###3      | 2/6 [00:00<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.377083:  50%|#####     | 3/6 [00:00<00:00,  4.13it/s]\u001b[32m[I 2022-10-01 17:11:07,196]\u001b[0m Trial 39 finished with value: 0.37775925553992573 and parameters: {'feature_fraction': 0.584}. Best is trial 39 with value: 0.37775925553992573.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.377083:  67%|######6   | 4/6 [00:00<00:00,  4.64it/s]\u001b[32m[I 2022-10-01 17:11:07,370]\u001b[0m Trial 40 finished with value: 0.3770831780134534 and parameters: {'feature_fraction': 0.616}. Best is trial 40 with value: 0.3770831780134534.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.377083:  67%|######6   | 4/6 [00:00<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.377083:  83%|########3 | 5/6 [00:01<00:00,  4.94it/s]\u001b[32m[I 2022-10-01 17:11:07,550]\u001b[0m Trial 41 finished with value: 0.37752826981976123 and parameters: {'feature_fraction': 0.6479999999999999}. Best is trial 40 with value: 0.3770831780134534.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.377083: 100%|##########| 6/6 [00:01<00:00,  5.06it/s]\u001b[32m[I 2022-10-01 17:11:07,738]\u001b[0m Trial 42 finished with value: 0.3783498285256607 and parameters: {'feature_fraction': 0.552}. Best is trial 40 with value: 0.3770831780134534.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.377083: 100%|##########| 6/6 [00:01<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.377083:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.377083:   5%|5         | 1/20 [00:00<00:04,  4.61it/s]\u001b[32m[I 2022-10-01 17:11:07,962]\u001b[0m Trial 43 finished with value: 0.3795970478367126 and parameters: {'lambda_l1': 0.00043421632709572135, 'lambda_l2': 0.0014427741159900884}. Best is trial 43 with value: 0.3795970478367126.\u001b[0m\n",
      "regularization_factors, val_score: 0.377083:  10%|#         | 2/20 [00:00<00:03,  5.04it/s]\u001b[32m[I 2022-10-01 17:11:08,147]\u001b[0m Trial 44 finished with value: 0.3828183251643003 and parameters: {'lambda_l1': 0.34465174289913225, 'lambda_l2': 4.1108690806721775}. Best is trial 43 with value: 0.3795970478367126.\u001b[0m\n",
      "regularization_factors, val_score: 0.377083:  10%|#         | 2/20 [00:00<00:03,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.377083:  15%|#5        | 3/20 [00:00<00:03,  5.02it/s]\u001b[32m[I 2022-10-01 17:11:08,347]\u001b[0m Trial 45 finished with value: 0.39552638563983644 and parameters: {'lambda_l1': 6.821412227135535, 'lambda_l2': 0.1242893418377081}. Best is trial 43 with value: 0.3795970478367126.\u001b[0m\n",
      "regularization_factors, val_score: 0.377083:  15%|#5        | 3/20 [00:00<00:03,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.377083:  20%|##        | 4/20 [00:00<00:03,  5.01it/s]\u001b[32m[I 2022-10-01 17:11:08,547]\u001b[0m Trial 46 finished with value: 0.37774729747096086 and parameters: {'lambda_l1': 0.0011255254860467248, 'lambda_l2': 4.795152037782118e-07}. Best is trial 46 with value: 0.37774729747096086.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  25%|##5       | 5/20 [00:00<00:02,  5.10it/s]\u001b[32m[I 2022-10-01 17:11:08,737]\u001b[0m Trial 47 finished with value: 0.3760754592919618 and parameters: {'lambda_l1': 0.3054153122053016, 'lambda_l2': 9.368457851525762e-07}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  25%|##5       | 5/20 [00:00<00:02,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376075:  30%|###       | 6/20 [00:01<00:02,  5.15it/s]\u001b[32m[I 2022-10-01 17:11:08,928]\u001b[0m Trial 48 finished with value: 0.37662590315886835 and parameters: {'lambda_l1': 2.211218928162658e-05, 'lambda_l2': 0.0035599973453821006}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  30%|###       | 6/20 [00:01<00:02,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376075:  35%|###5      | 7/20 [00:01<00:02,  5.13it/s]\u001b[32m[I 2022-10-01 17:11:09,124]\u001b[0m Trial 49 finished with value: 0.3802969784425714 and parameters: {'lambda_l1': 1.4649269149359169e-05, 'lambda_l2': 1.5700420969569548}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  40%|####      | 8/20 [00:01<00:02,  5.24it/s]\u001b[32m[I 2022-10-01 17:11:09,307]\u001b[0m Trial 50 finished with value: 0.38374890673870354 and parameters: {'lambda_l1': 0.6295487188701482, 'lambda_l2': 0.0001578371559028131}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  40%|####      | 8/20 [00:01<00:02,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376075:  45%|####5     | 9/20 [00:01<00:02,  5.16it/s]\u001b[32m[I 2022-10-01 17:11:09,506]\u001b[0m Trial 51 finished with value: 0.3784042598255859 and parameters: {'lambda_l1': 4.707045269398653e-08, 'lambda_l2': 2.5442270271695198}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  45%|####5     | 9/20 [00:01<00:02,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376075:  50%|#####     | 10/20 [00:01<00:01,  5.05it/s]\u001b[32m[I 2022-10-01 17:11:09,714]\u001b[0m Trial 52 finished with value: 0.3766036235151968 and parameters: {'lambda_l1': 0.00460819605330365, 'lambda_l2': 0.006493901593083646}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  55%|#####5    | 11/20 [00:02<00:01,  5.10it/s]\u001b[32m[I 2022-10-01 17:11:09,906]\u001b[0m Trial 53 finished with value: 0.38023767447615076 and parameters: {'lambda_l1': 0.034302145532378155, 'lambda_l2': 1.2353586317483398e-08}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  55%|#####5    | 11/20 [00:02<00:01,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376075:  60%|######    | 12/20 [00:02<00:01,  5.05it/s]\u001b[32m[I 2022-10-01 17:11:10,108]\u001b[0m Trial 54 finished with value: 0.37826953777687256 and parameters: {'lambda_l1': 0.012124245077596742, 'lambda_l2': 1.1942827835971565e-05}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  60%|######    | 12/20 [00:02<00:01,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376075:  65%|######5   | 13/20 [00:02<00:01,  3.90it/s]\u001b[32m[I 2022-10-01 17:11:10,500]\u001b[0m Trial 55 finished with value: 0.37996119500735037 and parameters: {'lambda_l1': 0.03150334968575921, 'lambda_l2': 1.8813818626619407e-06}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  65%|######5   | 13/20 [00:02<00:01,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376075:  70%|#######   | 14/20 [00:03<00:01,  3.86it/s]\u001b[32m[I 2022-10-01 17:11:10,764]\u001b[0m Trial 56 finished with value: 0.3870601408831496 and parameters: {'lambda_l1': 5.6281034587665655, 'lambda_l2': 0.025719602263816827}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.376075:  70%|#######   | 14/20 [00:03<00:01,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.376075:  75%|#######5  | 15/20 [00:03<00:01,  3.92it/s]\u001b[32m[I 2022-10-01 17:11:11,010]\u001b[0m Trial 57 finished with value: 0.37944539083192386 and parameters: {'lambda_l1': 1.577538643038448e-05, 'lambda_l2': 6.69282366712868e-05}. Best is trial 47 with value: 0.3760754592919618.\u001b[0m\n",
      "regularization_factors, val_score: 0.375797:  80%|########  | 16/20 [00:03<00:00,  4.15it/s]\u001b[32m[I 2022-10-01 17:11:11,218]\u001b[0m Trial 58 finished with value: 0.3757970220273518 and parameters: {'lambda_l1': 0.005020723449659635, 'lambda_l2': 4.764649146671415e-08}. Best is trial 58 with value: 0.3757970220273518.\u001b[0m\n",
      "regularization_factors, val_score: 0.375797:  80%|########  | 16/20 [00:03<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.375797:  85%|########5 | 17/20 [00:03<00:00,  4.36it/s]\u001b[32m[I 2022-10-01 17:11:11,420]\u001b[0m Trial 59 finished with value: 0.3783735667814921 and parameters: {'lambda_l1': 0.3094343689483433, 'lambda_l2': 1.111840440656134e-08}. Best is trial 58 with value: 0.3757970220273518.\u001b[0m\n",
      "regularization_factors, val_score: 0.375797:  85%|########5 | 17/20 [00:03<00:00,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.375797:  90%|######### | 18/20 [00:03<00:00,  4.54it/s]\u001b[32m[I 2022-10-01 17:11:11,620]\u001b[0m Trial 60 finished with value: 0.3769575617181271 and parameters: {'lambda_l1': 0.00013556966241689, 'lambda_l2': 1.9551672836232023e-07}. Best is trial 58 with value: 0.3757970220273518.\u001b[0m\n",
      "regularization_factors, val_score: 0.375797:  90%|######### | 18/20 [00:03<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.375797:  95%|#########5| 19/20 [00:04<00:00,  4.67it/s]\u001b[32m[I 2022-10-01 17:11:11,820]\u001b[0m Trial 61 finished with value: 0.3770831779866835 and parameters: {'lambda_l1': 1.4371596601529747e-07, 'lambda_l2': 1.0446223116961727e-07}. Best is trial 58 with value: 0.3757970220273518.\u001b[0m\n",
      "regularization_factors, val_score: 0.375797:  95%|#########5| 19/20 [00:04<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.375797: 100%|##########| 20/20 [00:04<00:00,  4.74it/s]\u001b[32m[I 2022-10-01 17:11:12,024]\u001b[0m Trial 62 finished with value: 0.3768326330966885 and parameters: {'lambda_l1': 0.10719154557541559, 'lambda_l2': 5.273142338981603e-06}. Best is trial 58 with value: 0.3757970220273518.\u001b[0m\n",
      "regularization_factors, val_score: 0.375797: 100%|##########| 20/20 [00:04<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.375797:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.375797:  20%|##        | 1/5 [00:00<00:00,  4.54it/s]\u001b[32m[I 2022-10-01 17:11:12,251]\u001b[0m Trial 63 finished with value: 0.3820031631552818 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.3820031631552818.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.375797:  40%|####      | 2/5 [00:00<00:00,  4.92it/s]\u001b[32m[I 2022-10-01 17:11:12,443]\u001b[0m Trial 64 finished with value: 0.3760283529751095 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.3760283529751095.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.375797:  40%|####      | 2/5 [00:00<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.375797:  60%|######    | 3/5 [00:00<00:00,  5.06it/s]\u001b[32m[I 2022-10-01 17:11:12,634]\u001b[0m Trial 65 finished with value: 0.3788144084213327 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.3760283529751095.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.375797:  60%|######    | 3/5 [00:00<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.375797:  80%|########  | 4/5 [00:00<00:00,  4.97it/s]\u001b[32m[I 2022-10-01 17:11:12,841]\u001b[0m Trial 66 finished with value: 0.38455574685033445 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.3760283529751095.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.375797: 100%|##########| 5/5 [00:00<00:00,  5.14it/s]\u001b[32m[I 2022-10-01 17:11:13,024]\u001b[0m Trial 67 finished with value: 0.38116664341744777 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.3760283529751095.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.375797: 100%|##########| 5/5 [00:00<00:00,  5.02it/s]\n",
      "\u001b[32m[I 2022-10-01 17:11:13,033]\u001b[0m A new study created in memory with name: no-name-8ebc6b8e-8ace-4ff3-902e-57cc8edb28f0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "fold 1/acc: 0.8085106382978723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388615:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388615:  14%|#4        | 1/7 [00:00<00:01,  4.89it/s]\u001b[32m[I 2022-10-01 17:11:13,243]\u001b[0m Trial 0 finished with value: 0.388615063534515 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.388615063534515.\u001b[0m\n",
      "feature_fraction, val_score: 0.388615:  14%|#4        | 1/7 [00:00<00:01,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.381232:  29%|##8       | 2/7 [00:00<00:01,  3.49it/s]\u001b[32m[I 2022-10-01 17:11:13,586]\u001b[0m Trial 1 finished with value: 0.3812317571506287 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.3812317571506287.\u001b[0m\n",
      "feature_fraction, val_score: 0.381232:  43%|####2     | 3/7 [00:00<00:00,  4.09it/s]\u001b[32m[I 2022-10-01 17:11:13,781]\u001b[0m Trial 2 finished with value: 0.38689384102397084 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.3812317571506287.\u001b[0m\n",
      "feature_fraction, val_score: 0.381232:  43%|####2     | 3/7 [00:00<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.381232:  57%|#####7    | 4/7 [00:00<00:00,  4.45it/s]\u001b[32m[I 2022-10-01 17:11:13,975]\u001b[0m Trial 3 finished with value: 0.3894094730602955 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.3812317571506287.\u001b[0m\n",
      "feature_fraction, val_score: 0.381232:  57%|#####7    | 4/7 [00:00<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.381232:  71%|#######1  | 5/7 [00:01<00:00,  4.66it/s]\u001b[32m[I 2022-10-01 17:11:14,172]\u001b[0m Trial 4 finished with value: 0.3842061433867521 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.3812317571506287.\u001b[0m\n",
      "feature_fraction, val_score: 0.381232:  86%|########5 | 6/7 [00:01<00:00,  4.99it/s]\u001b[32m[I 2022-10-01 17:11:14,345]\u001b[0m Trial 5 finished with value: 0.3853340754055881 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.3812317571506287.\u001b[0m\n",
      "feature_fraction, val_score: 0.381232:  86%|########5 | 6/7 [00:01<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.381232: 100%|##########| 7/7 [00:01<00:00,  4.95it/s]\u001b[32m[I 2022-10-01 17:11:14,550]\u001b[0m Trial 6 finished with value: 0.3847798615252073 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.3812317571506287.\u001b[0m\n",
      "feature_fraction, val_score: 0.381232: 100%|##########| 7/7 [00:01<00:00,  4.62it/s]\n",
      "num_leaves, val_score: 0.381232:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:   5%|5         | 1/20 [00:00<00:09,  1.91it/s]\u001b[32m[I 2022-10-01 17:11:15,080]\u001b[0m Trial 7 finished with value: 0.4087984286580188 and parameters: {'num_leaves': 172}. Best is trial 7 with value: 0.4087984286580188.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:   5%|5         | 1/20 [00:00<00:09,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:  10%|#         | 2/20 [00:00<00:08,  2.06it/s]\u001b[32m[I 2022-10-01 17:11:15,540]\u001b[0m Trial 8 finished with value: 0.4004971211893216 and parameters: {'num_leaves': 137}. Best is trial 8 with value: 0.4004971211893216.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  10%|#         | 2/20 [00:00<00:08,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:  15%|#5        | 3/20 [00:01<00:07,  2.38it/s]\u001b[32m[I 2022-10-01 17:11:15,881]\u001b[0m Trial 9 finished with value: 0.3885644179563052 and parameters: {'num_leaves': 82}. Best is trial 9 with value: 0.3885644179563052.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  15%|#5        | 3/20 [00:01<00:07,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:  20%|##        | 4/20 [00:01<00:07,  2.06it/s]\u001b[32m[I 2022-10-01 17:11:16,467]\u001b[0m Trial 10 finished with value: 0.4130743191861491 and parameters: {'num_leaves': 210}. Best is trial 9 with value: 0.3885644179563052.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  20%|##        | 4/20 [00:01<00:07,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:  25%|##5       | 5/20 [00:02<00:06,  2.32it/s]\u001b[32m[I 2022-10-01 17:11:16,804]\u001b[0m Trial 11 finished with value: 0.38732869864529573 and parameters: {'num_leaves': 78}. Best is trial 11 with value: 0.38732869864529573.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  25%|##5       | 5/20 [00:02<00:06,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:  30%|###       | 6/20 [00:02<00:06,  2.28it/s]\u001b[32m[I 2022-10-01 17:11:17,258]\u001b[0m Trial 12 finished with value: 0.4025781122098098 and parameters: {'num_leaves': 132}. Best is trial 11 with value: 0.38732869864529573.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  30%|###       | 6/20 [00:02<00:06,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:  35%|###5      | 7/20 [00:03<00:05,  2.39it/s]\u001b[32m[I 2022-10-01 17:11:17,635]\u001b[0m Trial 13 finished with value: 0.3918032256366091 and parameters: {'num_leaves': 111}. Best is trial 11 with value: 0.38732869864529573.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  35%|###5      | 7/20 [00:03<00:05,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:  40%|####      | 8/20 [00:04<00:08,  1.48it/s]\u001b[32m[I 2022-10-01 17:11:18,858]\u001b[0m Trial 14 finished with value: 0.413643184128928 and parameters: {'num_leaves': 233}. Best is trial 11 with value: 0.38732869864529573.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  40%|####      | 8/20 [00:04<00:08,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:  45%|####5     | 9/20 [00:04<00:06,  1.79it/s]\u001b[32m[I 2022-10-01 17:11:19,163]\u001b[0m Trial 15 finished with value: 0.3871624683814564 and parameters: {'num_leaves': 63}. Best is trial 15 with value: 0.3871624683814564.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  45%|####5     | 9/20 [00:04<00:06,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:  50%|#####     | 10/20 [00:04<00:04,  2.17it/s]\u001b[32m[I 2022-10-01 17:11:19,402]\u001b[0m Trial 16 finished with value: 0.38675472551398493 and parameters: {'num_leaves': 49}. Best is trial 16 with value: 0.38675472551398493.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  50%|#####     | 10/20 [00:04<00:04,  2.17it/s]\u001b[32m[I 2022-10-01 17:11:19,491]\u001b[0m Trial 17 finished with value: 0.4864489820418657 and parameters: {'num_leaves': 2}. Best is trial 16 with value: 0.38675472551398493.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  55%|#####5    | 11/20 [00:04<00:04,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.381232:  60%|######    | 12/20 [00:05<00:02,  3.27it/s]\u001b[32m[I 2022-10-01 17:11:19,663]\u001b[0m Trial 18 finished with value: 0.38391607005429834 and parameters: {'num_leaves': 20}. Best is trial 18 with value: 0.38391607005429834.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  65%|######5   | 13/20 [00:05<00:01,  3.87it/s]\u001b[32m[I 2022-10-01 17:11:19,780]\u001b[0m Trial 19 finished with value: 0.41018931576336687 and parameters: {'num_leaves': 5}. Best is trial 18 with value: 0.38391607005429834.\u001b[0m\n",
      "num_leaves, val_score: 0.381232:  65%|######5   | 13/20 [00:05<00:01,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379530:  70%|#######   | 14/20 [00:05<00:01,  3.97it/s]\u001b[32m[I 2022-10-01 17:11:20,014]\u001b[0m Trial 20 finished with value: 0.37953004588112443 and parameters: {'num_leaves': 35}. Best is trial 20 with value: 0.37953004588112443.\u001b[0m\n",
      "num_leaves, val_score: 0.379530:  75%|#######5  | 15/20 [00:05<00:01,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-01 17:11:20,223]\u001b[0m Trial 21 finished with value: 0.38125572141441133 and parameters: {'num_leaves': 32}. Best is trial 20 with value: 0.37953004588112443.\u001b[0m\n",
      "num_leaves, val_score: 0.379530:  75%|#######5  | 15/20 [00:05<00:01,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379530:  80%|########  | 16/20 [00:05<00:00,  4.07it/s]\u001b[32m[I 2022-10-01 17:11:20,482]\u001b[0m Trial 22 finished with value: 0.3829068161273096 and parameters: {'num_leaves': 39}. Best is trial 20 with value: 0.37953004588112443.\u001b[0m\n",
      "num_leaves, val_score: 0.379530:  80%|########  | 16/20 [00:05<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379530:  85%|########5 | 17/20 [00:06<00:00,  3.52it/s]\u001b[32m[I 2022-10-01 17:11:20,862]\u001b[0m Trial 23 finished with value: 0.3956071504919088 and parameters: {'num_leaves': 94}. Best is trial 20 with value: 0.37953004588112443.\u001b[0m\n",
      "num_leaves, val_score: 0.379530:  90%|######### | 18/20 [00:06<00:00,  3.84it/s]\u001b[32m[I 2022-10-01 17:11:21,065]\u001b[0m Trial 24 finished with value: 0.37953004588112443 and parameters: {'num_leaves': 35}. Best is trial 20 with value: 0.37953004588112443.\u001b[0m\n",
      "num_leaves, val_score: 0.379530:  90%|######### | 18/20 [00:06<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379530:  95%|#########5| 19/20 [00:07<00:00,  3.04it/s]\u001b[32m[I 2022-10-01 17:11:21,559]\u001b[0m Trial 25 finished with value: 0.4069835629393012 and parameters: {'num_leaves': 153}. Best is trial 20 with value: 0.37953004588112443.\u001b[0m\n",
      "num_leaves, val_score: 0.379530:  95%|#########5| 19/20 [00:07<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.379530: 100%|##########| 20/20 [00:07<00:00,  3.17it/s]\u001b[32m[I 2022-10-01 17:11:21,843]\u001b[0m Trial 26 finished with value: 0.38749647232072426 and parameters: {'num_leaves': 57}. Best is trial 20 with value: 0.37953004588112443.\u001b[0m\n",
      "num_leaves, val_score: 0.379530: 100%|##########| 20/20 [00:07<00:00,  2.74it/s]\n",
      "bagging, val_score: 0.379530:  10%|#         | 1/10 [00:00<00:01,  5.08it/s]\u001b[32m[I 2022-10-01 17:11:22,048]\u001b[0m Trial 27 finished with value: 0.38534715162437083 and parameters: {'bagging_fraction': 0.9883305977384128, 'bagging_freq': 1}. Best is trial 27 with value: 0.38534715162437083.\u001b[0m\n",
      "bagging, val_score: 0.379530:  10%|#         | 1/10 [00:00<00:01,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379530:  20%|##        | 2/10 [00:00<00:01,  4.93it/s]\u001b[32m[I 2022-10-01 17:11:22,255]\u001b[0m Trial 28 finished with value: 0.3905130538113351 and parameters: {'bagging_fraction': 0.511116190678235, 'bagging_freq': 6}. Best is trial 27 with value: 0.38534715162437083.\u001b[0m\n",
      "bagging, val_score: 0.379530:  20%|##        | 2/10 [00:00<00:01,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379530:  30%|###       | 3/10 [00:00<00:01,  4.90it/s]\u001b[32m[I 2022-10-01 17:11:22,461]\u001b[0m Trial 29 finished with value: 0.3893972937719148 and parameters: {'bagging_fraction': 0.6355346619233594, 'bagging_freq': 7}. Best is trial 27 with value: 0.38534715162437083.\u001b[0m\n",
      "bagging, val_score: 0.379530:  30%|###       | 3/10 [00:00<00:01,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379530:  40%|####      | 4/10 [00:00<00:01,  4.94it/s]\u001b[32m[I 2022-10-01 17:11:22,660]\u001b[0m Trial 30 finished with value: 0.3869868938814721 and parameters: {'bagging_fraction': 0.7498943260226316, 'bagging_freq': 1}. Best is trial 27 with value: 0.38534715162437083.\u001b[0m\n",
      "bagging, val_score: 0.379530:  40%|####      | 4/10 [00:00<00:01,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379530:  50%|#####     | 5/10 [00:01<00:01,  4.85it/s]\u001b[32m[I 2022-10-01 17:11:22,873]\u001b[0m Trial 31 finished with value: 0.3879739055293657 and parameters: {'bagging_fraction': 0.8317525835900037, 'bagging_freq': 5}. Best is trial 27 with value: 0.38534715162437083.\u001b[0m\n",
      "bagging, val_score: 0.379530:  50%|#####     | 5/10 [00:01<00:01,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379530:  60%|######    | 6/10 [00:01<00:00,  4.91it/s]\u001b[32m[I 2022-10-01 17:11:23,073]\u001b[0m Trial 32 finished with value: 0.3919111462001119 and parameters: {'bagging_fraction': 0.4163448813756882, 'bagging_freq': 6}. Best is trial 27 with value: 0.38534715162437083.\u001b[0m\n",
      "bagging, val_score: 0.379530:  60%|######    | 6/10 [00:01<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379530:  70%|#######   | 7/10 [00:01<00:00,  3.52it/s]\u001b[32m[I 2022-10-01 17:11:23,522]\u001b[0m Trial 33 finished with value: 0.3883954596949414 and parameters: {'bagging_fraction': 0.47897618941741316, 'bagging_freq': 3}. Best is trial 27 with value: 0.38534715162437083.\u001b[0m\n",
      "bagging, val_score: 0.379530:  70%|#######   | 7/10 [00:01<00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379530:  80%|########  | 8/10 [00:01<00:00,  3.61it/s]\u001b[32m[I 2022-10-01 17:11:23,784]\u001b[0m Trial 34 finished with value: 0.38687748139630646 and parameters: {'bagging_fraction': 0.9910330272974446, 'bagging_freq': 7}. Best is trial 27 with value: 0.38534715162437083.\u001b[0m\n",
      "bagging, val_score: 0.379530:  90%|######### | 9/10 [00:02<00:00,  4.00it/s]\u001b[32m[I 2022-10-01 17:11:23,975]\u001b[0m Trial 35 finished with value: 0.3886641736145298 and parameters: {'bagging_fraction': 0.6862014153530422, 'bagging_freq': 7}. Best is trial 27 with value: 0.38534715162437083.\u001b[0m\n",
      "bagging, val_score: 0.379530:  90%|######### | 9/10 [00:02<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.379530: 100%|##########| 10/10 [00:02<00:00,  3.63it/s]\u001b[32m[I 2022-10-01 17:11:24,306]\u001b[0m Trial 36 finished with value: 0.3825083257722539 and parameters: {'bagging_fraction': 0.6565880181111637, 'bagging_freq': 3}. Best is trial 36 with value: 0.3825083257722539.\u001b[0m\n",
      "bagging, val_score: 0.379530: 100%|##########| 10/10 [00:02<00:00,  4.07it/s]\n",
      "feature_fraction_stage2, val_score: 0.379530:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.379530:  33%|###3      | 1/3 [00:00<00:00,  2.07it/s]\u001b[32m[I 2022-10-01 17:11:24,797]\u001b[0m Trial 37 finished with value: 0.38168052752279036 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.38168052752279036.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.379530:  33%|###3      | 1/3 [00:00<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.379530:  67%|######6   | 2/3 [00:00<00:00,  2.13it/s]\u001b[32m[I 2022-10-01 17:11:25,258]\u001b[0m Trial 38 finished with value: 0.38089397839643657 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 38 with value: 0.38089397839643657.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.379530:  67%|######6   | 2/3 [00:00<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.379530: 100%|##########| 3/3 [00:01<00:00,  2.22it/s]\u001b[32m[I 2022-10-01 17:11:25,686]\u001b[0m Trial 39 finished with value: 0.38168052752279036 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 38 with value: 0.38089397839643657.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.379530: 100%|##########| 3/3 [00:01<00:00,  2.18it/s]\n",
      "regularization_factors, val_score: 0.379530:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:   5%|5         | 1/20 [00:00<00:04,  4.49it/s]\u001b[32m[I 2022-10-01 17:11:25,917]\u001b[0m Trial 40 finished with value: 0.3859130057787765 and parameters: {'lambda_l1': 3.148460928828545, 'lambda_l2': 0.0722039784678056}. Best is trial 40 with value: 0.3859130057787765.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:   5%|5         | 1/20 [00:00<00:04,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:  10%|#         | 2/20 [00:00<00:06,  2.84it/s]\u001b[32m[I 2022-10-01 17:11:26,361]\u001b[0m Trial 41 finished with value: 0.3851653180191499 and parameters: {'lambda_l1': 0.4710178313719168, 'lambda_l2': 3.988286723512191e-06}. Best is trial 41 with value: 0.3851653180191499.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  10%|#         | 2/20 [00:00<00:06,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:  15%|#5        | 3/20 [00:00<00:05,  3.14it/s]\u001b[32m[I 2022-10-01 17:11:26,637]\u001b[0m Trial 42 finished with value: 0.3842434590854082 and parameters: {'lambda_l1': 6.953636456983614e-08, 'lambda_l2': 0.14548060431152796}. Best is trial 42 with value: 0.3842434590854082.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  15%|#5        | 3/20 [00:00<00:05,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:  20%|##        | 4/20 [00:01<00:04,  3.38it/s]\u001b[32m[I 2022-10-01 17:11:26,899]\u001b[0m Trial 43 finished with value: 0.39339589547235065 and parameters: {'lambda_l1': 7.160725523485754, 'lambda_l2': 4.497297373429429e-07}. Best is trial 42 with value: 0.3842434590854082.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  20%|##        | 4/20 [00:01<00:04,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:  25%|##5       | 5/20 [00:01<00:03,  3.82it/s]\u001b[32m[I 2022-10-01 17:11:27,100]\u001b[0m Trial 44 finished with value: 0.3816752440218259 and parameters: {'lambda_l1': 8.742440686909912e-05, 'lambda_l2': 0.00045721468730318263}. Best is trial 44 with value: 0.3816752440218259.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  30%|###       | 6/20 [00:01<00:03,  4.27it/s]\u001b[32m[I 2022-10-01 17:11:27,280]\u001b[0m Trial 45 finished with value: 0.38405666076240935 and parameters: {'lambda_l1': 0.0036791492340202537, 'lambda_l2': 4.469369432665842e-07}. Best is trial 44 with value: 0.3816752440218259.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  30%|###       | 6/20 [00:01<00:03,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:  35%|###5      | 7/20 [00:01<00:02,  4.77it/s]\u001b[32m[I 2022-10-01 17:11:27,439]\u001b[0m Trial 46 finished with value: 0.38109411398731874 and parameters: {'lambda_l1': 0.00409769445997152, 'lambda_l2': 5.856191484943802e-06}. Best is trial 46 with value: 0.38109411398731874.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  40%|####      | 8/20 [00:01<00:02,  5.26it/s]\u001b[32m[I 2022-10-01 17:11:27,588]\u001b[0m Trial 47 finished with value: 0.37953004571151505 and parameters: {'lambda_l1': 1.2500399596141634e-07, 'lambda_l2': 1.641499179114036e-07}. Best is trial 47 with value: 0.37953004571151505.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  40%|####      | 8/20 [00:01<00:02,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:  45%|####5     | 9/20 [00:02<00:02,  5.26it/s]\u001b[32m[I 2022-10-01 17:11:27,779]\u001b[0m Trial 48 finished with value: 0.38454629102829047 and parameters: {'lambda_l1': 3.190524519076416e-08, 'lambda_l2': 0.10253330971303083}. Best is trial 47 with value: 0.37953004571151505.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  45%|####5     | 9/20 [00:02<00:02,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:  50%|#####     | 10/20 [00:02<00:02,  4.00it/s]\u001b[32m[I 2022-10-01 17:11:28,162]\u001b[0m Trial 49 finished with value: 0.3829266554371096 and parameters: {'lambda_l1': 0.01065217672182608, 'lambda_l2': 0.0032359784237194554}. Best is trial 47 with value: 0.37953004571151505.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  50%|#####     | 10/20 [00:02<00:02,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:  55%|#####5    | 11/20 [00:02<00:02,  4.16it/s]\u001b[32m[I 2022-10-01 17:11:28,381]\u001b[0m Trial 50 finished with value: 0.3795300438303988 and parameters: {'lambda_l1': 2.878567087481868e-06, 'lambda_l2': 2.3675148318578398e-08}. Best is trial 50 with value: 0.3795300438303988.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  55%|#####5    | 11/20 [00:02<00:02,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:  60%|######    | 12/20 [00:03<00:02,  3.58it/s]\u001b[32m[I 2022-10-01 17:11:28,750]\u001b[0m Trial 51 finished with value: 0.37953004419382413 and parameters: {'lambda_l1': 2.3714226938453697e-06, 'lambda_l2': 1.07145714420793e-08}. Best is trial 50 with value: 0.3795300438303988.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  60%|######    | 12/20 [00:03<00:02,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379530:  65%|######5   | 13/20 [00:03<00:01,  3.78it/s]\u001b[32m[I 2022-10-01 17:11:28,981]\u001b[0m Trial 52 finished with value: 0.37953004117866734 and parameters: {'lambda_l1': 6.393398375343361e-06, 'lambda_l2': 1.8065631567007613e-08}. Best is trial 52 with value: 0.37953004117866734.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  70%|#######   | 14/20 [00:03<00:01,  4.02it/s]\u001b[32m[I 2022-10-01 17:11:29,192]\u001b[0m Trial 53 finished with value: 0.37953004381267036 and parameters: {'lambda_l1': 2.884113173600141e-06, 'lambda_l2': 2.5225431945663933e-08}. Best is trial 52 with value: 0.37953004117866734.\u001b[0m\n",
      "regularization_factors, val_score: 0.379530:  70%|#######   | 14/20 [00:03<00:01,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379369:  75%|#######5  | 15/20 [00:03<00:01,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-01 17:11:29,407]\u001b[0m Trial 54 finished with value: 0.3793689778635513 and parameters: {'lambda_l1': 1.8442237175376466e-05, 'lambda_l2': 1.7093130666286656e-05}. Best is trial 54 with value: 0.3793689778635513.\u001b[0m\n",
      "regularization_factors, val_score: 0.379369:  75%|#######5  | 15/20 [00:03<00:01,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379369:  80%|########  | 16/20 [00:04<00:01,  3.81it/s]\u001b[32m[I 2022-10-01 17:11:29,725]\u001b[0m Trial 55 finished with value: 0.3825427761885218 and parameters: {'lambda_l1': 0.0001312667929498503, 'lambda_l2': 2.9178986952756538e-05}. Best is trial 54 with value: 0.3793689778635513.\u001b[0m\n",
      "regularization_factors, val_score: 0.379369:  85%|########5 | 17/20 [00:04<00:00,  4.09it/s]\u001b[32m[I 2022-10-01 17:11:29,929]\u001b[0m Trial 56 finished with value: 0.3819155097901033 and parameters: {'lambda_l1': 2.634983161845411e-05, 'lambda_l2': 0.00018383784465935988}. Best is trial 54 with value: 0.3793689778635513.\u001b[0m\n",
      "regularization_factors, val_score: 0.379369:  85%|########5 | 17/20 [00:04<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379369:  90%|######### | 18/20 [00:04<00:00,  3.94it/s]\u001b[32m[I 2022-10-01 17:11:30,204]\u001b[0m Trial 57 finished with value: 0.3808208183631301 and parameters: {'lambda_l1': 3.722873069971494e-07, 'lambda_l2': 6.103032066433687}. Best is trial 54 with value: 0.3793689778635513.\u001b[0m\n",
      "regularization_factors, val_score: 0.379369:  90%|######### | 18/20 [00:04<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.379369:  95%|#########5| 19/20 [00:04<00:00,  3.95it/s]\u001b[32m[I 2022-10-01 17:11:30,455]\u001b[0m Trial 58 finished with value: 0.38492055888562576 and parameters: {'lambda_l1': 0.0010285774577887612, 'lambda_l2': 5.052618238928733e-06}. Best is trial 54 with value: 0.3793689778635513.\u001b[0m\n",
      "regularization_factors, val_score: 0.379369: 100%|##########| 20/20 [00:04<00:00,  4.20it/s]\u001b[32m[I 2022-10-01 17:11:30,657]\u001b[0m Trial 59 finished with value: 0.38334494814803177 and parameters: {'lambda_l1': 0.060077178542464804, 'lambda_l2': 0.000929021365650303}. Best is trial 54 with value: 0.3793689778635513.\u001b[0m\n",
      "regularization_factors, val_score: 0.379369: 100%|##########| 20/20 [00:04<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.379369:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.379369:  20%|##        | 1/5 [00:01<00:07,  1.81s/it]\u001b[32m[I 2022-10-01 17:11:32,477]\u001b[0m Trial 60 finished with value: 0.38181150866323393 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.38181150866323393.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.379369:  20%|##        | 1/5 [00:01<00:07,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.379369:  40%|####      | 2/5 [00:03<00:05,  1.85s/it]\u001b[32m[I 2022-10-01 17:11:34,346]\u001b[0m Trial 61 finished with value: 0.38146413543259283 and parameters: {'min_child_samples': 50}. Best is trial 61 with value: 0.38146413543259283.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.379369:  40%|####      | 2/5 [00:03<00:05,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.379369:  60%|######    | 3/5 [00:05<00:03,  1.78s/it]\u001b[32m[I 2022-10-01 17:11:36,059]\u001b[0m Trial 62 finished with value: 0.3882150213555022 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.38146413543259283.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.379369:  60%|######    | 3/5 [00:05<00:03,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.379369:  80%|########  | 4/5 [00:07<00:01,  1.78s/it]\u001b[32m[I 2022-10-01 17:11:37,820]\u001b[0m Trial 63 finished with value: 0.3844214436367972 and parameters: {'min_child_samples': 5}. Best is trial 61 with value: 0.38146413543259283.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.379369:  80%|########  | 4/5 [00:07<00:01,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3506, number of negative: 3448\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504170 -> initscore=0.016681\n",
      "[LightGBM] [Info] Start training from score 0.016681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.379369: 100%|##########| 5/5 [00:09<00:00,  2.02s/it]\u001b[32m[I 2022-10-01 17:11:40,275]\u001b[0m Trial 64 finished with value: 0.3813156477199352 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.3813156477199352.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.379369: 100%|##########| 5/5 [00:09<00:00,  1.92s/it]\n",
      "\u001b[32m[I 2022-10-01 17:11:40,286]\u001b[0m A new study created in memory with name: no-name-eda0e669-7672-43c2-a353-76d1ab0a8393\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "fold 2/acc: 0.8154111558366878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "feature_fraction, val_score: 0.372886:  14%|#4        | 1/7 [00:01<00:09,  1.62s/it]\u001b[32m[I 2022-10-01 17:11:41,909]\u001b[0m Trial 0 finished with value: 0.3728861127287743 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.3728861127287743.\u001b[0m\n",
      "feature_fraction, val_score: 0.372886:  14%|#4        | 1/7 [00:01<00:09,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.370822:  29%|##8       | 2/7 [00:02<00:07,  1.44s/it]\u001b[32m[I 2022-10-01 17:11:43,217]\u001b[0m Trial 1 finished with value: 0.3708216367652059 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.3708216367652059.\u001b[0m\n",
      "feature_fraction, val_score: 0.370822:  29%|##8       | 2/7 [00:02<00:07,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.370822:  43%|####2     | 3/7 [00:04<00:05,  1.32s/it]\u001b[32m[I 2022-10-01 17:11:44,408]\u001b[0m Trial 2 finished with value: 0.37336909963454046 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.3708216367652059.\u001b[0m\n",
      "feature_fraction, val_score: 0.370822:  43%|####2     | 3/7 [00:04<00:05,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.370822:  57%|#####7    | 4/7 [00:05<00:03,  1.20s/it]\u001b[32m[I 2022-10-01 17:11:45,426]\u001b[0m Trial 3 finished with value: 0.3717140940246901 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.3708216367652059.\u001b[0m\n",
      "feature_fraction, val_score: 0.370822:  57%|#####7    | 4/7 [00:05<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.370822:  71%|#######1  | 5/7 [00:06<00:02,  1.11s/it]\u001b[32m[I 2022-10-01 17:11:46,380]\u001b[0m Trial 4 finished with value: 0.3722306923148053 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.3708216367652059.\u001b[0m\n",
      "feature_fraction, val_score: 0.370822:  71%|#######1  | 5/7 [00:06<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.369378:  86%|########5 | 6/7 [00:07<00:01,  1.10s/it]\u001b[32m[I 2022-10-01 17:11:47,454]\u001b[0m Trial 5 finished with value: 0.3693780760673029 and parameters: {'feature_fraction': 0.5}. Best is trial 5 with value: 0.3693780760673029.\u001b[0m\n",
      "feature_fraction, val_score: 0.369378:  86%|########5 | 6/7 [00:07<00:01,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.367584: 100%|##########| 7/7 [00:08<00:00,  1.03s/it]\u001b[32m[I 2022-10-01 17:11:48,327]\u001b[0m Trial 6 finished with value: 0.36758415970792735 and parameters: {'feature_fraction': 0.6}. Best is trial 6 with value: 0.36758415970792735.\u001b[0m\n",
      "feature_fraction, val_score: 0.367584: 100%|##########| 7/7 [00:08<00:00,  1.15s/it]\n",
      "num_leaves, val_score: 0.367584:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.367584:   5%|5         | 1/20 [00:02<00:45,  2.41s/it]\u001b[32m[I 2022-10-01 17:11:50,749]\u001b[0m Trial 7 finished with value: 0.3762072638152137 and parameters: {'num_leaves': 60}. Best is trial 7 with value: 0.3762072638152137.\u001b[0m\n",
      "num_leaves, val_score: 0.367584:   5%|5         | 1/20 [00:02<00:45,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.367584:  10%|#         | 2/20 [00:04<00:42,  2.35s/it]\u001b[32m[I 2022-10-01 17:11:53,046]\u001b[0m Trial 8 finished with value: 0.370562090332749 and parameters: {'num_leaves': 73}. Best is trial 8 with value: 0.370562090332749.\u001b[0m\n",
      "num_leaves, val_score: 0.367584:  15%|#5        | 3/20 [00:04<00:22,  1.34s/it]\u001b[32m[I 2022-10-01 17:11:53,196]\u001b[0m Trial 9 finished with value: 0.4718816519901019 and parameters: {'num_leaves': 2}. Best is trial 8 with value: 0.370562090332749.\u001b[0m\n",
      "num_leaves, val_score: 0.367584:  15%|#5        | 3/20 [00:04<00:22,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.367584:  20%|##        | 4/20 [00:06<00:22,  1.39s/it]\u001b[32m[I 2022-10-01 17:11:54,667]\u001b[0m Trial 10 finished with value: 0.37337182337989516 and parameters: {'num_leaves': 64}. Best is trial 8 with value: 0.370562090332749.\u001b[0m\n",
      "num_leaves, val_score: 0.367584:  20%|##        | 4/20 [00:06<00:22,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.367584:  25%|##5       | 5/20 [00:09<00:31,  2.09s/it]\u001b[32m[I 2022-10-01 17:11:58,003]\u001b[0m Trial 11 finished with value: 0.37794963620067795 and parameters: {'num_leaves': 253}. Best is trial 8 with value: 0.370562090332749.\u001b[0m\n",
      "num_leaves, val_score: 0.367584:  25%|##5       | 5/20 [00:09<00:31,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.367584:  30%|###       | 6/20 [00:12<00:31,  2.26s/it]\u001b[32m[I 2022-10-01 17:12:00,579]\u001b[0m Trial 12 finished with value: 0.3709977394010564 and parameters: {'num_leaves': 99}. Best is trial 8 with value: 0.370562090332749.\u001b[0m\n",
      "num_leaves, val_score: 0.367584:  30%|###       | 6/20 [00:12<00:31,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  35%|###5      | 7/20 [00:13<00:23,  1.81s/it]\u001b[32m[I 2022-10-01 17:12:01,460]\u001b[0m Trial 13 finished with value: 0.3655473704621694 and parameters: {'num_leaves': 36}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  35%|###5      | 7/20 [00:13<00:23,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  40%|####      | 8/20 [00:14<00:20,  1.73s/it]\u001b[32m[I 2022-10-01 17:12:03,009]\u001b[0m Trial 14 finished with value: 0.3689893506279649 and parameters: {'num_leaves': 74}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  40%|####      | 8/20 [00:14<00:20,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  45%|####5     | 9/20 [00:17<00:23,  2.18s/it]\u001b[32m[I 2022-10-01 17:12:06,187]\u001b[0m Trial 15 finished with value: 0.377944349881313 and parameters: {'num_leaves': 197}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  45%|####5     | 9/20 [00:17<00:23,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  50%|#####     | 10/20 [00:19<00:21,  2.16s/it]\u001b[32m[I 2022-10-01 17:12:08,319]\u001b[0m Trial 16 finished with value: 0.37363185499892254 and parameters: {'num_leaves': 112}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  50%|#####     | 10/20 [00:19<00:21,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  55%|#####5    | 11/20 [00:20<00:15,  1.76s/it]\u001b[32m[I 2022-10-01 17:12:09,165]\u001b[0m Trial 17 finished with value: 0.3684751403703844 and parameters: {'num_leaves': 14}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  60%|######    | 12/20 [00:21<00:10,  1.29s/it]\u001b[32m[I 2022-10-01 17:12:09,374]\u001b[0m Trial 18 finished with value: 0.40740118481916515 and parameters: {'num_leaves': 4}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  60%|######    | 12/20 [00:21<00:10,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  65%|######5   | 13/20 [00:22<00:09,  1.37s/it]\u001b[32m[I 2022-10-01 17:12:10,922]\u001b[0m Trial 19 finished with value: 0.36712109604580867 and parameters: {'num_leaves': 30}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  65%|######5   | 13/20 [00:22<00:09,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  70%|#######   | 14/20 [00:25<00:11,  1.87s/it]\u001b[32m[I 2022-10-01 17:12:13,944]\u001b[0m Trial 20 finished with value: 0.3760152720305514 and parameters: {'num_leaves': 157}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  70%|#######   | 14/20 [00:25<00:11,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  75%|#######5  | 15/20 [00:29<00:11,  2.34s/it]\u001b[32m[I 2022-10-01 17:12:17,391]\u001b[0m Trial 21 finished with value: 0.3768531790256322 and parameters: {'num_leaves': 163}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  75%|#######5  | 15/20 [00:29<00:11,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  80%|########  | 16/20 [00:29<00:07,  1.91s/it]\u001b[32m[I 2022-10-01 17:12:18,287]\u001b[0m Trial 22 finished with value: 0.37521118204524156 and parameters: {'num_leaves': 38}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  80%|########  | 16/20 [00:29<00:07,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  85%|########5 | 17/20 [00:30<00:04,  1.61s/it]\u001b[32m[I 2022-10-01 17:12:19,190]\u001b[0m Trial 23 finished with value: 0.36712109604580867 and parameters: {'num_leaves': 30}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  85%|########5 | 17/20 [00:30<00:04,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  90%|######### | 18/20 [00:33<00:03,  1.83s/it]\u001b[32m[I 2022-10-01 17:12:21,530]\u001b[0m Trial 24 finished with value: 0.37432385937264806 and parameters: {'num_leaves': 132}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  90%|######### | 18/20 [00:33<00:03,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547:  95%|#########5| 19/20 [00:34<00:01,  1.56s/it]\u001b[32m[I 2022-10-01 17:12:22,481]\u001b[0m Trial 25 finished with value: 0.3676591926063444 and parameters: {'num_leaves': 40}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547:  95%|#########5| 19/20 [00:34<00:01,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.365547: 100%|##########| 20/20 [00:37<00:00,  2.08s/it]\u001b[32m[I 2022-10-01 17:12:25,774]\u001b[0m Trial 26 finished with value: 0.38743802376181524 and parameters: {'num_leaves': 98}. Best is trial 13 with value: 0.3655473704621694.\u001b[0m\n",
      "num_leaves, val_score: 0.365547: 100%|##########| 20/20 [00:37<00:00,  1.87s/it]\n",
      "bagging, val_score: 0.365547:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365547:  10%|#         | 1/10 [00:01<00:12,  1.35s/it]\u001b[32m[I 2022-10-01 17:12:27,139]\u001b[0m Trial 27 finished with value: 0.37600183461760467 and parameters: {'bagging_fraction': 0.6363442802733696, 'bagging_freq': 3}. Best is trial 27 with value: 0.37600183461760467.\u001b[0m\n",
      "bagging, val_score: 0.365547:  10%|#         | 1/10 [00:01<00:12,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365547:  20%|##        | 2/10 [00:03<00:12,  1.60s/it]\u001b[32m[I 2022-10-01 17:12:28,912]\u001b[0m Trial 28 finished with value: 0.37203574596057515 and parameters: {'bagging_fraction': 0.8016155504453419, 'bagging_freq': 2}. Best is trial 28 with value: 0.37203574596057515.\u001b[0m\n",
      "bagging, val_score: 0.365547:  20%|##        | 2/10 [00:03<00:12,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365547:  30%|###       | 3/10 [00:04<00:09,  1.39s/it]\u001b[32m[I 2022-10-01 17:12:30,054]\u001b[0m Trial 29 finished with value: 0.37213443724609196 and parameters: {'bagging_fraction': 0.9259667604214536, 'bagging_freq': 7}. Best is trial 28 with value: 0.37203574596057515.\u001b[0m\n",
      "bagging, val_score: 0.365547:  30%|###       | 3/10 [00:04<00:09,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365547:  40%|####      | 4/10 [00:05<00:07,  1.31s/it]\u001b[32m[I 2022-10-01 17:12:31,252]\u001b[0m Trial 30 finished with value: 0.3791923627844745 and parameters: {'bagging_fraction': 0.690362076278756, 'bagging_freq': 3}. Best is trial 28 with value: 0.37203574596057515.\u001b[0m\n",
      "bagging, val_score: 0.365547:  40%|####      | 4/10 [00:05<00:07,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365547:  50%|#####     | 5/10 [00:07<00:08,  1.69s/it]\u001b[32m[I 2022-10-01 17:12:33,612]\u001b[0m Trial 31 finished with value: 0.37149005455672196 and parameters: {'bagging_fraction': 0.6621705311579855, 'bagging_freq': 6}. Best is trial 31 with value: 0.37149005455672196.\u001b[0m\n",
      "bagging, val_score: 0.365547:  50%|#####     | 5/10 [00:07<00:08,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365547:  60%|######    | 6/10 [00:08<00:05,  1.49s/it]\u001b[32m[I 2022-10-01 17:12:34,711]\u001b[0m Trial 32 finished with value: 0.3718560823707683 and parameters: {'bagging_fraction': 0.6562168301525138, 'bagging_freq': 3}. Best is trial 31 with value: 0.37149005455672196.\u001b[0m\n",
      "bagging, val_score: 0.365547:  60%|######    | 6/10 [00:08<00:05,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365547:  70%|#######   | 7/10 [00:09<00:03,  1.32s/it]\u001b[32m[I 2022-10-01 17:12:35,686]\u001b[0m Trial 33 finished with value: 0.37141986818577094 and parameters: {'bagging_fraction': 0.900448106893808, 'bagging_freq': 7}. Best is trial 33 with value: 0.37141986818577094.\u001b[0m\n",
      "bagging, val_score: 0.365547:  70%|#######   | 7/10 [00:09<00:03,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365547:  80%|########  | 8/10 [00:10<00:02,  1.19s/it]\u001b[32m[I 2022-10-01 17:12:36,604]\u001b[0m Trial 34 finished with value: 0.3692250172993578 and parameters: {'bagging_fraction': 0.820273846461303, 'bagging_freq': 4}. Best is trial 34 with value: 0.3692250172993578.\u001b[0m\n",
      "bagging, val_score: 0.365547:  80%|########  | 8/10 [00:10<00:02,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365547:  90%|######### | 9/10 [00:11<00:01,  1.14s/it]\u001b[32m[I 2022-10-01 17:12:37,637]\u001b[0m Trial 35 finished with value: 0.3736281651914969 and parameters: {'bagging_fraction': 0.9462319798148474, 'bagging_freq': 7}. Best is trial 34 with value: 0.3692250172993578.\u001b[0m\n",
      "bagging, val_score: 0.365547:  90%|######### | 9/10 [00:11<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.365547: 100%|##########| 10/10 [00:12<00:00,  1.09s/it]\u001b[32m[I 2022-10-01 17:12:38,617]\u001b[0m Trial 36 finished with value: 0.3742351389758336 and parameters: {'bagging_fraction': 0.9584378256390478, 'bagging_freq': 4}. Best is trial 34 with value: 0.3692250172993578.\u001b[0m\n",
      "bagging, val_score: 0.365547: 100%|##########| 10/10 [00:12<00:00,  1.28s/it]\n",
      "feature_fraction_stage2, val_score: 0.365547:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.365547:  17%|#6        | 1/6 [00:00<00:04,  1.10it/s]\u001b[32m[I 2022-10-01 17:12:39,533]\u001b[0m Trial 37 finished with value: 0.3655473704621694 and parameters: {'feature_fraction': 0.616}. Best is trial 37 with value: 0.3655473704621694.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.365547:  17%|#6        | 1/6 [00:00<00:04,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.365547:  33%|###3      | 2/6 [00:01<00:03,  1.11it/s]\u001b[32m[I 2022-10-01 17:12:40,422]\u001b[0m Trial 38 finished with value: 0.3718522882700601 and parameters: {'feature_fraction': 0.584}. Best is trial 37 with value: 0.3655473704621694.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.365547:  33%|###3      | 2/6 [00:01<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.365547:  50%|#####     | 3/6 [00:02<00:02,  1.12it/s]\u001b[32m[I 2022-10-01 17:12:41,313]\u001b[0m Trial 39 finished with value: 0.36988311382242134 and parameters: {'feature_fraction': 0.52}. Best is trial 37 with value: 0.3655473704621694.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.365547:  50%|#####     | 3/6 [00:02<00:02,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.365547:  67%|######6   | 4/6 [00:03<00:01,  1.07it/s]\u001b[32m[I 2022-10-01 17:12:42,308]\u001b[0m Trial 40 finished with value: 0.3753469700070737 and parameters: {'feature_fraction': 0.6799999999999999}. Best is trial 37 with value: 0.3655473704621694.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.365547:  67%|######6   | 4/6 [00:03<00:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.365547:  83%|########3 | 5/6 [00:04<00:00,  1.06it/s]\u001b[32m[I 2022-10-01 17:12:43,270]\u001b[0m Trial 41 finished with value: 0.36988311382242134 and parameters: {'feature_fraction': 0.552}. Best is trial 37 with value: 0.3655473704621694.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.365547:  83%|########3 | 5/6 [00:04<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.365547: 100%|##########| 6/6 [00:05<00:00,  1.09it/s]\u001b[32m[I 2022-10-01 17:12:44,145]\u001b[0m Trial 42 finished with value: 0.372480628926086 and parameters: {'feature_fraction': 0.6479999999999999}. Best is trial 37 with value: 0.3655473704621694.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.365547: 100%|##########| 6/6 [00:05<00:00,  1.09it/s]\n",
      "regularization_factors, val_score: 0.365547:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:   5%|5         | 1/20 [00:00<00:16,  1.18it/s]\u001b[32m[I 2022-10-01 17:12:44,997]\u001b[0m Trial 43 finished with value: 0.36554737015132027 and parameters: {'lambda_l1': 1.3121282663038488e-08, 'lambda_l2': 2.446627352932581e-07}. Best is trial 43 with value: 0.36554737015132027.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:   5%|5         | 1/20 [00:00<00:16,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  10%|#         | 2/20 [00:01<00:16,  1.10it/s]\u001b[32m[I 2022-10-01 17:12:45,956]\u001b[0m Trial 44 finished with value: 0.3719459677796048 and parameters: {'lambda_l1': 0.00016066780488445463, 'lambda_l2': 0.0001314091124727301}. Best is trial 43 with value: 0.36554737015132027.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  10%|#         | 2/20 [00:01<00:16,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  15%|#5        | 3/20 [00:02<00:15,  1.08it/s]\u001b[32m[I 2022-10-01 17:12:46,898]\u001b[0m Trial 45 finished with value: 0.36984036616117744 and parameters: {'lambda_l1': 0.08563420581771028, 'lambda_l2': 1.4708122673311753e-08}. Best is trial 43 with value: 0.36554737015132027.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  15%|#5        | 3/20 [00:02<00:15,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  20%|##        | 4/20 [00:03<00:16,  1.00s/it]\u001b[32m[I 2022-10-01 17:12:48,021]\u001b[0m Trial 46 finished with value: 0.3711860477467752 and parameters: {'lambda_l1': 0.043418798370190144, 'lambda_l2': 3.985925152421978}. Best is trial 43 with value: 0.36554737015132027.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  20%|##        | 4/20 [00:03<00:16,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  25%|##5       | 5/20 [00:04<00:14,  1.07it/s]\u001b[32m[I 2022-10-01 17:12:48,838]\u001b[0m Trial 47 finished with value: 0.3811665203671993 and parameters: {'lambda_l1': 7.4618845586096825, 'lambda_l2': 0.0001562489049973152}. Best is trial 43 with value: 0.36554737015132027.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  25%|##5       | 5/20 [00:04<00:14,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  30%|###       | 6/20 [00:05<00:12,  1.11it/s]\u001b[32m[I 2022-10-01 17:12:49,672]\u001b[0m Trial 48 finished with value: 0.37005754489760084 and parameters: {'lambda_l1': 1.192112632054919e-06, 'lambda_l2': 0.3764373750589301}. Best is trial 43 with value: 0.36554737015132027.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  30%|###       | 6/20 [00:05<00:12,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  35%|###5      | 7/20 [00:06<00:11,  1.13it/s]\u001b[32m[I 2022-10-01 17:12:50,514]\u001b[0m Trial 49 finished with value: 0.3671080556196055 and parameters: {'lambda_l1': 0.004826389668368877, 'lambda_l2': 0.003115992601970111}. Best is trial 43 with value: 0.36554737015132027.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  35%|###5      | 7/20 [00:06<00:11,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  40%|####      | 8/20 [00:07<00:10,  1.13it/s]\u001b[32m[I 2022-10-01 17:12:51,405]\u001b[0m Trial 50 finished with value: 0.3758056283414476 and parameters: {'lambda_l1': 3.1114238320523113, 'lambda_l2': 1.200939114236252e-08}. Best is trial 43 with value: 0.36554737015132027.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  40%|####      | 8/20 [00:07<00:10,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  45%|####5     | 9/20 [00:08<00:09,  1.14it/s]\u001b[32m[I 2022-10-01 17:12:52,261]\u001b[0m Trial 51 finished with value: 0.3731520661100747 and parameters: {'lambda_l1': 2.5746598054394834e-08, 'lambda_l2': 0.009259013905615194}. Best is trial 43 with value: 0.36554737015132027.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  45%|####5     | 9/20 [00:08<00:09,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  50%|#####     | 10/20 [00:08<00:08,  1.15it/s]\u001b[32m[I 2022-10-01 17:12:53,108]\u001b[0m Trial 52 finished with value: 0.37226069654491667 and parameters: {'lambda_l1': 0.00030051534588046983, 'lambda_l2': 0.0102958408036733}. Best is trial 43 with value: 0.36554737015132027.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  50%|#####     | 10/20 [00:08<00:08,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  55%|#####5    | 11/20 [00:09<00:08,  1.10it/s]\u001b[32m[I 2022-10-01 17:12:54,125]\u001b[0m Trial 53 finished with value: 0.3655473671313358 and parameters: {'lambda_l1': 1.8890367485557766e-06, 'lambda_l2': 1.0371874321556257e-06}. Best is trial 53 with value: 0.3655473671313358.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  55%|#####5    | 11/20 [00:09<00:08,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  60%|######    | 12/20 [00:10<00:07,  1.07it/s]\u001b[32m[I 2022-10-01 17:12:55,098]\u001b[0m Trial 54 finished with value: 0.36554736851282504 and parameters: {'lambda_l1': 2.65838180354778e-08, 'lambda_l2': 1.7743896733205808e-06}. Best is trial 53 with value: 0.3655473671313358.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  60%|######    | 12/20 [00:10<00:07,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  65%|######5   | 13/20 [00:12<00:06,  1.03it/s]\u001b[32m[I 2022-10-01 17:12:56,159]\u001b[0m Trial 55 finished with value: 0.3655473646098464 and parameters: {'lambda_l1': 2.510641582644108e-06, 'lambda_l2': 2.7366520856204196e-06}. Best is trial 55 with value: 0.3655473646098464.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  65%|######5   | 13/20 [00:12<00:06,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  70%|#######   | 14/20 [00:12<00:05,  1.05it/s]\u001b[32m[I 2022-10-01 17:12:57,082]\u001b[0m Trial 56 finished with value: 0.3655473584796663 and parameters: {'lambda_l1': 4.9210109555550505e-06, 'lambda_l2': 5.7609589832347285e-06}. Best is trial 56 with value: 0.3655473584796663.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  70%|#######   | 14/20 [00:12<00:05,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  75%|#######5  | 15/20 [00:13<00:04,  1.06it/s]\u001b[32m[I 2022-10-01 17:12:58,009]\u001b[0m Trial 57 finished with value: 0.3655473165409834 and parameters: {'lambda_l1': 5.2722884026693224e-06, 'lambda_l2': 4.404635719384813e-05}. Best is trial 57 with value: 0.3655473165409834.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  75%|#######5  | 15/20 [00:13<00:04,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.365547:  80%|########  | 16/20 [00:14<00:03,  1.07it/s]\u001b[32m[I 2022-10-01 17:12:58,911]\u001b[0m Trial 58 finished with value: 0.36981844092200067 and parameters: {'lambda_l1': 2.82948086041346e-05, 'lambda_l2': 3.350603087666732e-05}. Best is trial 57 with value: 0.3655473165409834.\u001b[0m\n",
      "regularization_factors, val_score: 0.365547:  80%|########  | 16/20 [00:14<00:03,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.364733:  85%|########5 | 17/20 [00:15<00:02,  1.09it/s]\u001b[32m[I 2022-10-01 17:12:59,795]\u001b[0m Trial 59 finished with value: 0.36473263528604977 and parameters: {'lambda_l1': 1.6712069029188244e-05, 'lambda_l2': 9.205769323760842e-06}. Best is trial 59 with value: 0.36473263528604977.\u001b[0m\n",
      "regularization_factors, val_score: 0.364733:  85%|########5 | 17/20 [00:15<00:02,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.364733:  90%|######### | 18/20 [00:16<00:01,  1.11it/s]\u001b[32m[I 2022-10-01 17:13:00,665]\u001b[0m Trial 60 finished with value: 0.3730260192243645 and parameters: {'lambda_l1': 2.5367347027917264e-07, 'lambda_l2': 0.0026126368690224293}. Best is trial 59 with value: 0.36473263528604977.\u001b[0m\n",
      "regularization_factors, val_score: 0.364733:  90%|######### | 18/20 [00:16<00:01,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.364733:  95%|#########5| 19/20 [00:17<00:00,  1.11it/s]\u001b[32m[I 2022-10-01 17:13:01,561]\u001b[0m Trial 61 finished with value: 0.3698184369900901 and parameters: {'lambda_l1': 3.078424515913803e-05, 'lambda_l2': 3.286501096443472e-05}. Best is trial 59 with value: 0.36473263528604977.\u001b[0m\n",
      "regularization_factors, val_score: 0.364733:  95%|#########5| 19/20 [00:17<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.364733: 100%|##########| 20/20 [00:18<00:00,  1.01it/s]\u001b[32m[I 2022-10-01 17:13:02,769]\u001b[0m Trial 62 finished with value: 0.3713048837882714 and parameters: {'lambda_l1': 0.0024438905754906016, 'lambda_l2': 1.783300233424863e-07}. Best is trial 59 with value: 0.36473263528604977.\u001b[0m\n",
      "regularization_factors, val_score: 0.364733: 100%|##########| 20/20 [00:18<00:00,  1.07it/s]\n",
      "min_data_in_leaf, val_score: 0.364733:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.364733:  20%|##        | 1/5 [00:00<00:03,  1.20it/s]\u001b[32m[I 2022-10-01 17:13:03,607]\u001b[0m Trial 63 finished with value: 0.3717606394871232 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.3717606394871232.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.364733:  20%|##        | 1/5 [00:00<00:03,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.364733:  40%|####      | 2/5 [00:01<00:02,  1.18it/s]\u001b[32m[I 2022-10-01 17:13:04,467]\u001b[0m Trial 64 finished with value: 0.3687111812356471 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.3687111812356471.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.364733:  40%|####      | 2/5 [00:01<00:02,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.364733:  60%|######    | 3/5 [00:02<00:01,  1.16it/s]\u001b[32m[I 2022-10-01 17:13:05,352]\u001b[0m Trial 65 finished with value: 0.37031053258873825 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.3687111812356471.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.364733:  60%|######    | 3/5 [00:02<00:01,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.364733:  80%|########  | 4/5 [00:03<00:00,  1.06it/s]\u001b[32m[I 2022-10-01 17:13:06,406]\u001b[0m Trial 66 finished with value: 0.37579974921179293 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.3687111812356471.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.364733:  80%|########  | 4/5 [00:03<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3495, number of negative: 3460\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502516 -> initscore=0.010065\n",
      "[LightGBM] [Info] Start training from score 0.010065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.364733: 100%|##########| 5/5 [00:04<00:00,  1.07it/s]\u001b[32m[I 2022-10-01 17:13:07,342]\u001b[0m Trial 67 finished with value: 0.37157537215327247 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.3687111812356471.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.364733: 100%|##########| 5/5 [00:04<00:00,  1.09it/s]\n",
      "\u001b[32m[I 2022-10-01 17:13:07,352]\u001b[0m A new study created in memory with name: no-name-3e7ea175-48f9-4cbf-a4f9-3e8ca39765cc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3/acc: 0.8158803222094362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yamada/.pyenv/versions/3.8.0/lib/python3.8/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.397043:  14%|#4        | 1/7 [00:01<00:10,  1.79s/it]\u001b[32m[I 2022-10-01 17:13:09,148]\u001b[0m Trial 0 finished with value: 0.3970426026781825 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.3970426026781825.\u001b[0m\n",
      "feature_fraction, val_score: 0.397043:  14%|#4        | 1/7 [00:01<00:10,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388287:  29%|##8       | 2/7 [00:03<00:09,  1.98s/it]\u001b[32m[I 2022-10-01 17:13:11,254]\u001b[0m Trial 1 finished with value: 0.38828743588801606 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.38828743588801606.\u001b[0m\n",
      "feature_fraction, val_score: 0.388287:  29%|##8       | 2/7 [00:03<00:09,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388287:  43%|####2     | 3/7 [00:05<00:07,  1.84s/it]\u001b[32m[I 2022-10-01 17:13:12,932]\u001b[0m Trial 2 finished with value: 0.3893634008792886 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.38828743588801606.\u001b[0m\n",
      "feature_fraction, val_score: 0.388287:  43%|####2     | 3/7 [00:05<00:07,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388287:  57%|#####7    | 4/7 [00:06<00:04,  1.59s/it]\u001b[32m[I 2022-10-01 17:13:14,150]\u001b[0m Trial 3 finished with value: 0.39611539058936335 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.38828743588801606.\u001b[0m\n",
      "feature_fraction, val_score: 0.388287:  57%|#####7    | 4/7 [00:06<00:04,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388287:  71%|#######1  | 5/7 [00:08<00:03,  1.65s/it]\u001b[32m[I 2022-10-01 17:13:15,905]\u001b[0m Trial 4 finished with value: 0.39716821093704185 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.38828743588801606.\u001b[0m\n",
      "feature_fraction, val_score: 0.388287:  71%|#######1  | 5/7 [00:08<00:03,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388287:  86%|########5 | 6/7 [00:10<00:01,  1.75s/it]\u001b[32m[I 2022-10-01 17:13:17,858]\u001b[0m Trial 5 finished with value: 0.39583094426673165 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.38828743588801606.\u001b[0m\n",
      "feature_fraction, val_score: 0.388287:  86%|########5 | 6/7 [00:10<00:01,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.388287: 100%|##########| 7/7 [00:11<00:00,  1.51s/it]\u001b[32m[I 2022-10-01 17:13:18,875]\u001b[0m Trial 6 finished with value: 0.3977748020444044 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.38828743588801606.\u001b[0m\n",
      "feature_fraction, val_score: 0.388287: 100%|##########| 7/7 [00:11<00:00,  1.65s/it]\n",
      "num_leaves, val_score: 0.388287:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:   5%|5         | 1/20 [00:04<01:34,  4.97s/it]\u001b[32m[I 2022-10-01 17:13:23,854]\u001b[0m Trial 7 finished with value: 0.40664502789544077 and parameters: {'num_leaves': 178}. Best is trial 7 with value: 0.40664502789544077.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:   5%|5         | 1/20 [00:04<01:34,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  10%|#         | 2/20 [00:07<00:58,  3.25s/it]\u001b[32m[I 2022-10-01 17:13:25,895]\u001b[0m Trial 8 finished with value: 0.4043911486016639 and parameters: {'num_leaves': 69}. Best is trial 8 with value: 0.4043911486016639.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  10%|#         | 2/20 [00:07<00:58,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  15%|#5        | 3/20 [00:10<01:00,  3.57s/it]\u001b[32m[I 2022-10-01 17:13:29,837]\u001b[0m Trial 9 finished with value: 0.40378486315634254 and parameters: {'num_leaves': 157}. Best is trial 9 with value: 0.40378486315634254.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  15%|#5        | 3/20 [00:10<01:00,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  20%|##        | 4/20 [00:14<00:56,  3.52s/it]\u001b[32m[I 2022-10-01 17:13:33,289]\u001b[0m Trial 10 finished with value: 0.40337382391852333 and parameters: {'num_leaves': 219}. Best is trial 10 with value: 0.40337382391852333.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  20%|##        | 4/20 [00:14<00:56,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  25%|##5       | 5/20 [00:15<00:37,  2.49s/it]\u001b[32m[I 2022-10-01 17:13:33,955]\u001b[0m Trial 11 finished with value: 0.4048576938648928 and parameters: {'num_leaves': 50}. Best is trial 10 with value: 0.40337382391852333.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  25%|##5       | 5/20 [00:15<00:37,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  30%|###       | 6/20 [00:15<00:25,  1.80s/it]\u001b[32m[I 2022-10-01 17:13:34,412]\u001b[0m Trial 12 finished with value: 0.39861264731008267 and parameters: {'num_leaves': 122}. Best is trial 12 with value: 0.39861264731008267.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  30%|###       | 6/20 [00:15<00:25,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  35%|###5      | 7/20 [00:16<00:18,  1.40s/it]\u001b[32m[I 2022-10-01 17:13:34,982]\u001b[0m Trial 13 finished with value: 0.403626830155016 and parameters: {'num_leaves': 198}. Best is trial 12 with value: 0.39861264731008267.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  35%|###5      | 7/20 [00:16<00:18,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  40%|####      | 8/20 [00:17<00:14,  1.24s/it]\u001b[32m[I 2022-10-01 17:13:35,887]\u001b[0m Trial 14 finished with value: 0.4011288867133104 and parameters: {'num_leaves': 130}. Best is trial 12 with value: 0.39861264731008267.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  40%|####      | 8/20 [00:17<00:14,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  45%|####5     | 9/20 [00:17<00:10,  1.05it/s]\u001b[32m[I 2022-10-01 17:13:36,208]\u001b[0m Trial 15 finished with value: 0.38950840771623924 and parameters: {'num_leaves': 29}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  45%|####5     | 9/20 [00:17<00:10,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  50%|#####     | 10/20 [00:21<00:20,  2.04s/it]\u001b[32m[I 2022-10-01 17:13:40,686]\u001b[0m Trial 16 finished with value: 0.4094633760418278 and parameters: {'num_leaves': 252}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  50%|#####     | 10/20 [00:21<00:20,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  55%|#####5    | 11/20 [00:22<00:13,  1.50s/it]\u001b[32m[I 2022-10-01 17:13:40,948]\u001b[0m Trial 17 finished with value: 0.41083459551586154 and parameters: {'num_leaves': 6}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  55%|#####5    | 11/20 [00:22<00:13,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  60%|######    | 12/20 [00:22<00:09,  1.23s/it]\u001b[32m[I 2022-10-01 17:13:41,571]\u001b[0m Trial 18 finished with value: 0.4001038255909886 and parameters: {'num_leaves': 87}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  65%|######5   | 13/20 [00:22<00:06,  1.11it/s]\u001b[32m[I 2022-10-01 17:13:41,721]\u001b[0m Trial 19 finished with value: 0.3953287303897767 and parameters: {'num_leaves': 11}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  65%|######5   | 13/20 [00:22<00:06,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  70%|#######   | 14/20 [00:22<00:03,  1.51it/s]\u001b[32m[I 2022-10-01 17:13:41,827]\u001b[0m Trial 20 finished with value: 0.4312726698247624 and parameters: {'num_leaves': 4}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  75%|#######5  | 15/20 [00:23<00:02,  1.91it/s]\u001b[32m[I 2022-10-01 17:13:42,025]\u001b[0m Trial 21 finished with value: 0.3972204475433269 and parameters: {'num_leaves': 39}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  75%|#######5  | 15/20 [00:23<00:02,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  80%|########  | 16/20 [00:24<00:02,  1.43it/s]\u001b[32m[I 2022-10-01 17:13:43,138]\u001b[0m Trial 22 finished with value: 0.3994136260024241 and parameters: {'num_leaves': 30}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  80%|########  | 16/20 [00:24<00:02,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  85%|########5 | 17/20 [00:24<00:01,  1.67it/s]\u001b[32m[I 2022-10-01 17:13:43,501]\u001b[0m Trial 23 finished with value: 0.4013837691942971 and parameters: {'num_leaves': 95}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  85%|########5 | 17/20 [00:24<00:01,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  90%|######### | 18/20 [00:24<00:01,  1.96it/s]\u001b[32m[I 2022-10-01 17:13:43,801]\u001b[0m Trial 24 finished with value: 0.40337339334734557 and parameters: {'num_leaves': 56}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  90%|######### | 18/20 [00:24<00:01,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287:  95%|#########5| 19/20 [00:25<00:00,  2.00it/s]\u001b[32m[I 2022-10-01 17:13:44,281]\u001b[0m Trial 25 finished with value: 0.3919527503122888 and parameters: {'num_leaves': 21}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287:  95%|#########5| 19/20 [00:25<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.388287: 100%|##########| 20/20 [00:25<00:00,  2.07it/s]\u001b[32m[I 2022-10-01 17:13:44,727]\u001b[0m Trial 26 finished with value: 0.3963352834376427 and parameters: {'num_leaves': 80}. Best is trial 15 with value: 0.38950840771623924.\u001b[0m\n",
      "num_leaves, val_score: 0.388287: 100%|##########| 20/20 [00:25<00:00,  1.29s/it]\n",
      "bagging, val_score: 0.388287:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388287:  10%|#         | 1/10 [00:00<00:05,  1.77it/s]\u001b[32m[I 2022-10-01 17:13:45,297]\u001b[0m Trial 27 finished with value: 0.3994749032251065 and parameters: {'bagging_fraction': 0.6367715145995549, 'bagging_freq': 3}. Best is trial 27 with value: 0.3994749032251065.\u001b[0m\n",
      "bagging, val_score: 0.388287:  10%|#         | 1/10 [00:00<00:05,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388287:  20%|##        | 2/10 [00:00<00:03,  2.41it/s]\u001b[32m[I 2022-10-01 17:13:45,609]\u001b[0m Trial 28 finished with value: 0.41216823656572527 and parameters: {'bagging_fraction': 0.4822701981159809, 'bagging_freq': 7}. Best is trial 27 with value: 0.3994749032251065.\u001b[0m\n",
      "bagging, val_score: 0.388287:  20%|##        | 2/10 [00:00<00:03,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388287:  30%|###       | 3/10 [00:01<00:02,  3.05it/s]\u001b[32m[I 2022-10-01 17:13:45,832]\u001b[0m Trial 29 finished with value: 0.39535731993481216 and parameters: {'bagging_fraction': 0.7595878002228814, 'bagging_freq': 6}. Best is trial 29 with value: 0.39535731993481216.\u001b[0m\n",
      "bagging, val_score: 0.388287:  30%|###       | 3/10 [00:01<00:02,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388287:  40%|####      | 4/10 [00:01<00:01,  3.16it/s]\u001b[32m[I 2022-10-01 17:13:46,131]\u001b[0m Trial 30 finished with value: 0.4037632172423197 and parameters: {'bagging_fraction': 0.5214345210173087, 'bagging_freq': 1}. Best is trial 29 with value: 0.39535731993481216.\u001b[0m\n",
      "bagging, val_score: 0.388287:  40%|####      | 4/10 [00:01<00:01,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388287:  50%|#####     | 5/10 [00:01<00:01,  3.34it/s]\u001b[32m[I 2022-10-01 17:13:46,401]\u001b[0m Trial 31 finished with value: 0.4001806820459491 and parameters: {'bagging_fraction': 0.5923096904623311, 'bagging_freq': 4}. Best is trial 29 with value: 0.39535731993481216.\u001b[0m\n",
      "bagging, val_score: 0.388287:  50%|#####     | 5/10 [00:01<00:01,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388287:  60%|######    | 6/10 [00:02<00:01,  2.65it/s]\u001b[32m[I 2022-10-01 17:13:46,931]\u001b[0m Trial 32 finished with value: 0.40510932819519313 and parameters: {'bagging_fraction': 0.5653051006137305, 'bagging_freq': 7}. Best is trial 29 with value: 0.39535731993481216.\u001b[0m\n",
      "bagging, val_score: 0.388287:  70%|#######   | 7/10 [00:02<00:00,  3.14it/s]\u001b[32m[I 2022-10-01 17:13:47,128]\u001b[0m Trial 33 finished with value: 0.39825571494011786 and parameters: {'bagging_fraction': 0.7486337436719045, 'bagging_freq': 4}. Best is trial 29 with value: 0.39535731993481216.\u001b[0m\n",
      "bagging, val_score: 0.388287:  70%|#######   | 7/10 [00:02<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388287:  80%|########  | 8/10 [00:02<00:00,  3.56it/s]\u001b[32m[I 2022-10-01 17:13:47,328]\u001b[0m Trial 34 finished with value: 0.3975793243861019 and parameters: {'bagging_fraction': 0.7049960343483206, 'bagging_freq': 1}. Best is trial 29 with value: 0.39535731993481216.\u001b[0m\n",
      "bagging, val_score: 0.388287:  80%|########  | 8/10 [00:02<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.388287:  90%|######### | 9/10 [00:02<00:00,  3.71it/s]\u001b[32m[I 2022-10-01 17:13:47,571]\u001b[0m Trial 35 finished with value: 0.39495796574098846 and parameters: {'bagging_fraction': 0.8030998495982161, 'bagging_freq': 5}. Best is trial 35 with value: 0.39495796574098846.\u001b[0m\n",
      "bagging, val_score: 0.388287: 100%|##########| 10/10 [00:03<00:00,  4.10it/s]\u001b[32m[I 2022-10-01 17:13:47,759]\u001b[0m Trial 36 finished with value: 0.39889987355569884 and parameters: {'bagging_fraction': 0.6742146945695016, 'bagging_freq': 4}. Best is trial 35 with value: 0.39495796574098846.\u001b[0m\n",
      "bagging, val_score: 0.388287: 100%|##########| 10/10 [00:03<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388287:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388287:  17%|#6        | 1/6 [00:01<00:05,  1.11s/it]\u001b[32m[I 2022-10-01 17:13:48,878]\u001b[0m Trial 37 finished with value: 0.38978372364193575 and parameters: {'feature_fraction': 0.748}. Best is trial 37 with value: 0.38978372364193575.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388287:  17%|#6        | 1/6 [00:01<00:05,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388287:  33%|###3      | 2/6 [00:02<00:04,  1.00s/it]\u001b[32m[I 2022-10-01 17:13:49,802]\u001b[0m Trial 38 finished with value: 0.3964342228145387 and parameters: {'feature_fraction': 0.652}. Best is trial 37 with value: 0.38978372364193575.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388287:  33%|###3      | 2/6 [00:02<00:04,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388287:  50%|#####     | 3/6 [00:03<00:03,  1.03s/it]\u001b[32m[I 2022-10-01 17:13:50,860]\u001b[0m Trial 39 finished with value: 0.3977748020444044 and parameters: {'feature_fraction': 0.62}. Best is trial 37 with value: 0.38978372364193575.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388287:  50%|#####     | 3/6 [00:03<00:03,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388287:  67%|######6   | 4/6 [00:04<00:02,  1.04s/it]\u001b[32m[I 2022-10-01 17:13:51,927]\u001b[0m Trial 40 finished with value: 0.3930256637970644 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 37 with value: 0.38978372364193575.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388287:  67%|######6   | 4/6 [00:04<00:02,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388287:  83%|########3 | 5/6 [00:05<00:01,  1.05s/it]\u001b[32m[I 2022-10-01 17:13:52,991]\u001b[0m Trial 41 finished with value: 0.38828743588801606 and parameters: {'feature_fraction': 0.716}. Best is trial 41 with value: 0.38828743588801606.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388287:  83%|########3 | 5/6 [00:05<00:01,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.388287: 100%|##########| 6/6 [00:05<00:00,  1.24it/s]\u001b[32m[I 2022-10-01 17:13:53,321]\u001b[0m Trial 42 finished with value: 0.3893634008792886 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 41 with value: 0.38828743588801606.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.388287: 100%|##########| 6/6 [00:05<00:00,  1.08it/s]\n",
      "regularization_factors, val_score: 0.388287:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:   5%|5         | 1/20 [00:00<00:09,  1.94it/s]\u001b[32m[I 2022-10-01 17:13:53,844]\u001b[0m Trial 43 finished with value: 0.38796011439488354 and parameters: {'lambda_l1': 0.0001597270775419597, 'lambda_l2': 3.740338333540858e-08}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  10%|#         | 2/20 [00:00<00:06,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-01 17:13:54,050]\u001b[0m Trial 44 finished with value: 0.3959395184063608 and parameters: {'lambda_l1': 0.17434462622595046, 'lambda_l2': 0.001645875314144162}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  15%|#5        | 3/20 [00:00<00:04,  3.69it/s]\u001b[32m[I 2022-10-01 17:13:54,246]\u001b[0m Trial 45 finished with value: 0.39652555545486573 and parameters: {'lambda_l1': 0.14671006922378974, 'lambda_l2': 1.4966359979096266e-06}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  15%|#5        | 3/20 [00:00<00:04,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  20%|##        | 4/20 [00:01<00:07,  2.20it/s]\u001b[32m[I 2022-10-01 17:13:54,980]\u001b[0m Trial 46 finished with value: 0.39756500132641726 and parameters: {'lambda_l1': 0.06280161468780074, 'lambda_l2': 2.948905961093102e-07}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  20%|##        | 4/20 [00:01<00:07,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  25%|##5       | 5/20 [00:01<00:05,  2.54it/s]\u001b[32m[I 2022-10-01 17:13:55,267]\u001b[0m Trial 47 finished with value: 0.4027759518293567 and parameters: {'lambda_l1': 4.17793693143478, 'lambda_l2': 0.2783864668932834}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  25%|##5       | 5/20 [00:01<00:05,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  30%|###       | 6/20 [00:02<00:05,  2.67it/s]\u001b[32m[I 2022-10-01 17:13:55,605]\u001b[0m Trial 48 finished with value: 0.38828743340637684 and parameters: {'lambda_l1': 3.648487821126496e-07, 'lambda_l2': 3.956665697387512e-06}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  30%|###       | 6/20 [00:02<00:05,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  35%|###5      | 7/20 [00:02<00:04,  2.85it/s]\u001b[32m[I 2022-10-01 17:13:55,906]\u001b[0m Trial 49 finished with value: 0.388287432836872 and parameters: {'lambda_l1': 2.9412479412069443e-07, 'lambda_l2': 5.507520759741738e-06}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  40%|####      | 8/20 [00:02<00:03,  3.33it/s]\u001b[32m[I 2022-10-01 17:13:56,099]\u001b[0m Trial 50 finished with value: 0.39627322902877327 and parameters: {'lambda_l1': 1.1602035446947505, 'lambda_l2': 0.3682236285343213}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  40%|####      | 8/20 [00:02<00:03,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  45%|####5     | 9/20 [00:02<00:02,  3.76it/s]\u001b[32m[I 2022-10-01 17:13:56,289]\u001b[0m Trial 51 finished with value: 0.3882874354411944 and parameters: {'lambda_l1': 2.3005620676124112e-07, 'lambda_l2': 6.289289264547616e-08}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  45%|####5     | 9/20 [00:02<00:02,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  50%|#####     | 10/20 [00:03<00:02,  4.02it/s]\u001b[32m[I 2022-10-01 17:13:56,499]\u001b[0m Trial 52 finished with value: 0.39071862295746845 and parameters: {'lambda_l1': 1.017044493393091e-05, 'lambda_l2': 0.0006257879511122899}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  50%|#####     | 10/20 [00:03<00:02,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  55%|#####5    | 11/20 [00:03<00:02,  3.85it/s]\u001b[32m[I 2022-10-01 17:13:56,784]\u001b[0m Trial 53 finished with value: 0.392774679530447 and parameters: {'lambda_l1': 0.0006649837842109003, 'lambda_l2': 1.32330472409254e-08}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  55%|#####5    | 11/20 [00:03<00:02,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  60%|######    | 12/20 [00:03<00:02,  3.57it/s]\u001b[32m[I 2022-10-01 17:13:57,112]\u001b[0m Trial 54 finished with value: 0.3882874294631776 and parameters: {'lambda_l1': 1.4482120173754084e-08, 'lambda_l2': 1.3804359659419041e-05}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  60%|######    | 12/20 [00:03<00:02,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  65%|######5   | 13/20 [00:04<00:02,  3.46it/s]\u001b[32m[I 2022-10-01 17:13:57,420]\u001b[0m Trial 55 finished with value: 0.3974706198224516 and parameters: {'lambda_l1': 0.0003512433253770283, 'lambda_l2': 4.3953513886524714e-05}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  65%|######5   | 13/20 [00:04<00:02,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  70%|#######   | 14/20 [00:04<00:01,  3.39it/s]\u001b[32m[I 2022-10-01 17:13:57,727]\u001b[0m Trial 56 finished with value: 0.39506754516967496 and parameters: {'lambda_l1': 1.2971148375052913e-08, 'lambda_l2': 0.009457603668710728}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  75%|#######5  | 15/20 [00:04<00:01,  3.77it/s]\u001b[32m[I 2022-10-01 17:13:57,925]\u001b[0m Trial 57 finished with value: 0.38828739246428867 and parameters: {'lambda_l1': 8.21595617083855e-06, 'lambda_l2': 6.348957136063344e-05}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  75%|#######5  | 15/20 [00:04<00:01,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  80%|########  | 16/20 [00:04<00:01,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-01 17:13:58,146]\u001b[0m Trial 58 finished with value: 0.39453918257222714 and parameters: {'lambda_l1': 2.3421216625063063e-05, 'lambda_l2': 0.014068892106291008}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  85%|########5 | 17/20 [00:05<00:00,  4.20it/s]\u001b[32m[I 2022-10-01 17:13:58,352]\u001b[0m Trial 59 finished with value: 0.39939410491243893 and parameters: {'lambda_l1': 0.004108018462597378, 'lambda_l2': 8.817944513675302}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  85%|########5 | 17/20 [00:05<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  90%|######### | 18/20 [00:05<00:00,  4.47it/s]\u001b[32m[I 2022-10-01 17:13:58,542]\u001b[0m Trial 60 finished with value: 0.3896365207469857 and parameters: {'lambda_l1': 1.4065476461724177e-05, 'lambda_l2': 0.00010563507574555948}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960:  90%|######### | 18/20 [00:05<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.387960:  95%|#########5| 19/20 [00:05<00:00,  4.59it/s]\u001b[32m[I 2022-10-01 17:13:58,746]\u001b[0m Trial 61 finished with value: 0.39376407899369903 and parameters: {'lambda_l1': 0.010885102521690835, 'lambda_l2': 2.619471449995014e-07}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960: 100%|##########| 20/20 [00:05<00:00,  4.90it/s]\u001b[32m[I 2022-10-01 17:13:58,917]\u001b[0m Trial 62 finished with value: 0.39152130391746875 and parameters: {'lambda_l1': 0.000117633696016661, 'lambda_l2': 2.1701433422980738e-08}. Best is trial 43 with value: 0.38796011439488354.\u001b[0m\n",
      "regularization_factors, val_score: 0.387960: 100%|##########| 20/20 [00:05<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.387960:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.387960:  20%|##        | 1/5 [00:00<00:00,  4.73it/s]\u001b[32m[I 2022-10-01 17:13:59,136]\u001b[0m Trial 63 finished with value: 0.3927510604405121 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.3927510604405121.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.387960:  40%|####      | 2/5 [00:00<00:00,  5.35it/s]\u001b[32m[I 2022-10-01 17:13:59,306]\u001b[0m Trial 64 finished with value: 0.40127348583209627 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.3927510604405121.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.387960:  40%|####      | 2/5 [00:00<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.387960:  60%|######    | 3/5 [00:00<00:00,  5.31it/s]\u001b[32m[I 2022-10-01 17:13:59,496]\u001b[0m Trial 65 finished with value: 0.39496716920802155 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.3927510604405121.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.387960:  80%|########  | 4/5 [00:00<00:00,  5.54it/s]\u001b[32m[I 2022-10-01 17:13:59,665]\u001b[0m Trial 66 finished with value: 0.393823777404057 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.3927510604405121.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.387960:  80%|########  | 4/5 [00:00<00:00,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Number of positive: 3511, number of negative: 3444\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 28\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504817 -> initscore=0.019267\n",
      "[LightGBM] [Info] Start training from score 0.019267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.387960: 100%|##########| 5/5 [00:00<00:00,  5.37it/s]\u001b[32m[I 2022-10-01 17:13:59,861]\u001b[0m Trial 67 finished with value: 0.3938120170999192 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.3927510604405121.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.387960: 100%|##########| 5/5 [00:00<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4/acc: 0.810126582278481\n",
      "CV score: 0.8113428415071292\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "val_scores = []\n",
    "models = []\n",
    "best_params = []\n",
    "for fold, (train_inds, val_inds) in enumerate(kf.split(x_trainval)):\n",
    "    \n",
    "    x_train, x_val = x_trainval[train_inds], x_trainval[val_inds]\n",
    "    y_train, y_val = y_trainval[train_inds], y_trainval[val_inds]\n",
    "\n",
    "    lgb_train = opt_lgb.Dataset(x_train, y_train)\n",
    "    lgb_val = opt_lgb.Dataset(x_val, y_val, reference=lgb_train)\n",
    "    \n",
    "    lgb_results = {}\n",
    "    model = opt_lgb.train(\n",
    "                    params,                    # ハイパーパラメータをセット\n",
    "                    lgb_train,              # 訓練データを訓練用にセット\n",
    "                    valid_sets=[lgb_train, lgb_val], # 訓練データとテストデータをセット\n",
    "                    valid_names=['Train', 'Val'],    # データセットの名前をそれぞれ設定\n",
    "                    num_boost_round=100,              # 計算回数\n",
    "                    early_stopping_rounds=50,         # アーリーストッピング設定\n",
    "                    evals_result=lgb_results,\n",
    "                    verbose_eval=0,\n",
    "                    )  \n",
    "    best_params.append(model.params)\n",
    "\n",
    "    y_val_proba = model.predict(x_val, num_iteration=model.best_iteration)\n",
    "    y_val_pred = np.where(y_val_proba < 0.5, 0, 1)\n",
    "    score = accuracy_score(y_val, y_val_pred)\n",
    "    print(f'fold {fold}/acc: {score}')\n",
    "    val_scores.append(score)\n",
    "    models.append(model)\n",
    "\n",
    "cv_score = np.mean(val_scores)\n",
    "print(f'CV score: {cv_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d2c3c48-ab62-436c-8b9c-78e6b8d7e232",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=0'>1</a>\u001b[0m importance \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(models)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=3'>4</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(models[i]\u001b[39m.\u001b[39;49mfeature_importances_,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=4'>5</a>\u001b[0m                       index\u001b[39m=\u001b[39mtrainval\u001b[39m.\u001b[39mcolumns[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], columns\u001b[39m=\u001b[39m[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=5'>6</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msort_values(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yamada/Develop/spaceship-titanic/src/experiment/atsushi_lgbm_trial5_optuna.ipynb#ch0000017?line=6'>7</a>\u001b[0m     importance \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([importance, df], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "importance = pd.DataFrame()\n",
    "\n",
    "for i in range(len(models)):\n",
    "    df = pd.DataFrame(models[i].feature_importances_,\n",
    "                      index=trainval.columns[:-1], columns=[f'model{i+1}'])\n",
    "    df = df.sort_values(f'model{i+1}', ascending=False)\n",
    "    importance = pd.concat([importance, df], axis=1)\n",
    "\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151b9b9-a1c7-4d5a-8501-38e9820ac4fc",
   "metadata": {},
   "source": [
    "### submit用のcsv作成\n",
    "\n",
    "cvごとの推論の単純平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4459b75c-690c-409e-b622-30f068561a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    predictor = models[i]\n",
    "    y_pred = predictor.predict(x_test, num_iteration=model.best_iteration)\n",
    "    y_preds.append(y_pred)\n",
    "ensemble = np.where(np.mean(y_preds, axis=0) < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26e62e7f-7e25-4b9b-8a58-bf68df56393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv('../../dataset/test.csv')['PassengerId']\n",
    "\n",
    "df_submit = pd.DataFrame(ensemble, index=test_ids, columns=['Transported'])\n",
    "df_submit.Transported = df_submit.Transported.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3e7c2dd-7152-449a-8f20-600b9047d49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0013_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0018_01</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0019_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0021_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0023_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9266_02</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9269_01</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9271_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9277_01</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Transported\n",
       "PassengerId             \n",
       "0013_01             True\n",
       "0018_01            False\n",
       "0019_01             True\n",
       "0021_01             True\n",
       "0023_01             True\n",
       "...                  ...\n",
       "9266_02             True\n",
       "9269_01            False\n",
       "9271_01             True\n",
       "9273_01             True\n",
       "9277_01             True\n",
       "\n",
       "[4277 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76ff1c0f-05f2-4e90-9b8c-0242f97b00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('submission/lgbm_trial9_optuna.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4588e-d121-4526-a80b-d003509fae4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
